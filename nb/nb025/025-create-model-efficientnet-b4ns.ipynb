{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:10.749012Z",
     "iopub.status.busy": "2021-01-30T14:36:10.748223Z",
     "iopub.status.idle": "2021-01-30T14:36:10.750463Z",
     "shell.execute_reply": "2021-01-30T14:36:10.750903Z"
    },
    "papermill": {
     "duration": 0.030067,
     "end_time": "2021-01-30T14:36:10.751039",
     "exception": false,
     "start_time": "2021-01-30T14:36:10.720972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install pytorch_ranger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:10.820054Z",
     "iopub.status.busy": "2021-01-30T14:36:10.819415Z",
     "iopub.status.idle": "2021-01-30T14:36:11.654760Z",
     "shell.execute_reply": "2021-01-30T14:36:11.653367Z"
    },
    "papermill": {
     "duration": 0.869779,
     "end_time": "2021-01-30T14:36:11.654874",
     "exception": false,
     "start_time": "2021-01-30T14:36:10.785095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:11.702411Z",
     "iopub.status.busy": "2021-01-30T14:36:11.701574Z",
     "iopub.status.idle": "2021-01-30T14:36:11.707793Z",
     "shell.execute_reply": "2021-01-30T14:36:11.707366Z"
    },
    "papermill": {
     "duration": 0.031059,
     "end_time": "2021-01-30T14:36:11.707883",
     "exception": false,
     "start_time": "2021-01-30T14:36:11.676824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_tfrecords',\n",
       " 'sample_submission.csv',\n",
       " 'test_tfrecords',\n",
       " 'label_num_to_disease_map.json',\n",
       " 'train_images',\n",
       " 'train.csv',\n",
       " 'test_images']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/cassava-leaf-disease-classification/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:11.760655Z",
     "iopub.status.busy": "2021-01-30T14:36:11.760161Z",
     "iopub.status.idle": "2021-01-30T14:36:12.060653Z",
     "shell.execute_reply": "2021-01-30T14:36:12.060112Z"
    },
    "papermill": {
     "duration": 0.330701,
     "end_time": "2021-01-30T14:36:12.060765",
     "exception": false,
     "start_time": "2021-01-30T14:36:11.730064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label  source\n",
       "0  1000015157.jpg      0    2020\n",
       "1  1000201771.jpg      3    2020\n",
       "2   100042118.jpg      1    2020\n",
       "3  1000723321.jpg      1    2020\n",
       "4  1000812911.jpg      3    2020"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  2216849948.jpg      4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cassava Bacterial Blight (CBB)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cassava Brown Streak Disease (CBSD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cassava Green Mottle (CGM)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cassava Mosaic Disease (CMD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0\n",
       "0       Cassava Bacterial Blight (CBB)\n",
       "1  Cassava Brown Streak Disease (CBSD)\n",
       "2           Cassava Green Mottle (CGM)\n",
       "3         Cassava Mosaic Disease (CMD)\n",
       "4                              Healthy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv('../input/cassava-leaf-disease-merged/merged.csv')\n",
    "test = pd.read_csv('../input/cassava-leaf-disease-classification//sample_submission.csv')\n",
    "label_map = pd.read_json('../input/cassava-leaf-disease-classification/label_num_to_disease_map.json', orient='index')\n",
    "\n",
    "display(train.head())\n",
    "display(test.head())\n",
    "display(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023241,
     "end_time": "2021-01-30T14:36:12.107500",
     "exception": false,
     "start_time": "2021-01-30T14:36:12.084259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Directory settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:12.158867Z",
     "iopub.status.busy": "2021-01-30T14:36:12.158188Z",
     "iopub.status.idle": "2021-01-30T14:36:12.161090Z",
     "shell.execute_reply": "2021-01-30T14:36:12.160625Z"
    },
    "papermill": {
     "duration": 0.030303,
     "end_time": "2021-01-30T14:36:12.161173",
     "exception": false,
     "start_time": "2021-01-30T14:36:12.130870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "    \n",
    "TRAIN_PATH = '../input/cassava-leaf-disease-merged/train'\n",
    "TEST_PATH = '../input/cassava-leaf-disease-classification/test_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025942,
     "end_time": "2021-01-30T14:36:12.210275",
     "exception": false,
     "start_time": "2021-01-30T14:36:12.184333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:12.309915Z",
     "iopub.status.busy": "2021-01-30T14:36:12.308943Z",
     "iopub.status.idle": "2021-01-30T14:36:12.313707Z",
     "shell.execute_reply": "2021-01-30T14:36:12.312810Z"
    },
    "papermill": {
     "duration": 0.065659,
     "end_time": "2021-01-30T14:36:12.313861",
     "exception": false,
     "start_time": "2021-01-30T14:36:12.248202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    debug = False\n",
    "    apex = False\n",
    "    print_freq = 100\n",
    "    num_workers = 4\n",
    "    model_name = 'tf_efficientnet_b4_ns'\n",
    "    size = 500\n",
    "    scheduler = 'CosineAnnealingWarmRestarts'\n",
    "    loss_train = 'BiTemperedLoss'\n",
    "    epochs = 10\n",
    "    T_0 = 10\n",
    "    lr_1 = 2.5e-4\n",
    "    lr_2 = 2.5e-5\n",
    "    t1 = 0.9\n",
    "    t2 = 1.5\n",
    "    smooth = 1e-2\n",
    "    min_lr = 1e-6\n",
    "    batch_size = 8\n",
    "    weight_decay = 1e-6\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1000\n",
    "    seed = 42\n",
    "    target_size = 5\n",
    "    target_col = 'label'\n",
    "    n_fold = 5\n",
    "    trn_fold = [4]\n",
    "    train = True\n",
    "    inference = False\n",
    "    \n",
    "if CFG.debug:\n",
    "    CFG.epochs = 3\n",
    "    train = train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035846,
     "end_time": "2021-01-30T14:36:12.389861",
     "exception": false,
     "start_time": "2021-01-30T14:36:12.354015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:12.478379Z",
     "iopub.status.busy": "2021-01-30T14:36:12.477569Z",
     "iopub.status.idle": "2021-01-30T14:36:16.104290Z",
     "shell.execute_reply": "2021-01-30T14:36:16.103602Z"
    },
    "papermill": {
     "duration": 3.677325,
     "end_time": "2021-01-30T14:36:16.104410",
     "exception": false,
     "start_time": "2021-01-30T14:36:12.427085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "sys.path.append('../input/bi-tempered-loss-pytorch')\n",
    "from bi_tempered_loss import *\n",
    "\n",
    "# sys.path.append('../input/pytorch-optimizer')\n",
    "# import torch_optimizer as optim\n",
    "\n",
    "sys.path.append('../input/pytorch-sam')\n",
    "from sam import SAM\n",
    "\n",
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n",
    ")\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "import timm\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if CFG.apex:\n",
    "    from apex import amp\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024071,
     "end_time": "2021-01-30T14:36:16.152408",
     "exception": false,
     "start_time": "2021-01-30T14:36:16.128337",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:16.209604Z",
     "iopub.status.busy": "2021-01-30T14:36:16.206601Z",
     "iopub.status.idle": "2021-01-30T14:36:16.215936Z",
     "shell.execute_reply": "2021-01-30T14:36:16.215390Z"
    },
    "papermill": {
     "duration": 0.040328,
     "end_time": "2021-01-30T14:36:16.216027",
     "exception": false,
     "start_time": "2021-01-30T14:36:16.175699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f}')\n",
    "    \n",
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023593,
     "end_time": "2021-01-30T14:36:16.262814",
     "exception": false,
     "start_time": "2021-01-30T14:36:16.239221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:16.350035Z",
     "iopub.status.busy": "2021-01-30T14:36:16.349262Z",
     "iopub.status.idle": "2021-01-30T14:36:16.371790Z",
     "shell.execute_reply": "2021-01-30T14:36:16.372220Z"
    },
    "papermill": {
     "duration": 0.055384,
     "end_time": "2021-01-30T14:36:16.372321",
     "exception": false,
     "start_time": "2021-01-30T14:36:16.316937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  label\n",
      "0     0         299\n",
      "      1         695\n",
      "      2         604\n",
      "      3        3092\n",
      "      4         578\n",
      "1     0         299\n",
      "      1         695\n",
      "      2         604\n",
      "      3        3092\n",
      "      4         578\n",
      "2     0         298\n",
      "      1         695\n",
      "      2         603\n",
      "      3        3093\n",
      "      4         578\n",
      "3     0         298\n",
      "      1         695\n",
      "      2         603\n",
      "      3        3093\n",
      "      4         578\n",
      "4     0         298\n",
      "      1         696\n",
      "      2         603\n",
      "      3        3092\n",
      "      4         578\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[CFG.target_col])):\n",
    "    folds.loc[val_index, 'fold'] = int(n)\n",
    "folds['fold'] = folds['fold'].astype(int)\n",
    "print(folds.groupby(['fold', CFG.target_col]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0252,
     "end_time": "2021-01-30T14:36:16.424050",
     "exception": false,
     "start_time": "2021-01-30T14:36:16.398850",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:16.490402Z",
     "iopub.status.busy": "2021-01-30T14:36:16.489592Z",
     "iopub.status.idle": "2021-01-30T14:36:16.492248Z",
     "shell.execute_reply": "2021-01-30T14:36:16.491833Z"
    },
    "papermill": {
     "duration": 0.041821,
     "end_time": "2021-01-30T14:36:16.492334",
     "exception": false,
     "start_time": "2021-01-30T14:36:16.450513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_id'].values\n",
    "        self.labels = df['label'].values\n",
    "#         self.labels = pd.get_dummies(df['label']).values  # One Hot Encoding\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f'{TRAIN_PATH}/{file_name}'\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        label = torch.tensor(self.labels[idx]).long()\n",
    "        return image, label\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_id'].values\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f'{TEST_PATH}/{file_name}'\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:16.545113Z",
     "iopub.status.busy": "2021-01-30T14:36:16.544412Z",
     "iopub.status.idle": "2021-01-30T14:36:16.547431Z",
     "shell.execute_reply": "2021-01-30T14:36:16.546792Z"
    },
    "papermill": {
     "duration": 0.0306,
     "end_time": "2021-01-30T14:36:16.547551",
     "exception": false,
     "start_time": "2021-01-30T14:36:16.516951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataset = TrainDataset(train, transform=None)\n",
    "\n",
    "# for i in range(1):\n",
    "#     image, label = train_dataset[i]\n",
    "#     plt.imshow(image)\n",
    "#     plt.title(f'label: {label}')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024598,
     "end_time": "2021-01-30T14:36:16.597461",
     "exception": false,
     "start_time": "2021-01-30T14:36:16.572863",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:16.655109Z",
     "iopub.status.busy": "2021-01-30T14:36:16.654260Z",
     "iopub.status.idle": "2021-01-30T14:36:16.657060Z",
     "shell.execute_reply": "2021-01-30T14:36:16.656636Z"
    },
    "papermill": {
     "duration": 0.035925,
     "end_time": "2021-01-30T14:36:16.657146",
     "exception": false,
     "start_time": "2021-01-30T14:36:16.621221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transforms(*, data):\n",
    "    \n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "            RandomResizedCrop(CFG.size, CFG.size), \n",
    "            Transpose(p=0.5), \n",
    "            HorizontalFlip(p=0.5), \n",
    "            VerticalFlip(p=0.5), \n",
    "            ShiftScaleRotate(p=0.5), \n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5), \n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5), \n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "            ), \n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    \n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "            Resize(CFG.size, CFG.size), \n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "            ), \n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:16.708108Z",
     "iopub.status.busy": "2021-01-30T14:36:16.707454Z",
     "iopub.status.idle": "2021-01-30T14:36:16.709957Z",
     "shell.execute_reply": "2021-01-30T14:36:16.710329Z"
    },
    "papermill": {
     "duration": 0.029612,
     "end_time": "2021-01-30T14:36:16.710437",
     "exception": false,
     "start_time": "2021-01-30T14:36:16.680825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataset = TrainDataset(train, transform=get_transforms(data='train'))\n",
    "\n",
    "# for i in range(1):\n",
    "#     image, label = train_dataset[i]\n",
    "#     plt.imshow(image[0])\n",
    "#     plt.title(f'label: {label}')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023594,
     "end_time": "2021-01-30T14:36:16.757626",
     "exception": false,
     "start_time": "2021-01-30T14:36:16.734032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:16.812627Z",
     "iopub.status.busy": "2021-01-30T14:36:16.811882Z",
     "iopub.status.idle": "2021-01-30T14:36:16.814978Z",
     "shell.execute_reply": "2021-01-30T14:36:16.814531Z"
    },
    "papermill": {
     "duration": 0.03349,
     "end_time": "2021-01-30T14:36:16.815066",
     "exception": false,
     "start_time": "2021-01-30T14:36:16.781576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomEfficientNetB4ns(nn.Module):\n",
    "    def __init__(self, model_name='tf_efficientnet_b4_ns', pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, CFG.target_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:16.866791Z",
     "iopub.status.busy": "2021-01-30T14:36:16.866098Z",
     "iopub.status.idle": "2021-01-30T14:36:16.868831Z",
     "shell.execute_reply": "2021-01-30T14:36:16.869295Z"
    },
    "papermill": {
     "duration": 0.030522,
     "end_time": "2021-01-30T14:36:16.869398",
     "exception": false,
     "start_time": "2021-01-30T14:36:16.838876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = CustomEfficientNetB4ns(model_name=CFG.model_name, pretrained=False)\n",
    "# train_dataset = TrainDataset(train, transform=get_transforms(data='train'))\n",
    "# train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, \n",
    "#                           num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "# for image, label in train_loader:\n",
    "#     print(image.size())\n",
    "#     output = model(image)\n",
    "#     print(output)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.041447,
     "end_time": "2021-01-30T14:36:16.938022",
     "exception": false,
     "start_time": "2021-01-30T14:36:16.896575",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:17.038017Z",
     "iopub.status.busy": "2021-01-30T14:36:17.037114Z",
     "iopub.status.idle": "2021-01-30T14:36:17.043022Z",
     "shell.execute_reply": "2021-01-30T14:36:17.044280Z"
    },
    "papermill": {
     "duration": 0.057582,
     "end_time": "2021-01-30T14:36:17.044561",
     "exception": false,
     "start_time": "2021-01-30T14:36:16.986979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Label Smoothing\n",
    "# ====================================================\n",
    "class LabelSmoothingLoss(nn.Module): \n",
    "    def __init__(self, classes=5, smoothing=0.0, dim=-1): \n",
    "        super(LabelSmoothingLoss, self).__init__() \n",
    "        self.confidence = 1.0 - smoothing \n",
    "        self.smoothing = smoothing \n",
    "        self.cls = classes \n",
    "        self.dim = dim \n",
    "    def forward(self, pred, target): \n",
    "        pred = pred.log_softmax(dim=self.dim) \n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred) \n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1)) \n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence) \n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:17.137614Z",
     "iopub.status.busy": "2021-01-30T14:36:17.136522Z",
     "iopub.status.idle": "2021-01-30T14:36:17.141488Z",
     "shell.execute_reply": "2021-01-30T14:36:17.142454Z"
    },
    "papermill": {
     "duration": 0.054209,
     "end_time": "2021-01-30T14:36:17.142601",
     "exception": false,
     "start_time": "2021-01-30T14:36:17.088392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = nn.CrossEntropyLoss()(inputs, targets)\n",
    "\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:17.232093Z",
     "iopub.status.busy": "2021-01-30T14:36:17.227261Z",
     "iopub.status.idle": "2021-01-30T14:36:17.235529Z",
     "shell.execute_reply": "2021-01-30T14:36:17.236576Z"
    },
    "papermill": {
     "duration": 0.055727,
     "end_time": "2021-01-30T14:36:17.236739",
     "exception": false,
     "start_time": "2021-01-30T14:36:17.181012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FocalCosineLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, xent=.1):\n",
    "        super(FocalCosineLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.xent = xent\n",
    "\n",
    "        self.y = torch.Tensor([1]).cuda()\n",
    "\n",
    "    def forward(self, input, target, reduction=\"mean\"):\n",
    "        cosine_loss = F.cosine_embedding_loss(input, F.one_hot(target, num_classes=input.size(-1)), self.y, reduction=reduction)\n",
    "\n",
    "        cent_loss = F.cross_entropy(F.normalize(input), target, reduce=False)\n",
    "        pt = torch.exp(-cent_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * cent_loss\n",
    "\n",
    "        if reduction == \"mean\":\n",
    "            focal_loss = torch.mean(focal_loss)\n",
    "\n",
    "        return cosine_loss + self.xent * focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:17.323736Z",
     "iopub.status.busy": "2021-01-30T14:36:17.322962Z",
     "iopub.status.idle": "2021-01-30T14:36:17.329154Z",
     "shell.execute_reply": "2021-01-30T14:36:17.330090Z"
    },
    "papermill": {
     "duration": 0.054447,
     "end_time": "2021-01-30T14:36:17.330226",
     "exception": false,
     "start_time": "2021-01-30T14:36:17.275779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SymmetricCrossEntropy(nn.Module):\n",
    "\n",
    "    def __init__(self, alpha=0.1, beta=1.0, num_classes=5):\n",
    "        super(SymmetricCrossEntropy, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, logits, targets, reduction='mean'):\n",
    "        onehot_targets = torch.eye(self.num_classes)[targets].cuda()\n",
    "        ce_loss = F.cross_entropy(logits, targets, reduction=reduction)\n",
    "        rce_loss = (-onehot_targets*logits.softmax(1).clamp(1e-7, 1.0).log()).sum(1)\n",
    "        if reduction == 'mean':\n",
    "            rce_loss = rce_loss.mean()\n",
    "        elif reduction == 'sum':\n",
    "            rce_loss = rce_loss.sum()\n",
    "        return self.alpha * ce_loss + self.beta * rce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:17.417885Z",
     "iopub.status.busy": "2021-01-30T14:36:17.416999Z",
     "iopub.status.idle": "2021-01-30T14:36:17.468923Z",
     "shell.execute_reply": "2021-01-30T14:36:17.469616Z"
    },
    "papermill": {
     "duration": 0.100986,
     "end_time": "2021-01-30T14:36:17.469773",
     "exception": false,
     "start_time": "2021-01-30T14:36:17.368787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_t(u, t):\n",
    "    \"\"\"Compute log_t for `u'.\"\"\"\n",
    "    if t==1.0:\n",
    "        return u.log()\n",
    "    else:\n",
    "        return (u.pow(1.0 - t) - 1.0) / (1.0 - t)\n",
    "\n",
    "def exp_t(u, t):\n",
    "    \"\"\"Compute exp_t for `u'.\"\"\"\n",
    "    if t==1:\n",
    "        return u.exp()\n",
    "    else:\n",
    "        return (1.0 + (1.0-t)*u).relu().pow(1.0 / (1.0 - t))\n",
    "\n",
    "def compute_normalization_fixed_point(activations, t, num_iters):\n",
    "\n",
    "    \"\"\"Returns the normalization value for each example (t > 1.0).\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      t: Temperature 2 (> 1.0 for tail heaviness).\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Return: A tensor of same shape as activation with the last dimension being 1.\n",
    "    \"\"\"\n",
    "    mu, _ = torch.max(activations, -1, keepdim=True)\n",
    "    normalized_activations_step_0 = activations - mu\n",
    "\n",
    "    normalized_activations = normalized_activations_step_0\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        logt_partition = torch.sum(\n",
    "                exp_t(normalized_activations, t), -1, keepdim=True)\n",
    "        normalized_activations = normalized_activations_step_0 * \\\n",
    "                logt_partition.pow(1.0-t)\n",
    "\n",
    "    logt_partition = torch.sum(\n",
    "            exp_t(normalized_activations, t), -1, keepdim=True)\n",
    "    normalization_constants = - log_t(1.0 / logt_partition, t) + mu\n",
    "\n",
    "    return normalization_constants\n",
    "\n",
    "def compute_normalization_binary_search(activations, t, num_iters):\n",
    "\n",
    "    \"\"\"Returns the normalization value for each example (t < 1.0).\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      t: Temperature 2 (< 1.0 for finite support).\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Return: A tensor of same rank as activation with the last dimension being 1.\n",
    "    \"\"\"\n",
    "\n",
    "    mu, _ = torch.max(activations, -1, keepdim=True)\n",
    "    normalized_activations = activations - mu\n",
    "\n",
    "    effective_dim = \\\n",
    "        torch.sum(\n",
    "                (normalized_activations > -1.0 / (1.0-t)).to(torch.int32),\n",
    "            dim=-1, keepdim=True).to(activations.dtype)\n",
    "\n",
    "    shape_partition = activations.shape[:-1] + (1,)\n",
    "    lower = torch.zeros(shape_partition, dtype=activations.dtype, device=activations.device)\n",
    "    upper = -log_t(1.0/effective_dim, t) * torch.ones_like(lower)\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        logt_partition = (upper + lower)/2.0\n",
    "        sum_probs = torch.sum(\n",
    "                exp_t(normalized_activations - logt_partition, t),\n",
    "                dim=-1, keepdim=True)\n",
    "        update = (sum_probs < 1.0).to(activations.dtype)\n",
    "        lower = torch.reshape(\n",
    "                lower * update + (1.0-update) * logt_partition,\n",
    "                shape_partition)\n",
    "        upper = torch.reshape(\n",
    "                upper * (1.0 - update) + update * logt_partition,\n",
    "                shape_partition)\n",
    "\n",
    "    logt_partition = (upper + lower)/2.0\n",
    "    return logt_partition + mu\n",
    "\n",
    "class ComputeNormalization(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Class implementing custom backward pass for compute_normalization. See compute_normalization.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, activations, t, num_iters):\n",
    "        if t < 1.0:\n",
    "            normalization_constants = compute_normalization_binary_search(activations, t, num_iters)\n",
    "        else:\n",
    "            normalization_constants = compute_normalization_fixed_point(activations, t, num_iters)\n",
    "\n",
    "        ctx.save_for_backward(activations, normalization_constants)\n",
    "        ctx.t=t\n",
    "        return normalization_constants\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        activations, normalization_constants = ctx.saved_tensors\n",
    "        t = ctx.t\n",
    "        normalized_activations = activations - normalization_constants \n",
    "        probabilities = exp_t(normalized_activations, t)\n",
    "        escorts = probabilities.pow(t)\n",
    "        escorts = escorts / escorts.sum(dim=-1, keepdim=True)\n",
    "        grad_input = escorts * grad_output\n",
    "        \n",
    "        return grad_input, None, None\n",
    "\n",
    "def compute_normalization(activations, t, num_iters=5):\n",
    "    \"\"\"Returns the normalization value for each example. \n",
    "    Backward pass is implemented.\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      t: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Return: A tensor of same rank as activation with the last dimension being 1.\n",
    "    \"\"\"\n",
    "    return ComputeNormalization.apply(activations, t, num_iters)\n",
    "\n",
    "def tempered_sigmoid(activations, t, num_iters = 5):\n",
    "    \"\"\"Tempered sigmoid function.\n",
    "    Args:\n",
    "      activations: Activations for the positive class for binary classification.\n",
    "      t: Temperature tensor > 0.0.\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Returns:\n",
    "      A probabilities tensor.\n",
    "    \"\"\"\n",
    "    internal_activations = torch.stack([activations,\n",
    "        torch.zeros_like(activations)],\n",
    "        dim=-1)\n",
    "    internal_probabilities = tempered_softmax(internal_activations, t, num_iters)\n",
    "    return internal_probabilities[..., 0]\n",
    "\n",
    "\n",
    "def tempered_softmax(activations, t, num_iters=5):\n",
    "    \"\"\"Tempered softmax function.\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      t: Temperature > 1.0.\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Returns:\n",
    "      A probabilities tensor.\n",
    "    \"\"\"\n",
    "    if t == 1.0:\n",
    "        return activations.softmax(dim=-1)\n",
    "\n",
    "    normalization_constants = compute_normalization(activations, t, num_iters)\n",
    "    return exp_t(activations - normalization_constants, t)\n",
    "\n",
    "def bi_tempered_binary_logistic_loss(activations,\n",
    "        labels,\n",
    "        t1,\n",
    "        t2,\n",
    "        label_smoothing = 0.0,\n",
    "        num_iters=5,\n",
    "        reduction='mean'):\n",
    "\n",
    "    \"\"\"Bi-Tempered binary logistic loss.\n",
    "    Args:\n",
    "      activations: A tensor containing activations for class 1.\n",
    "      labels: A tensor with shape as activations, containing probabilities for class 1\n",
    "      t1: Temperature 1 (< 1.0 for boundedness).\n",
    "      t2: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n",
    "      label_smoothing: Label smoothing\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Returns:\n",
    "      A loss tensor.\n",
    "    \"\"\"\n",
    "    internal_activations = torch.stack([activations,\n",
    "        torch.zeros_like(activations)],\n",
    "        dim=-1)\n",
    "    internal_labels = torch.stack([labels.to(activations.dtype),\n",
    "        1.0 - labels.to(activations.dtype)],\n",
    "        dim=-1)\n",
    "    return bi_tempered_logistic_loss(internal_activations, \n",
    "            internal_labels,\n",
    "            t1,\n",
    "            t2,\n",
    "            label_smoothing = label_smoothing,\n",
    "            num_iters = num_iters,\n",
    "            reduction = reduction)\n",
    "\n",
    "def bi_tempered_logistic_loss(activations,\n",
    "        labels,\n",
    "        t1,\n",
    "        t2,\n",
    "        label_smoothing=0.0,\n",
    "        num_iters=5,\n",
    "        reduction = 'mean'):\n",
    "\n",
    "    \"\"\"Bi-Tempered Logistic Loss.\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      labels: A tensor with shape and dtype as activations (onehot), \n",
    "        or a long tensor of one dimension less than activations (pytorch standard)\n",
    "      t1: Temperature 1 (< 1.0 for boundedness).\n",
    "      t2: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n",
    "      label_smoothing: Label smoothing parameter between [0, 1). Default 0.0.\n",
    "      num_iters: Number of iterations to run the method. Default 5.\n",
    "      reduction: ``'none'`` | ``'mean'`` | ``'sum'``. Default ``'mean'``.\n",
    "        ``'none'``: No reduction is applied, return shape is shape of\n",
    "        activations without the last dimension.\n",
    "        ``'mean'``: Loss is averaged over minibatch. Return shape (1,)\n",
    "        ``'sum'``: Loss is summed over minibatch. Return shape (1,)\n",
    "    Returns:\n",
    "      A loss tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(labels.shape)<len(activations.shape): #not one-hot\n",
    "        labels_onehot = torch.zeros_like(activations)\n",
    "        labels_onehot.scatter_(1, labels[..., None], 1)\n",
    "    else:\n",
    "        labels_onehot = labels\n",
    "\n",
    "    if label_smoothing > 0:\n",
    "        num_classes = labels_onehot.shape[-1]\n",
    "        labels_onehot = ( 1 - label_smoothing * num_classes / (num_classes - 1) ) \\\n",
    "                * labels_onehot + \\\n",
    "                label_smoothing / (num_classes - 1)\n",
    "\n",
    "    probabilities = tempered_softmax(activations, t2, num_iters)\n",
    "\n",
    "    loss_values = labels_onehot * log_t(labels_onehot + 1e-10, t1) \\\n",
    "            - labels_onehot * log_t(probabilities, t1) \\\n",
    "            - labels_onehot.pow(2.0 - t1) / (2.0 - t1) \\\n",
    "            + probabilities.pow(2.0 - t1) / (2.0 - t1)\n",
    "    loss_values = loss_values.sum(dim = -1) #sum over classes\n",
    "\n",
    "    if reduction == 'none':\n",
    "        return loss_values\n",
    "    if reduction == 'sum':\n",
    "        return loss_values.sum()\n",
    "    if reduction == 'mean':\n",
    "        return loss_values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:17.543061Z",
     "iopub.status.busy": "2021-01-30T14:36:17.541377Z",
     "iopub.status.idle": "2021-01-30T14:36:17.543701Z",
     "shell.execute_reply": "2021-01-30T14:36:17.544106Z"
    },
    "papermill": {
     "duration": 0.033191,
     "end_time": "2021-01-30T14:36:17.544202",
     "exception": false,
     "start_time": "2021-01-30T14:36:17.511011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BiTemperedLogisticLoss(nn.Module): \n",
    "    def __init__(self, t1, t2, smoothing=0.0): \n",
    "        super(BiTemperedLogisticLoss, self).__init__() \n",
    "        self.t1 = t1\n",
    "        self.t2 = t2\n",
    "        self.smoothing = smoothing\n",
    "    def forward(self, logit_label, truth_label):\n",
    "        loss_label = bi_tempered_logistic_loss(\n",
    "            logit_label, truth_label,\n",
    "            t1=self.t1, t2=self.t2,\n",
    "            label_smoothing=self.smoothing,\n",
    "            reduction='none'\n",
    "        )\n",
    "        \n",
    "        loss_label = loss_label.mean()\n",
    "        return loss_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:17.626979Z",
     "iopub.status.busy": "2021-01-30T14:36:17.620058Z",
     "iopub.status.idle": "2021-01-30T14:36:17.629059Z",
     "shell.execute_reply": "2021-01-30T14:36:17.629441Z"
    },
    "papermill": {
     "duration": 0.061775,
     "end_time": "2021-01-30T14:36:17.629547",
     "exception": false,
     "start_time": "2021-01-30T14:36:17.567772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "def asMinutes(s):\n",
    "    \"\"\"秒を分に変換する関数\"\"\"\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    \"\"\"経過時間の測定と終了時間の予測を行う関数\n",
    "    Parameters\n",
    "    ----------\n",
    "    since : float\n",
    "        実験を始めた時刻\n",
    "    percent : float\n",
    "        実験が進んだ割合\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    s : 経過時間\n",
    "    re : 終了までの時間の予測\n",
    "    \"\"\"\n",
    "    now = time.time()\n",
    "    s = now - since  # 経過時間の測定\n",
    "    es = s / percent  # 終了時間の予測\n",
    "    re = es - s  # 残り時間の予想\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(re))\n",
    "\n",
    "def train_fn(train_loader, model, loss_train, loss_metric, optimizer, epoch, shechduler, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        y_preds = model(images)\n",
    "        metric = loss_metric(y_preds, labels)\n",
    "        loss = loss_train(y_preds, labels)\n",
    "        # record loss\n",
    "        losses.update(metric.item(), batch_size)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        if CFG.apex:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else: \n",
    "            loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            optimizer.first_step(zero_grad=True)\n",
    "#             optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "        # measure elapsed time\n",
    "        loss_train(model(images), labels).backward()\n",
    "#         loss = torch.mean(loss)\n",
    "#         loss.backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "        \n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}]'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})'\n",
    "                  'Elapsed {remain:s}' \n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f})' \n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  .format(epoch+1, step, len(train_loader), batch_time=batch_time, \n",
    "                          data_time=data_time, loss=losses, \n",
    "                          remain=timeSince(start, float(step+1)/len(train_loader)), \n",
    "                          grad_norm=grad_norm))\n",
    "    return losses.avg\n",
    "\n",
    "def valid_fn(valid_loader, model, loss_metric, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (images, labels) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images)\n",
    "        loss = loss_metric(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(\n",
    "                   step, len(valid_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses,\n",
    "                   remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                   ))\n",
    "            \n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions\n",
    "\n",
    "def inference(model, states, test_loader, device):\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    probs = []\n",
    "    for i, (images) in tk0:\n",
    "        images = images.to(device)\n",
    "        avgpreds = []\n",
    "        for state in states:\n",
    "            model.load_state_dict(state['model'])\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "        avg_preds = np.mean(avg_preds, axis=0)\n",
    "        probs.append(avg_preds)\n",
    "    probs = np.concatenate(probs)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023767,
     "end_time": "2021-01-30T14:36:17.677791",
     "exception": false,
     "start_time": "2021-01-30T14:36:17.654024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:17.729114Z",
     "iopub.status.busy": "2021-01-30T14:36:17.728215Z",
     "iopub.status.idle": "2021-01-30T14:36:17.759722Z",
     "shell.execute_reply": "2021-01-30T14:36:17.759298Z"
    },
    "papermill": {
     "duration": 0.058265,
     "end_time": "2021-01-30T14:36:17.759808",
     "exception": false,
     "start_time": "2021-01-30T14:36:17.701543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# Train loop\n",
    "# ======================================================\n",
    "\n",
    "def train_loop(folds, fold):\n",
    "    \n",
    "    seed_torch(seed=CFG.seed)    \n",
    "    \n",
    "    LOGGER.info(f'========== fold: {fold} training ============')\n",
    "    \n",
    "    # ======================================================\n",
    "    # loader\n",
    "    # ======================================================\n",
    "    trn_idx = folds[folds['fold'] != fold].index\n",
    "    val_idx = folds[folds['fold'] == fold].index\n",
    "    \n",
    "    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = TrainDataset(train_folds, \n",
    "                                 transform=get_transforms(data='train'))\n",
    "    valid_dataset = TrainDataset(valid_folds, \n",
    "                                 transform=get_transforms(data='valid'))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, \n",
    "                              batch_size=CFG.batch_size, \n",
    "                              shuffle=True, \n",
    "                              num_workers=CFG.num_workers, \n",
    "                              pin_memory=True, \n",
    "                              drop_last=False)\n",
    "    valid_loader = DataLoader(valid_dataset, \n",
    "                              batch_size=CFG.batch_size, \n",
    "                              shuffle=False, \n",
    "                              num_workers=CFG.num_workers, \n",
    "                              pin_memory=True, \n",
    "                              drop_last=False)\n",
    "    \n",
    "    # ===============================================\n",
    "    # scheduler\n",
    "    # ===============================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler=='ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n",
    "        elif CFG.scheduler=='CosineAnnealingLR':\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        return scheduler\n",
    "    \n",
    "    # ===============================================\n",
    "    # model & optimizer\n",
    "    # ===============================================\n",
    "    model = CustomEfficientNetB4ns(CFG.model_name, pretrained=True)\n",
    "    \n",
    "    # 最初の3epochはclassifier層以外全て凍結する。\n",
    "    for name, param in model.model.named_parameters():\n",
    "        if 'classifier' not in name:\n",
    "            param.requires_grad=False\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    base_optimizer = Adam\n",
    "    optimizer = SAM(model.parameters(), base_optimizer, lr=CFG.lr_1, weight_decay=CFG.weight_decay, amsgrad=False)\n",
    "    \n",
    "    scheduler = get_scheduler(optimizer)\n",
    "    \n",
    "    # ===============================================\n",
    "    # apex \n",
    "    # ===============================================\n",
    "    if CFG.apex:\n",
    "        model.optimizer = amp.initialize(model, optimizer, opt_level='O1', verbosity=0)\n",
    "        \n",
    "    # ===============================================\n",
    "    # loop\n",
    "    # ===============================================\n",
    "    def get_loss_train():\n",
    "        if CFG.loss_train == 'CrossEntropyLoss':\n",
    "            loss_train = nn.CrossEntropyLoss()\n",
    "        elif CFG.loss_train == 'LabelSmoothing':\n",
    "            loss_train = LabelSmoothingLoss(classes=CFG.target_size, smoothing=CFG.smooth)\n",
    "        elif CFG.loss_train == 'FocalLoss':\n",
    "            loss_train = FocalLoss().to(device)\n",
    "        elif CFG.loss_train == 'FocalCosineLoss':\n",
    "            loss_train = FocalCosineLoss()\n",
    "        elif CFG.loss_train == 'SymmetricCrossEntropyLoss':\n",
    "            loss_train = SymmetricCrossEntropy().to(device)\n",
    "        elif CFG.loss_train == 'BiTemperedLoss':\n",
    "            loss_train = BiTemperedLogisticLoss(t1=CFG.t1, t2=CFG.t2, smoothing=CFG.smooth)\n",
    "        return loss_train\n",
    "    \n",
    "    loss_train = get_loss_train()\n",
    "    LOGGER.info(f'loss_train: {loss_train}')\n",
    "    loss_metric = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_score = 0.\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(CFG.epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        if epoch == 1:\n",
    "            \n",
    "            # 2epoch目に重みを全て解凍する\n",
    "            for param in model.model.parameters():\n",
    "                param.requires_grad = True\n",
    "                \n",
    "            # 学習率を4e-3から4e-4に落とす\n",
    "            base_optimizer = Adam\n",
    "            optimizer = SAM(model.parameters(), base_optimizer, lr=CFG.lr_2, weight_decay=CFG.weight_decay, amsgrad=False)\n",
    "            scheduler = get_scheduler(optimizer)\n",
    "\n",
    "            LOGGER.info('requires_grad of all parameters are unlocked')\n",
    "            \n",
    "        \n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, loss_train, loss_metric, optimizer, epoch, scheduler, device)\n",
    "        \n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, loss_metric, device)\n",
    "        valid_labels = valid_folds[CFG.target_col].values\n",
    "        \n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "        \n",
    "        # scoring\n",
    "        score = get_score(valid_labels, preds.argmax(1))\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f} avg_val_loss: {avg_val_loss:.4f} time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Accuracy: {score}')\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(), \n",
    "                        'preds': preds}, \n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth')\n",
    "            \n",
    "        # inference用に全て保存しておく        \n",
    "        torch.save({'model': model.state_dict()}, OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_epoch{epoch+1}.pth')\n",
    "    \n",
    "    check_point = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth')\n",
    "    valid_folds[[str(c) for c in range(5)]] = check_point['preds']\n",
    "    valid_folds['preds'] = check_point['preds'].argmax(1)\n",
    "    \n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:17.820739Z",
     "iopub.status.busy": "2021-01-30T14:36:17.819178Z",
     "iopub.status.idle": "2021-01-30T14:36:17.821744Z",
     "shell.execute_reply": "2021-01-30T14:36:17.822163Z"
    },
    "papermill": {
     "duration": 0.038697,
     "end_time": "2021-01-30T14:36:17.822278",
     "exception": false,
     "start_time": "2021-01-30T14:36:17.783581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# main\n",
    "# ====================================================\n",
    "def main():\n",
    "    \n",
    "    \"\"\"\n",
    "    Prepare: 1.train 2.test 3.submission 4.folds\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_result(result_df):\n",
    "        preds = result_df['preds'].values\n",
    "        labels = result_df[CFG.target_col].values\n",
    "        score = get_score(labels, preds)\n",
    "        LOGGER.info(f'Score: {score:<.5f}')\n",
    "        \n",
    "    if CFG.train:\n",
    "        # train\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df = train_loop(folds, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                LOGGER.info(f'=============== fold: {fold} result ================')\n",
    "                get_result(_oof_df)\n",
    "                \n",
    "        # CV result\n",
    "        LOGGER.info(f'============ CV ============')\n",
    "        get_result(oof_df)\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)\n",
    "        \n",
    "    if CFG.inference:\n",
    "        # inference\n",
    "        model = CustomEfficientNetB4ns(CFG.model_name, pretrained=False)\n",
    "        states = [torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth') for fold in CFG.trn_fold]\n",
    "        test_dataset = TestDataset(test, batch_size=CFG.batch_size, shuffle=False, pin_memory=True)\n",
    "        predictions = inference(model, states, test_loader, device)\n",
    "        # submission\n",
    "        test['label'] = predictions.argmax(1)\n",
    "        test[['image_id', 'label']].to_csv(OUTPUT_DIR+'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:17.874545Z",
     "iopub.status.busy": "2021-01-30T14:36:17.873735Z",
     "iopub.status.idle": "2021-01-30T14:36:17.878399Z",
     "shell.execute_reply": "2021-01-30T14:36:17.877820Z"
    },
    "papermill": {
     "duration": 0.032044,
     "end_time": "2021-01-30T14:36:17.878513",
     "exception": false,
     "start_time": "2021-01-30T14:36:17.846469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "used device: cuda\n"
     ]
    }
   ],
   "source": [
    "LOGGER.info(f'used device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-30T14:36:17.933224Z",
     "iopub.status.busy": "2021-01-30T14:36:17.932390Z",
     "iopub.status.idle": "2021-01-30T20:43:16.543036Z",
     "shell.execute_reply": "2021-01-30T20:43:16.542516Z"
    },
    "papermill": {
     "duration": 22018.639157,
     "end_time": "2021-01-30T20:43:16.543152",
     "exception": false,
     "start_time": "2021-01-30T14:36:17.903995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 4 training ============\n",
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b4_ns-d6313a46.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_b4_ns-d6313a46.pth\n",
      "loss_train: BiTemperedLogisticLoss()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2634]Data 0.958 (0.958)Elapsed 0m 2s (remain 92m 1s)Loss: 1.5684(1.5684)Grad: 0.7996  \n",
      "Epoch: [1][100/2634]Data 0.000 (0.010)Elapsed 0m 26s (remain 10m 57s)Loss: 1.6975(1.3986)Grad: 0.7264  \n",
      "Epoch: [1][200/2634]Data 0.000 (0.005)Elapsed 0m 49s (remain 10m 0s)Loss: 0.5229(1.3874)Grad: 0.6896  \n",
      "Epoch: [1][300/2634]Data 0.000 (0.004)Elapsed 1m 13s (remain 9m 28s)Loss: 1.4204(1.3920)Grad: 0.6751  \n",
      "Epoch: [1][400/2634]Data 0.000 (0.003)Elapsed 1m 37s (remain 9m 1s)Loss: 0.6445(1.3530)Grad: 0.4929  \n",
      "Epoch: [1][500/2634]Data 0.000 (0.003)Elapsed 2m 1s (remain 8m 35s)Loss: 1.4101(1.3466)Grad: 0.5456  \n",
      "Epoch: [1][600/2634]Data 0.000 (0.002)Elapsed 2m 24s (remain 8m 8s)Loss: 0.8687(1.3225)Grad: 0.6008  \n",
      "Epoch: [1][700/2634]Data 0.000 (0.002)Elapsed 2m 48s (remain 7m 44s)Loss: 1.0893(1.3152)Grad: 0.6351  \n",
      "Epoch: [1][800/2634]Data 0.000 (0.002)Elapsed 3m 12s (remain 7m 20s)Loss: 0.8757(1.2961)Grad: 0.6917  \n",
      "Epoch: [1][900/2634]Data 0.006 (0.002)Elapsed 3m 36s (remain 6m 55s)Loss: 1.9189(1.2860)Grad: 0.8000  \n",
      "Epoch: [1][1000/2634]Data 0.000 (0.002)Elapsed 3m 59s (remain 6m 31s)Loss: 1.5075(1.2723)Grad: 0.8254  \n",
      "Epoch: [1][1100/2634]Data 0.000 (0.002)Elapsed 4m 23s (remain 6m 7s)Loss: 1.5406(1.2694)Grad: 0.6291  \n",
      "Epoch: [1][1200/2634]Data 0.000 (0.002)Elapsed 4m 47s (remain 5m 42s)Loss: 1.0389(1.2534)Grad: 0.5032  \n",
      "Epoch: [1][1300/2634]Data 0.000 (0.001)Elapsed 5m 10s (remain 5m 18s)Loss: 0.9984(1.2413)Grad: 0.5909  \n",
      "Epoch: [1][1400/2634]Data 0.000 (0.001)Elapsed 5m 34s (remain 4m 54s)Loss: 0.6573(1.2268)Grad: 0.4464  \n",
      "Epoch: [1][1500/2634]Data 0.000 (0.001)Elapsed 5m 59s (remain 4m 30s)Loss: 0.9417(1.2168)Grad: 0.5674  \n",
      "Epoch: [1][1600/2634]Data 0.000 (0.001)Elapsed 6m 22s (remain 4m 6s)Loss: 0.4827(1.2096)Grad: 0.4563  \n",
      "Epoch: [1][1700/2634]Data 0.000 (0.001)Elapsed 6m 46s (remain 3m 42s)Loss: 0.8304(1.1994)Grad: 0.4718  \n",
      "Epoch: [1][1800/2634]Data 0.000 (0.001)Elapsed 7m 10s (remain 3m 18s)Loss: 1.4471(1.1941)Grad: 0.6033  \n",
      "Epoch: [1][1900/2634]Data 0.000 (0.001)Elapsed 7m 34s (remain 2m 55s)Loss: 0.8749(1.1878)Grad: 0.6135  \n",
      "Epoch: [1][2000/2634]Data 0.000 (0.001)Elapsed 7m 58s (remain 2m 31s)Loss: 1.0405(1.1807)Grad: 0.6886  \n",
      "Epoch: [1][2100/2634]Data 0.000 (0.001)Elapsed 8m 21s (remain 2m 7s)Loss: 0.6581(1.1734)Grad: 0.6417  \n",
      "Epoch: [1][2200/2634]Data 0.000 (0.001)Elapsed 8m 45s (remain 1m 43s)Loss: 0.0759(1.1652)Grad: 0.3785  \n",
      "Epoch: [1][2300/2634]Data 0.000 (0.001)Elapsed 9m 9s (remain 1m 19s)Loss: 0.8406(1.1637)Grad: 0.7740  \n",
      "Epoch: [1][2400/2634]Data 0.000 (0.001)Elapsed 9m 33s (remain 0m 55s)Loss: 1.3569(1.1574)Grad: 0.7805  \n",
      "Epoch: [1][2500/2634]Data 0.000 (0.001)Elapsed 9m 56s (remain 0m 31s)Loss: 1.6815(1.1486)Grad: 0.4068  \n",
      "Epoch: [1][2600/2634]Data 0.000 (0.001)Elapsed 10m 20s (remain 0m 7s)Loss: 0.8291(1.1472)Grad: 0.7901  \n",
      "Epoch: [1][2633/2634]Data 0.000 (0.001)Elapsed 10m 28s (remain 0m 0s)Loss: 1.0629(1.1446)Grad: 0.7141  \n",
      "EVAL: [0/659] Data 0.576 (0.576) Elapsed 0m 0s (remain 7m 43s) Loss: 1.0780(1.0780) \n",
      "EVAL: [100/659] Data 0.000 (0.018) Elapsed 0m 13s (remain 1m 17s) Loss: 1.7019(0.7974) \n",
      "EVAL: [200/659] Data 0.000 (0.015) Elapsed 0m 26s (remain 1m 0s) Loss: 0.2934(0.7765) \n",
      "EVAL: [300/659] Data 0.000 (0.013) Elapsed 0m 39s (remain 0m 46s) Loss: 0.7688(0.7667) \n",
      "EVAL: [400/659] Data 0.000 (0.013) Elapsed 0m 52s (remain 0m 33s) Loss: 0.8438(0.7634) \n",
      "EVAL: [500/659] Data 0.003 (0.012) Elapsed 1m 4s (remain 0m 20s) Loss: 1.0414(0.7658) \n",
      "EVAL: [600/659] Data 0.000 (0.010) Elapsed 1m 17s (remain 0m 7s) Loss: 1.2191(0.7886) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 1.1446 avg_val_loss: 0.7970 time: 712s\n",
      "Epoch 1 - Accuracy: 0.7184355420543004\n",
      "Epoch 1 - Save Best Score: 0.7184 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [658/659] Data 0.000 (0.010) Elapsed 1m 23s (remain 0m 0s) Loss: 1.0355(0.7970) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "requires_grad of all parameters are unlocked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2634]Data 0.750 (0.750)Elapsed 0m 1s (remain 86m 18s)Loss: 0.8898(0.8898)Grad: 4.5573  \n",
      "Epoch: [2][100/2634]Data 0.000 (0.008)Elapsed 1m 28s (remain 37m 1s)Loss: 1.2570(0.9967)Grad: 4.0677  \n",
      "Epoch: [2][200/2634]Data 0.000 (0.004)Elapsed 2m 55s (remain 35m 21s)Loss: 0.5997(0.9592)Grad: 2.6860  \n",
      "Epoch: [2][300/2634]Data 0.000 (0.003)Elapsed 4m 22s (remain 33m 53s)Loss: 0.3879(0.9301)Grad: 1.7720  \n",
      "Epoch: [2][400/2634]Data 0.000 (0.002)Elapsed 5m 49s (remain 32m 23s)Loss: 0.2918(0.8892)Grad: 1.7777  \n",
      "Epoch: [2][500/2634]Data 0.000 (0.002)Elapsed 7m 15s (remain 30m 55s)Loss: 0.1940(0.8575)Grad: 2.8358  \n",
      "Epoch: [2][600/2634]Data 0.000 (0.001)Elapsed 8m 42s (remain 29m 27s)Loss: 0.3917(0.8461)Grad: 3.0145  \n",
      "Epoch: [2][700/2634]Data 0.000 (0.001)Elapsed 10m 9s (remain 27m 59s)Loss: 0.3697(0.8360)Grad: 2.3605  \n",
      "Epoch: [2][800/2634]Data 0.000 (0.001)Elapsed 11m 35s (remain 26m 32s)Loss: 0.7874(0.8235)Grad: 3.1490  \n",
      "Epoch: [2][900/2634]Data 0.000 (0.001)Elapsed 13m 2s (remain 25m 5s)Loss: 0.8477(0.8031)Grad: 2.5733  \n",
      "Epoch: [2][1000/2634]Data 0.000 (0.001)Elapsed 14m 29s (remain 23m 37s)Loss: 0.2009(0.7968)Grad: 2.0160  \n",
      "Epoch: [2][1100/2634]Data 0.000 (0.001)Elapsed 15m 55s (remain 22m 10s)Loss: 0.4930(0.7916)Grad: 3.5252  \n",
      "Epoch: [2][1200/2634]Data 0.000 (0.001)Elapsed 17m 22s (remain 20m 43s)Loss: 0.0402(0.7884)Grad: 1.2520  \n",
      "Epoch: [2][1300/2634]Data 0.000 (0.001)Elapsed 18m 48s (remain 19m 16s)Loss: 0.1037(0.7796)Grad: 1.4792  \n",
      "Epoch: [2][1400/2634]Data 0.000 (0.001)Elapsed 20m 15s (remain 17m 49s)Loss: 0.4451(0.7786)Grad: 1.8480  \n",
      "Epoch: [2][1500/2634]Data 0.000 (0.001)Elapsed 21m 42s (remain 16m 22s)Loss: 0.1288(0.7644)Grad: 2.0525  \n",
      "Epoch: [2][1600/2634]Data 0.000 (0.001)Elapsed 23m 8s (remain 14m 56s)Loss: 1.6633(0.7548)Grad: 2.8176  \n",
      "Epoch: [2][1700/2634]Data 0.000 (0.001)Elapsed 24m 35s (remain 13m 29s)Loss: 0.6251(0.7532)Grad: 2.4208  \n",
      "Epoch: [2][1800/2634]Data 0.000 (0.001)Elapsed 26m 2s (remain 12m 2s)Loss: 0.0080(0.7505)Grad: 0.5662  \n",
      "Epoch: [2][1900/2634]Data 0.000 (0.001)Elapsed 27m 29s (remain 10m 36s)Loss: 2.6639(0.7485)Grad: 3.5731  \n",
      "Epoch: [2][2000/2634]Data 0.000 (0.001)Elapsed 28m 56s (remain 9m 9s)Loss: 1.0131(0.7443)Grad: 2.4189  \n",
      "Epoch: [2][2100/2634]Data 0.000 (0.000)Elapsed 30m 22s (remain 7m 42s)Loss: 2.7286(0.7426)Grad: 3.1352  \n",
      "Epoch: [2][2200/2634]Data 0.000 (0.000)Elapsed 31m 49s (remain 6m 15s)Loss: 0.5413(0.7365)Grad: 1.9482  \n",
      "Epoch: [2][2300/2634]Data 0.000 (0.000)Elapsed 33m 16s (remain 4m 48s)Loss: 0.3162(0.7347)Grad: 3.3328  \n",
      "Epoch: [2][2400/2634]Data 0.000 (0.000)Elapsed 34m 42s (remain 3m 22s)Loss: 1.1024(0.7363)Grad: 2.6398  \n",
      "Epoch: [2][2500/2634]Data 0.000 (0.000)Elapsed 36m 9s (remain 1m 55s)Loss: 1.3749(0.7332)Grad: 2.5858  \n",
      "Epoch: [2][2600/2634]Data 0.000 (0.000)Elapsed 37m 36s (remain 0m 28s)Loss: 0.0086(0.7266)Grad: 0.6467  \n",
      "Epoch: [2][2633/2634]Data 0.000 (0.000)Elapsed 38m 4s (remain 0m 0s)Loss: 3.3682(0.7259)Grad: 3.7735  \n",
      "EVAL: [0/659] Data 0.753 (0.753) Elapsed 0m 1s (remain 11m 21s) Loss: 0.5768(0.5768) \n",
      "EVAL: [100/659] Data 0.005 (0.009) Elapsed 0m 13s (remain 1m 13s) Loss: 0.6614(0.4685) \n",
      "EVAL: [200/659] Data 0.000 (0.005) Elapsed 0m 25s (remain 0m 57s) Loss: 0.0561(0.4626) \n",
      "EVAL: [300/659] Data 0.000 (0.005) Elapsed 0m 38s (remain 0m 45s) Loss: 0.4852(0.4462) \n",
      "EVAL: [400/659] Data 0.000 (0.004) Elapsed 0m 50s (remain 0m 32s) Loss: 0.6775(0.4474) \n",
      "EVAL: [500/659] Data 0.000 (0.004) Elapsed 1m 2s (remain 0m 19s) Loss: 0.9581(0.4516) \n",
      "EVAL: [600/659] Data 0.000 (0.003) Elapsed 1m 14s (remain 0m 7s) Loss: 0.4004(0.4702) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.7259 avg_val_loss: 0.4856 time: 2366s\n",
      "Epoch 2 - Accuracy: 0.8651984051642301\n",
      "Epoch 2 - Save Best Score: 0.8652 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [658/659] Data 0.000 (0.003) Elapsed 1m 21s (remain 0m 0s) Loss: 0.0735(0.4856) \n",
      "Epoch: [3][0/2634]Data 0.769 (0.769)Elapsed 0m 1s (remain 78m 42s)Loss: 0.0125(0.0125)Grad: 0.7072  \n",
      "Epoch: [3][100/2634]Data 0.000 (0.008)Elapsed 1m 28s (remain 37m 8s)Loss: 1.3066(0.7332)Grad: 2.2775  \n",
      "Epoch: [3][200/2634]Data 0.000 (0.004)Elapsed 2m 55s (remain 35m 26s)Loss: 0.1742(0.7206)Grad: 1.6612  \n",
      "Epoch: [3][300/2634]Data 0.000 (0.003)Elapsed 4m 22s (remain 33m 55s)Loss: 0.6645(0.6932)Grad: 2.1823  \n",
      "Epoch: [3][400/2634]Data 0.000 (0.002)Elapsed 5m 49s (remain 32m 27s)Loss: 1.5692(0.6772)Grad: 1.0248  \n",
      "Epoch: [3][500/2634]Data 0.000 (0.002)Elapsed 7m 16s (remain 30m 58s)Loss: 0.1871(0.6625)Grad: 1.8187  \n",
      "Epoch: [3][600/2634]Data 0.000 (0.001)Elapsed 8m 43s (remain 29m 29s)Loss: 0.2565(0.6383)Grad: 2.2376  \n",
      "Epoch: [3][700/2634]Data 0.000 (0.001)Elapsed 10m 10s (remain 28m 2s)Loss: 0.1701(0.6558)Grad: 1.1149  \n",
      "Epoch: [3][800/2634]Data 0.000 (0.001)Elapsed 11m 36s (remain 26m 34s)Loss: 1.8825(0.6444)Grad: 2.5413  \n",
      "Epoch: [3][900/2634]Data 0.000 (0.001)Elapsed 13m 3s (remain 25m 7s)Loss: 0.6308(0.6515)Grad: 2.6980  \n",
      "Epoch: [3][1000/2634]Data 0.000 (0.001)Elapsed 14m 30s (remain 23m 40s)Loss: 0.7804(0.6484)Grad: 1.9173  \n",
      "Epoch: [3][1100/2634]Data 0.000 (0.001)Elapsed 15m 57s (remain 22m 13s)Loss: 0.1384(0.6531)Grad: 1.9599  \n",
      "Epoch: [3][1200/2634]Data 0.000 (0.001)Elapsed 17m 24s (remain 20m 45s)Loss: 1.4173(0.6466)Grad: 1.3324  \n",
      "Epoch: [3][1300/2634]Data 0.000 (0.001)Elapsed 18m 50s (remain 19m 18s)Loss: 0.2311(0.6420)Grad: 1.6032  \n",
      "Epoch: [3][1400/2634]Data 0.000 (0.001)Elapsed 20m 17s (remain 17m 51s)Loss: 0.2121(0.6401)Grad: 1.7846  \n",
      "Epoch: [3][1500/2634]Data 0.000 (0.001)Elapsed 21m 44s (remain 16m 24s)Loss: 0.1121(0.6294)Grad: 1.2850  \n",
      "Epoch: [3][1600/2634]Data 0.000 (0.001)Elapsed 23m 10s (remain 14m 57s)Loss: 0.0894(0.6210)Grad: 1.1371  \n",
      "Epoch: [3][1700/2634]Data 0.000 (0.001)Elapsed 24m 37s (remain 13m 30s)Loss: 0.6395(0.6261)Grad: 2.2004  \n",
      "Epoch: [3][1800/2634]Data 0.000 (0.001)Elapsed 26m 3s (remain 12m 3s)Loss: 0.1527(0.6230)Grad: 1.3463  \n",
      "Epoch: [3][1900/2634]Data 0.000 (0.001)Elapsed 27m 30s (remain 10m 36s)Loss: 0.8525(0.6227)Grad: 3.0388  \n",
      "Epoch: [3][2000/2634]Data 0.000 (0.001)Elapsed 28m 57s (remain 9m 9s)Loss: 0.4742(0.6214)Grad: 2.1024  \n",
      "Epoch: [3][2100/2634]Data 0.000 (0.001)Elapsed 30m 24s (remain 7m 42s)Loss: 0.5140(0.6226)Grad: 3.0293  \n",
      "Epoch: [3][2200/2634]Data 0.000 (0.000)Elapsed 31m 50s (remain 6m 15s)Loss: 0.9991(0.6173)Grad: 1.2592  \n",
      "Epoch: [3][2300/2634]Data 0.000 (0.000)Elapsed 33m 17s (remain 4m 49s)Loss: 0.0224(0.6128)Grad: 0.5726  \n",
      "Epoch: [3][2400/2634]Data 0.000 (0.000)Elapsed 34m 43s (remain 3m 22s)Loss: 0.0829(0.6117)Grad: 1.1826  \n",
      "Epoch: [3][2500/2634]Data 0.000 (0.000)Elapsed 36m 10s (remain 1m 55s)Loss: 1.8418(0.6160)Grad: 3.4741  \n",
      "Epoch: [3][2600/2634]Data 0.000 (0.000)Elapsed 37m 37s (remain 0m 28s)Loss: 0.1500(0.6153)Grad: 1.9446  \n",
      "Epoch: [3][2633/2634]Data 0.000 (0.000)Elapsed 38m 5s (remain 0m 0s)Loss: 0.0532(0.6153)Grad: 1.0850  \n",
      "EVAL: [0/659] Data 0.596 (0.596) Elapsed 0m 0s (remain 7m 53s) Loss: 1.2299(1.2299) \n",
      "EVAL: [100/659] Data 0.004 (0.008) Elapsed 0m 12s (remain 1m 9s) Loss: 0.7204(0.4733) \n",
      "EVAL: [200/659] Data 0.000 (0.007) Elapsed 0m 25s (remain 0m 57s) Loss: 0.0427(0.4610) \n",
      "EVAL: [300/659] Data 0.000 (0.006) Elapsed 0m 37s (remain 0m 44s) Loss: 0.4599(0.4490) \n",
      "EVAL: [400/659] Data 0.000 (0.005) Elapsed 0m 49s (remain 0m 32s) Loss: 0.6984(0.4460) \n",
      "EVAL: [500/659] Data 0.000 (0.005) Elapsed 1m 2s (remain 0m 19s) Loss: 0.8105(0.4418) \n",
      "EVAL: [600/659] Data 0.000 (0.005) Elapsed 1m 14s (remain 0m 7s) Loss: 0.1378(0.4605) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6153 avg_val_loss: 0.4758 time: 2367s\n",
      "Epoch 3 - Accuracy: 0.87583064363015\n",
      "Epoch 3 - Save Best Score: 0.8758 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [658/659] Data 0.000 (0.004) Elapsed 1m 20s (remain 0m 0s) Loss: 0.0450(0.4758) \n",
      "Epoch: [4][0/2634]Data 0.820 (0.820)Elapsed 0m 1s (remain 78m 47s)Loss: 0.0130(0.0130)Grad: 0.4908  \n",
      "Epoch: [4][100/2634]Data 0.000 (0.008)Elapsed 1m 28s (remain 36m 52s)Loss: 0.0626(0.6330)Grad: 1.6549  \n",
      "Epoch: [4][200/2634]Data 0.000 (0.004)Elapsed 2m 54s (remain 35m 17s)Loss: 0.5729(0.6513)Grad: 1.7227  \n",
      "Epoch: [4][300/2634]Data 0.000 (0.003)Elapsed 4m 21s (remain 33m 48s)Loss: 0.0050(0.6367)Grad: 0.3184  \n",
      "Epoch: [4][400/2634]Data 0.000 (0.002)Elapsed 5m 48s (remain 32m 19s)Loss: 0.1059(0.6317)Grad: 1.6769  \n",
      "Epoch: [4][500/2634]Data 0.000 (0.002)Elapsed 7m 15s (remain 30m 53s)Loss: 0.2262(0.6016)Grad: 2.0135  \n",
      "Epoch: [4][600/2634]Data 0.000 (0.002)Elapsed 8m 42s (remain 29m 26s)Loss: 0.0320(0.6017)Grad: 1.1884  \n",
      "Epoch: [4][700/2634]Data 0.000 (0.001)Elapsed 10m 8s (remain 27m 59s)Loss: 2.4028(0.6087)Grad: 3.8103  \n",
      "Epoch: [4][800/2634]Data 0.000 (0.001)Elapsed 11m 36s (remain 26m 32s)Loss: 1.1310(0.6243)Grad: 3.4005  \n",
      "Epoch: [4][900/2634]Data 0.000 (0.001)Elapsed 13m 2s (remain 25m 6s)Loss: 0.1857(0.6122)Grad: 1.7796  \n",
      "Epoch: [4][1000/2634]Data 0.000 (0.001)Elapsed 14m 30s (remain 23m 39s)Loss: 0.1694(0.6049)Grad: 1.3099  \n",
      "Epoch: [4][1100/2634]Data 0.000 (0.001)Elapsed 15m 57s (remain 22m 13s)Loss: 0.4541(0.6066)Grad: 1.8014  \n",
      "Epoch: [4][1200/2634]Data 0.000 (0.001)Elapsed 17m 24s (remain 20m 45s)Loss: 0.1332(0.6069)Grad: 1.3794  \n",
      "Epoch: [4][1300/2634]Data 0.000 (0.001)Elapsed 18m 51s (remain 19m 19s)Loss: 0.0868(0.6038)Grad: 1.0339  \n",
      "Epoch: [4][1400/2634]Data 0.000 (0.001)Elapsed 20m 18s (remain 17m 52s)Loss: 0.5109(0.6033)Grad: 1.0293  \n",
      "Epoch: [4][1500/2634]Data 0.000 (0.001)Elapsed 21m 45s (remain 16m 25s)Loss: 0.4263(0.6015)Grad: 1.7785  \n",
      "Epoch: [4][1600/2634]Data 0.000 (0.001)Elapsed 23m 12s (remain 14m 58s)Loss: 0.1288(0.6021)Grad: 2.9326  \n",
      "Epoch: [4][1700/2634]Data 0.000 (0.001)Elapsed 24m 39s (remain 13m 31s)Loss: 0.8111(0.6089)Grad: 2.4283  \n",
      "Epoch: [4][1800/2634]Data 0.000 (0.001)Elapsed 26m 6s (remain 12m 4s)Loss: 0.4743(0.6024)Grad: 2.1940  \n",
      "Epoch: [4][1900/2634]Data 0.000 (0.001)Elapsed 27m 33s (remain 10m 37s)Loss: 0.1330(0.5996)Grad: 1.8355  \n",
      "Epoch: [4][2000/2634]Data 0.000 (0.001)Elapsed 28m 59s (remain 9m 10s)Loss: 0.1525(0.6052)Grad: 2.5990  \n",
      "Epoch: [4][2100/2634]Data 0.000 (0.001)Elapsed 30m 26s (remain 7m 43s)Loss: 0.6556(0.6053)Grad: 0.8724  \n",
      "Epoch: [4][2200/2634]Data 0.000 (0.001)Elapsed 31m 53s (remain 6m 16s)Loss: 0.0009(0.5994)Grad: 0.2045  \n",
      "Epoch: [4][2300/2634]Data 0.000 (0.001)Elapsed 33m 19s (remain 4m 49s)Loss: 0.2024(0.5985)Grad: 2.1758  \n",
      "Epoch: [4][2400/2634]Data 0.000 (0.000)Elapsed 34m 46s (remain 3m 22s)Loss: 0.0053(0.5947)Grad: 0.4131  \n",
      "Epoch: [4][2500/2634]Data 0.000 (0.000)Elapsed 36m 13s (remain 1m 55s)Loss: 0.0650(0.5959)Grad: 1.2214  \n",
      "Epoch: [4][2600/2634]Data 0.000 (0.000)Elapsed 37m 39s (remain 0m 28s)Loss: 0.3261(0.5933)Grad: 1.7879  \n",
      "Epoch: [4][2633/2634]Data 0.000 (0.000)Elapsed 38m 8s (remain 0m 0s)Loss: 0.2349(0.5907)Grad: 2.2240  \n",
      "EVAL: [0/659] Data 0.563 (0.563) Elapsed 0m 0s (remain 7m 33s) Loss: 0.8161(0.8161) \n",
      "EVAL: [100/659] Data 0.000 (0.012) Elapsed 0m 12s (remain 1m 11s) Loss: 0.5762(0.4745) \n",
      "EVAL: [200/659] Data 0.006 (0.007) Elapsed 0m 25s (remain 0m 59s) Loss: 0.0214(0.4561) \n",
      "EVAL: [300/659] Data 0.000 (0.006) Elapsed 0m 37s (remain 0m 45s) Loss: 0.4788(0.4413) \n",
      "EVAL: [400/659] Data 0.000 (0.005) Elapsed 0m 49s (remain 0m 32s) Loss: 0.5900(0.4407) \n",
      "EVAL: [500/659] Data 0.002 (0.005) Elapsed 1m 2s (remain 0m 19s) Loss: 1.0567(0.4326) \n",
      "EVAL: [600/659] Data 0.000 (0.004) Elapsed 1m 14s (remain 0m 7s) Loss: 0.0457(0.4572) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.5907 avg_val_loss: 0.4748 time: 2369s\n",
      "Epoch 4 - Accuracy: 0.8824757926713499\n",
      "Epoch 4 - Save Best Score: 0.8825 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [658/659] Data 0.000 (0.004) Elapsed 1m 20s (remain 0m 0s) Loss: 0.0244(0.4748) \n",
      "Epoch: [5][0/2634]Data 0.818 (0.818)Elapsed 0m 1s (remain 80m 36s)Loss: 0.2934(0.2934)Grad: 2.4936  \n",
      "Epoch: [5][100/2634]Data 0.000 (0.008)Elapsed 1m 28s (remain 36m 56s)Loss: 1.2610(0.5473)Grad: 1.4227  \n",
      "Epoch: [5][200/2634]Data 0.000 (0.004)Elapsed 2m 54s (remain 35m 18s)Loss: 0.0429(0.5828)Grad: 0.8477  \n",
      "Epoch: [5][300/2634]Data 0.000 (0.003)Elapsed 4m 21s (remain 33m 49s)Loss: 0.0239(0.5655)Grad: 0.6262  \n",
      "Epoch: [5][400/2634]Data 0.000 (0.002)Elapsed 5m 48s (remain 32m 19s)Loss: 2.4758(0.5735)Grad: 2.8125  \n",
      "Epoch: [5][500/2634]Data 0.000 (0.002)Elapsed 7m 14s (remain 30m 51s)Loss: 0.5949(0.5429)Grad: 3.4200  \n",
      "Epoch: [5][600/2634]Data 0.000 (0.001)Elapsed 8m 41s (remain 29m 24s)Loss: 0.8694(0.5436)Grad: 0.6795  \n",
      "Epoch: [5][700/2634]Data 0.000 (0.001)Elapsed 10m 8s (remain 27m 56s)Loss: 2.1800(0.5741)Grad: 2.5271  \n",
      "Epoch: [5][800/2634]Data 0.000 (0.001)Elapsed 11m 34s (remain 26m 29s)Loss: 1.2873(0.5650)Grad: 4.0563  \n",
      "Epoch: [5][900/2634]Data 0.000 (0.001)Elapsed 13m 1s (remain 25m 2s)Loss: 0.8567(0.5678)Grad: 1.6809  \n",
      "Epoch: [5][1000/2634]Data 0.000 (0.001)Elapsed 14m 28s (remain 23m 36s)Loss: 0.2676(0.5588)Grad: 2.3953  \n",
      "Epoch: [5][1100/2634]Data 0.000 (0.001)Elapsed 15m 54s (remain 22m 9s)Loss: 0.1262(0.5538)Grad: 1.3408  \n",
      "Epoch: [5][1200/2634]Data 0.000 (0.001)Elapsed 17m 21s (remain 20m 42s)Loss: 0.1648(0.5504)Grad: 1.8603  \n",
      "Epoch: [5][1300/2634]Data 0.000 (0.001)Elapsed 18m 48s (remain 19m 15s)Loss: 1.6908(0.5563)Grad: 2.7126  \n",
      "Epoch: [5][1400/2634]Data 0.000 (0.001)Elapsed 20m 14s (remain 17m 49s)Loss: 0.0177(0.5590)Grad: 0.8749  \n",
      "Epoch: [5][1500/2634]Data 0.000 (0.001)Elapsed 21m 41s (remain 16m 22s)Loss: 0.0183(0.5594)Grad: 0.5505  \n",
      "Epoch: [5][1600/2634]Data 0.000 (0.001)Elapsed 23m 8s (remain 14m 55s)Loss: 1.3699(0.5575)Grad: 1.4162  \n",
      "Epoch: [5][1700/2634]Data 0.000 (0.001)Elapsed 24m 34s (remain 13m 29s)Loss: 1.5056(0.5647)Grad: 2.2177  \n",
      "Epoch: [5][1800/2634]Data 0.000 (0.001)Elapsed 26m 1s (remain 12m 2s)Loss: 0.2033(0.5681)Grad: 1.2761  \n",
      "Epoch: [5][1900/2634]Data 0.000 (0.001)Elapsed 27m 28s (remain 10m 35s)Loss: 1.0699(0.5677)Grad: 1.7325  \n",
      "Epoch: [5][2000/2634]Data 0.000 (0.001)Elapsed 28m 55s (remain 9m 8s)Loss: 1.8539(0.5707)Grad: 1.5050  \n",
      "Epoch: [5][2100/2634]Data 0.000 (0.001)Elapsed 30m 22s (remain 7m 42s)Loss: 0.0247(0.5741)Grad: 0.5788  \n",
      "Epoch: [5][2200/2634]Data 0.000 (0.001)Elapsed 31m 48s (remain 6m 15s)Loss: 0.0549(0.5754)Grad: 0.7550  \n",
      "Epoch: [5][2300/2634]Data 0.000 (0.000)Elapsed 33m 15s (remain 4m 48s)Loss: 0.0347(0.5727)Grad: 1.1085  \n",
      "Epoch: [5][2400/2634]Data 0.000 (0.000)Elapsed 34m 42s (remain 3m 22s)Loss: 0.8225(0.5709)Grad: 1.4755  \n",
      "Epoch: [5][2500/2634]Data 0.000 (0.000)Elapsed 36m 9s (remain 1m 55s)Loss: 0.1790(0.5717)Grad: 1.1943  \n",
      "Epoch: [5][2600/2634]Data 0.000 (0.000)Elapsed 37m 36s (remain 0m 28s)Loss: 0.0674(0.5714)Grad: 0.9642  \n",
      "Epoch: [5][2633/2634]Data 0.000 (0.000)Elapsed 38m 4s (remain 0m 0s)Loss: 0.1195(0.5676)Grad: 1.7596  \n",
      "EVAL: [0/659] Data 0.615 (0.615) Elapsed 0m 0s (remain 8m 7s) Loss: 0.8958(0.8958) \n",
      "EVAL: [100/659] Data 0.001 (0.011) Elapsed 0m 12s (remain 1m 11s) Loss: 0.4901(0.4535) \n",
      "EVAL: [200/659] Data 0.000 (0.007) Elapsed 0m 25s (remain 0m 58s) Loss: 0.0311(0.4496) \n",
      "EVAL: [300/659] Data 0.005 (0.005) Elapsed 0m 37s (remain 0m 45s) Loss: 0.5375(0.4292) \n",
      "EVAL: [400/659] Data 0.000 (0.004) Elapsed 0m 49s (remain 0m 32s) Loss: 0.6455(0.4278) \n",
      "EVAL: [500/659] Data 0.003 (0.004) Elapsed 1m 2s (remain 0m 19s) Loss: 0.5958(0.4220) \n",
      "EVAL: [600/659] Data 0.000 (0.003) Elapsed 1m 14s (remain 0m 7s) Loss: 0.0794(0.4410) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.5676 avg_val_loss: 0.4538 time: 2366s\n",
      "Epoch 5 - Accuracy: 0.8870324662996013\n",
      "Epoch 5 - Save Best Score: 0.8870 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [658/659] Data 0.000 (0.003) Elapsed 1m 20s (remain 0m 0s) Loss: 0.0375(0.4538) \n",
      "Epoch: [6][0/2634]Data 0.619 (0.619)Elapsed 0m 1s (remain 80m 23s)Loss: 1.4918(1.4918)Grad: 1.9210  \n",
      "Epoch: [6][100/2634]Data 0.000 (0.006)Elapsed 1m 28s (remain 36m 59s)Loss: 0.2748(0.5952)Grad: 1.3094  \n",
      "Epoch: [6][200/2634]Data 0.000 (0.003)Elapsed 2m 55s (remain 35m 20s)Loss: 1.2635(0.6067)Grad: 1.9577  \n",
      "Epoch: [6][300/2634]Data 0.000 (0.002)Elapsed 4m 21s (remain 33m 48s)Loss: 0.1332(0.5780)Grad: 1.3376  \n",
      "Epoch: [6][400/2634]Data 0.000 (0.002)Elapsed 5m 48s (remain 32m 20s)Loss: 0.0206(0.5809)Grad: 0.8614  \n",
      "Epoch: [6][500/2634]Data 0.000 (0.001)Elapsed 7m 15s (remain 30m 52s)Loss: 0.6608(0.5840)Grad: 1.4442  \n",
      "Epoch: [6][600/2634]Data 0.000 (0.001)Elapsed 8m 41s (remain 29m 24s)Loss: 0.0175(0.5783)Grad: 0.4384  \n",
      "Epoch: [6][700/2634]Data 0.000 (0.001)Elapsed 10m 8s (remain 27m 57s)Loss: 0.1251(0.5686)Grad: 1.5464  \n",
      "Epoch: [6][800/2634]Data 0.000 (0.001)Elapsed 11m 35s (remain 26m 31s)Loss: 0.1629(0.5759)Grad: 1.5443  \n",
      "Epoch: [6][900/2634]Data 0.000 (0.001)Elapsed 13m 2s (remain 25m 4s)Loss: 1.2008(0.5804)Grad: 2.3052  \n",
      "Epoch: [6][1000/2634]Data 0.000 (0.001)Elapsed 14m 28s (remain 23m 37s)Loss: 0.3390(0.5733)Grad: 1.7231  \n",
      "Epoch: [6][1100/2634]Data 0.000 (0.001)Elapsed 15m 55s (remain 22m 11s)Loss: 0.2230(0.5692)Grad: 1.4452  \n",
      "Epoch: [6][1200/2634]Data 0.000 (0.001)Elapsed 17m 22s (remain 20m 44s)Loss: 1.7712(0.5687)Grad: 1.4679  \n",
      "Epoch: [6][1300/2634]Data 0.000 (0.001)Elapsed 18m 49s (remain 19m 17s)Loss: 0.3747(0.5655)Grad: 1.7312  \n",
      "Epoch: [6][1400/2634]Data 0.000 (0.001)Elapsed 20m 16s (remain 17m 50s)Loss: 0.0940(0.5652)Grad: 0.9001  \n",
      "Epoch: [6][1500/2634]Data 0.000 (0.001)Elapsed 21m 42s (remain 16m 23s)Loss: 0.0847(0.5745)Grad: 1.4750  \n",
      "Epoch: [6][1600/2634]Data 0.000 (0.001)Elapsed 23m 9s (remain 14m 56s)Loss: 0.1881(0.5676)Grad: 1.3492  \n",
      "Epoch: [6][1700/2634]Data 0.000 (0.001)Elapsed 24m 36s (remain 13m 29s)Loss: 0.6118(0.5592)Grad: 1.5682  \n",
      "Epoch: [6][1800/2634]Data 0.000 (0.000)Elapsed 26m 3s (remain 12m 2s)Loss: 1.3983(0.5503)Grad: 2.4208  \n",
      "Epoch: [6][1900/2634]Data 0.000 (0.000)Elapsed 27m 29s (remain 10m 36s)Loss: 0.4396(0.5442)Grad: 2.3898  \n",
      "Epoch: [6][2000/2634]Data 0.000 (0.000)Elapsed 28m 56s (remain 9m 9s)Loss: 0.7179(0.5457)Grad: 1.9639  \n",
      "Epoch: [6][2100/2634]Data 0.000 (0.000)Elapsed 30m 22s (remain 7m 42s)Loss: 0.8222(0.5499)Grad: 2.2991  \n",
      "Epoch: [6][2200/2634]Data 0.000 (0.000)Elapsed 31m 49s (remain 6m 15s)Loss: 0.2300(0.5507)Grad: 2.7084  \n",
      "Epoch: [6][2300/2634]Data 0.000 (0.000)Elapsed 33m 16s (remain 4m 48s)Loss: 0.9876(0.5482)Grad: 1.7175  \n",
      "Epoch: [6][2400/2634]Data 0.000 (0.000)Elapsed 34m 43s (remain 3m 22s)Loss: 0.0613(0.5484)Grad: 1.1112  \n",
      "Epoch: [6][2500/2634]Data 0.000 (0.000)Elapsed 36m 10s (remain 1m 55s)Loss: 0.0495(0.5458)Grad: 0.8100  \n",
      "Epoch: [6][2600/2634]Data 0.000 (0.000)Elapsed 37m 36s (remain 0m 28s)Loss: 0.1178(0.5502)Grad: 1.3461  \n",
      "Epoch: [6][2633/2634]Data 0.000 (0.000)Elapsed 38m 5s (remain 0m 0s)Loss: 0.1436(0.5511)Grad: 1.3271  \n",
      "EVAL: [0/659] Data 0.599 (0.599) Elapsed 0m 0s (remain 7m 42s) Loss: 0.7349(0.7349) \n",
      "EVAL: [100/659] Data 0.002 (0.009) Elapsed 0m 13s (remain 1m 13s) Loss: 0.4890(0.4650) \n",
      "EVAL: [200/659] Data 0.000 (0.008) Elapsed 0m 25s (remain 0m 58s) Loss: 0.0342(0.4479) \n",
      "EVAL: [300/659] Data 0.000 (0.006) Elapsed 0m 37s (remain 0m 44s) Loss: 0.5250(0.4260) \n",
      "EVAL: [400/659] Data 0.000 (0.006) Elapsed 0m 50s (remain 0m 32s) Loss: 0.6276(0.4247) \n",
      "EVAL: [500/659] Data 0.000 (0.006) Elapsed 1m 2s (remain 0m 19s) Loss: 0.6936(0.4204) \n",
      "EVAL: [600/659] Data 0.000 (0.005) Elapsed 1m 14s (remain 0m 7s) Loss: 0.0791(0.4457) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.5511 avg_val_loss: 0.4644 time: 2367s\n",
      "Epoch 6 - Accuracy: 0.8900702487184355\n",
      "Epoch 6 - Save Best Score: 0.8901 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [658/659] Data 0.000 (0.005) Elapsed 1m 21s (remain 0m 0s) Loss: 0.0184(0.4644) \n",
      "Epoch: [7][0/2634]Data 0.780 (0.780)Elapsed 0m 1s (remain 78m 23s)Loss: 0.0914(0.0914)Grad: 1.1535  \n",
      "Epoch: [7][100/2634]Data 0.000 (0.008)Elapsed 1m 28s (remain 36m 57s)Loss: 0.9993(0.5873)Grad: 2.4593  \n",
      "Epoch: [7][200/2634]Data 0.000 (0.004)Elapsed 2m 54s (remain 35m 17s)Loss: 1.6850(0.5604)Grad: 1.2680  \n",
      "Epoch: [7][300/2634]Data 0.000 (0.003)Elapsed 4m 21s (remain 33m 48s)Loss: 0.1761(0.5639)Grad: 1.5368  \n",
      "Epoch: [7][400/2634]Data 0.000 (0.002)Elapsed 5m 48s (remain 32m 20s)Loss: 0.1931(0.5456)Grad: 3.2645  \n",
      "Epoch: [7][500/2634]Data 0.000 (0.002)Elapsed 7m 15s (remain 30m 52s)Loss: 0.3252(0.5323)Grad: 2.5508  \n",
      "Epoch: [7][600/2634]Data 0.000 (0.001)Elapsed 8m 41s (remain 29m 24s)Loss: 0.2098(0.5304)Grad: 1.4188  \n",
      "Epoch: [7][700/2634]Data 0.000 (0.001)Elapsed 10m 8s (remain 27m 57s)Loss: 0.1818(0.5241)Grad: 1.7843  \n",
      "Epoch: [7][800/2634]Data 0.000 (0.001)Elapsed 11m 34s (remain 26m 30s)Loss: 0.3884(0.5399)Grad: 1.0750  \n",
      "Epoch: [7][900/2634]Data 0.000 (0.001)Elapsed 13m 1s (remain 25m 3s)Loss: 1.9053(0.5396)Grad: 1.0490  \n",
      "Epoch: [7][1000/2634]Data 0.000 (0.001)Elapsed 14m 28s (remain 23m 36s)Loss: 0.7408(0.5344)Grad: 1.4052  \n",
      "Epoch: [7][1100/2634]Data 0.000 (0.001)Elapsed 15m 55s (remain 22m 10s)Loss: 0.0700(0.5369)Grad: 1.4806  \n",
      "Epoch: [7][1200/2634]Data 0.000 (0.001)Elapsed 17m 22s (remain 20m 43s)Loss: 0.0681(0.5410)Grad: 1.2913  \n",
      "Epoch: [7][1300/2634]Data 0.000 (0.001)Elapsed 18m 48s (remain 19m 16s)Loss: 1.4702(0.5447)Grad: 0.7604  \n",
      "Epoch: [7][1400/2634]Data 0.000 (0.001)Elapsed 20m 15s (remain 17m 49s)Loss: 0.4808(0.5390)Grad: 1.3290  \n",
      "Epoch: [7][1500/2634]Data 0.000 (0.001)Elapsed 21m 42s (remain 16m 22s)Loss: 0.8623(0.5404)Grad: 2.1689  \n",
      "Epoch: [7][1600/2634]Data 0.000 (0.001)Elapsed 23m 8s (remain 14m 55s)Loss: 0.5030(0.5486)Grad: 1.7094  \n",
      "Epoch: [7][1700/2634]Data 0.000 (0.001)Elapsed 24m 35s (remain 13m 29s)Loss: 0.0024(0.5478)Grad: 0.2885  \n",
      "Epoch: [7][1800/2634]Data 0.000 (0.001)Elapsed 26m 1s (remain 12m 2s)Loss: 0.1211(0.5535)Grad: 1.9112  \n",
      "Epoch: [7][1900/2634]Data 0.000 (0.001)Elapsed 27m 28s (remain 10m 35s)Loss: 1.4918(0.5534)Grad: 2.4066  \n",
      "Epoch: [7][2000/2634]Data 0.000 (0.001)Elapsed 28m 55s (remain 9m 8s)Loss: 0.3933(0.5551)Grad: 0.8478  \n",
      "Epoch: [7][2100/2634]Data 0.000 (0.001)Elapsed 30m 21s (remain 7m 42s)Loss: 0.0851(0.5470)Grad: 1.7210  \n",
      "Epoch: [7][2200/2634]Data 0.000 (0.000)Elapsed 31m 48s (remain 6m 15s)Loss: 0.0355(0.5441)Grad: 0.8822  \n",
      "Epoch: [7][2300/2634]Data 0.000 (0.000)Elapsed 33m 15s (remain 4m 48s)Loss: 0.0025(0.5442)Grad: 0.3337  \n",
      "Epoch: [7][2400/2634]Data 0.000 (0.000)Elapsed 34m 42s (remain 3m 22s)Loss: 0.1630(0.5411)Grad: 1.0389  \n",
      "Epoch: [7][2500/2634]Data 0.000 (0.000)Elapsed 36m 8s (remain 1m 55s)Loss: 0.2719(0.5387)Grad: 1.6205  \n",
      "Epoch: [7][2600/2634]Data 0.000 (0.000)Elapsed 37m 35s (remain 0m 28s)Loss: 0.4048(0.5431)Grad: 1.5087  \n",
      "Epoch: [7][2633/2634]Data 0.000 (0.000)Elapsed 38m 3s (remain 0m 0s)Loss: 0.0114(0.5439)Grad: 0.7599  \n",
      "EVAL: [0/659] Data 0.587 (0.587) Elapsed 0m 0s (remain 8m 19s) Loss: 0.4679(0.4679) \n",
      "EVAL: [100/659] Data 0.000 (0.012) Elapsed 0m 13s (remain 1m 12s) Loss: 0.4342(0.4544) \n",
      "EVAL: [200/659] Data 0.002 (0.007) Elapsed 0m 25s (remain 0m 57s) Loss: 0.0341(0.4433) \n",
      "EVAL: [300/659] Data 0.008 (0.007) Elapsed 0m 37s (remain 0m 44s) Loss: 0.4510(0.4131) \n",
      "EVAL: [400/659] Data 0.071 (0.007) Elapsed 0m 49s (remain 0m 32s) Loss: 0.5351(0.4102) \n",
      "EVAL: [500/659] Data 0.041 (0.006) Elapsed 1m 2s (remain 0m 19s) Loss: 0.7422(0.4046) \n",
      "EVAL: [600/659] Data 0.000 (0.005) Elapsed 1m 14s (remain 0m 7s) Loss: 0.1474(0.4274) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.5439 avg_val_loss: 0.4461 time: 2365s\n",
      "Epoch 7 - Accuracy: 0.8904499715207899\n",
      "Epoch 7 - Save Best Score: 0.8904 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [658/659] Data 0.000 (0.005) Elapsed 1m 21s (remain 0m 0s) Loss: 0.0177(0.4461) \n",
      "Epoch: [8][0/2634]Data 0.783 (0.783)Elapsed 0m 1s (remain 78m 39s)Loss: 0.2274(0.2274)Grad: 1.4096  \n",
      "Epoch: [8][100/2634]Data 0.000 (0.008)Elapsed 1m 28s (remain 36m 57s)Loss: 0.2701(0.5352)Grad: 2.6655  \n",
      "Epoch: [8][200/2634]Data 0.000 (0.004)Elapsed 2m 54s (remain 35m 17s)Loss: 0.0107(0.6023)Grad: 0.4550  \n",
      "Epoch: [8][300/2634]Data 0.000 (0.003)Elapsed 4m 21s (remain 33m 48s)Loss: 0.0549(0.5824)Grad: 0.7284  \n",
      "Epoch: [8][400/2634]Data 0.000 (0.002)Elapsed 5m 48s (remain 32m 19s)Loss: 0.9910(0.5382)Grad: 1.4691  \n",
      "Epoch: [8][500/2634]Data 0.000 (0.002)Elapsed 7m 14s (remain 30m 51s)Loss: 0.8349(0.5178)Grad: 1.0936  \n",
      "Epoch: [8][600/2634]Data 0.000 (0.001)Elapsed 8m 41s (remain 29m 23s)Loss: 0.0363(0.5245)Grad: 1.1230  \n",
      "Epoch: [8][700/2634]Data 0.000 (0.001)Elapsed 10m 8s (remain 27m 56s)Loss: 0.8801(0.5160)Grad: 1.9750  \n",
      "Epoch: [8][800/2634]Data 0.000 (0.001)Elapsed 11m 34s (remain 26m 29s)Loss: 4.8063(0.5298)Grad: 1.2422  \n",
      "Epoch: [8][900/2634]Data 0.000 (0.001)Elapsed 13m 1s (remain 25m 2s)Loss: 0.0034(0.5298)Grad: 0.2716  \n",
      "Epoch: [8][1000/2634]Data 0.000 (0.001)Elapsed 14m 27s (remain 23m 35s)Loss: 0.2274(0.5333)Grad: 2.0740  \n",
      "Epoch: [8][1100/2634]Data 0.000 (0.001)Elapsed 15m 54s (remain 22m 9s)Loss: 0.0143(0.5238)Grad: 0.4396  \n",
      "Epoch: [8][1200/2634]Data 0.000 (0.001)Elapsed 17m 21s (remain 20m 42s)Loss: 0.4465(0.5273)Grad: 1.8024  \n",
      "Epoch: [8][1300/2634]Data 0.000 (0.001)Elapsed 18m 48s (remain 19m 16s)Loss: 1.8248(0.5285)Grad: 1.3504  \n",
      "Epoch: [8][1400/2634]Data 0.000 (0.001)Elapsed 20m 14s (remain 17m 49s)Loss: 2.7232(0.5254)Grad: 1.6343  \n",
      "Epoch: [8][1500/2634]Data 0.000 (0.001)Elapsed 21m 41s (remain 16m 22s)Loss: 1.4563(0.5267)Grad: 1.0173  \n",
      "Epoch: [8][1600/2634]Data 0.000 (0.001)Elapsed 23m 8s (remain 14m 55s)Loss: 3.1044(0.5311)Grad: 2.0438  \n",
      "Epoch: [8][1700/2634]Data 0.000 (0.001)Elapsed 24m 34s (remain 13m 29s)Loss: 0.6032(0.5252)Grad: 1.2899  \n",
      "Epoch: [8][1800/2634]Data 0.000 (0.001)Elapsed 26m 1s (remain 12m 2s)Loss: 0.0176(0.5261)Grad: 0.7133  \n",
      "Epoch: [8][1900/2634]Data 0.000 (0.001)Elapsed 27m 28s (remain 10m 35s)Loss: 0.0958(0.5277)Grad: 1.4170  \n",
      "Epoch: [8][2000/2634]Data 0.000 (0.001)Elapsed 28m 54s (remain 9m 8s)Loss: 0.3809(0.5337)Grad: 2.4658  \n",
      "Epoch: [8][2100/2634]Data 0.000 (0.001)Elapsed 30m 21s (remain 7m 42s)Loss: 0.1675(0.5325)Grad: 1.0860  \n",
      "Epoch: [8][2200/2634]Data 0.000 (0.000)Elapsed 31m 48s (remain 6m 15s)Loss: 0.0438(0.5369)Grad: 0.6735  \n",
      "Epoch: [8][2300/2634]Data 0.000 (0.000)Elapsed 33m 14s (remain 4m 48s)Loss: 0.0589(0.5396)Grad: 1.4954  \n",
      "Epoch: [8][2400/2634]Data 0.000 (0.000)Elapsed 34m 41s (remain 3m 21s)Loss: 1.0163(0.5392)Grad: 0.9307  \n",
      "Epoch: [8][2500/2634]Data 0.000 (0.000)Elapsed 36m 8s (remain 1m 55s)Loss: 0.1801(0.5394)Grad: 1.8111  \n",
      "Epoch: [8][2600/2634]Data 0.000 (0.000)Elapsed 37m 34s (remain 0m 28s)Loss: 0.0759(0.5389)Grad: 1.4538  \n",
      "Epoch: [8][2633/2634]Data 0.000 (0.000)Elapsed 38m 3s (remain 0m 0s)Loss: 0.9199(0.5382)Grad: 1.8519  \n",
      "EVAL: [0/659] Data 0.541 (0.541) Elapsed 0m 0s (remain 7m 38s) Loss: 0.6371(0.6371) \n",
      "EVAL: [100/659] Data 0.000 (0.008) Elapsed 0m 12s (remain 1m 11s) Loss: 0.5067(0.4449) \n",
      "EVAL: [200/659] Data 0.000 (0.007) Elapsed 0m 25s (remain 0m 58s) Loss: 0.0351(0.4390) \n",
      "EVAL: [300/659] Data 0.000 (0.005) Elapsed 0m 37s (remain 0m 44s) Loss: 0.5788(0.4205) \n",
      "EVAL: [400/659] Data 0.000 (0.004) Elapsed 0m 49s (remain 0m 31s) Loss: 0.5367(0.4196) \n",
      "EVAL: [500/659] Data 0.000 (0.004) Elapsed 1m 2s (remain 0m 19s) Loss: 0.6142(0.4121) \n",
      "EVAL: [600/659] Data 0.000 (0.003) Elapsed 1m 14s (remain 0m 7s) Loss: 0.1204(0.4345) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.5382 avg_val_loss: 0.4521 time: 2364s\n",
      "Epoch 8 - Accuracy: 0.8864628820960698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [658/659] Data 0.000 (0.003) Elapsed 1m 20s (remain 0m 0s) Loss: 0.0322(0.4521) \n",
      "Epoch: [9][0/2634]Data 0.643 (0.643)Elapsed 0m 1s (remain 77m 33s)Loss: 0.1961(0.1961)Grad: 2.5605  \n",
      "Epoch: [9][100/2634]Data 0.000 (0.007)Elapsed 1m 28s (remain 37m 3s)Loss: 2.8273(0.6139)Grad: 1.5933  \n",
      "Epoch: [9][200/2634]Data 0.000 (0.003)Elapsed 2m 55s (remain 35m 25s)Loss: 0.0005(0.5934)Grad: 0.1474  \n",
      "Epoch: [9][300/2634]Data 0.000 (0.002)Elapsed 4m 22s (remain 33m 52s)Loss: 1.1699(0.5586)Grad: 1.2154  \n",
      "Epoch: [9][400/2634]Data 0.000 (0.002)Elapsed 5m 49s (remain 32m 24s)Loss: 1.2691(0.5409)Grad: 2.5975  \n",
      "Epoch: [9][500/2634]Data 0.000 (0.001)Elapsed 7m 15s (remain 30m 55s)Loss: 0.2643(0.5236)Grad: 1.5622  \n",
      "Epoch: [9][600/2634]Data 0.000 (0.001)Elapsed 8m 42s (remain 29m 27s)Loss: 0.1115(0.5132)Grad: 1.6861  \n",
      "Epoch: [9][700/2634]Data 0.000 (0.001)Elapsed 10m 9s (remain 27m 59s)Loss: 1.0512(0.5017)Grad: 0.9661  \n",
      "Epoch: [9][800/2634]Data 0.000 (0.001)Elapsed 11m 35s (remain 26m 32s)Loss: 0.4452(0.4976)Grad: 1.5430  \n",
      "Epoch: [9][900/2634]Data 0.000 (0.001)Elapsed 13m 2s (remain 25m 4s)Loss: 1.8246(0.4946)Grad: 1.1623  \n",
      "Epoch: [9][1000/2634]Data 0.000 (0.001)Elapsed 14m 28s (remain 23m 37s)Loss: 0.7735(0.5050)Grad: 1.9641  \n",
      "Epoch: [9][1100/2634]Data 0.000 (0.001)Elapsed 15m 55s (remain 22m 10s)Loss: 0.6373(0.5087)Grad: 0.9460  \n",
      "Epoch: [9][1200/2634]Data 0.000 (0.001)Elapsed 17m 22s (remain 20m 43s)Loss: 0.1920(0.5157)Grad: 1.0516  \n",
      "Epoch: [9][1300/2634]Data 0.000 (0.001)Elapsed 18m 49s (remain 19m 16s)Loss: 0.0152(0.5133)Grad: 0.8287  \n",
      "Epoch: [9][1400/2634]Data 0.000 (0.001)Elapsed 20m 15s (remain 17m 49s)Loss: 1.0441(0.5126)Grad: 2.6087  \n",
      "Epoch: [9][1500/2634]Data 0.000 (0.001)Elapsed 21m 42s (remain 16m 23s)Loss: 0.1999(0.5055)Grad: 1.0484  \n",
      "Epoch: [9][1600/2634]Data 0.000 (0.001)Elapsed 23m 9s (remain 14m 56s)Loss: 0.1665(0.4983)Grad: 1.3559  \n",
      "Epoch: [9][1700/2634]Data 0.000 (0.001)Elapsed 24m 36s (remain 13m 29s)Loss: 0.0088(0.4977)Grad: 0.3853  \n",
      "Epoch: [9][1800/2634]Data 0.000 (0.000)Elapsed 26m 3s (remain 12m 2s)Loss: 0.4507(0.5002)Grad: 1.4159  \n",
      "Epoch: [9][1900/2634]Data 0.000 (0.000)Elapsed 27m 29s (remain 10m 36s)Loss: 0.1359(0.5003)Grad: 1.8724  \n",
      "Epoch: [9][2000/2634]Data 0.000 (0.000)Elapsed 28m 56s (remain 9m 9s)Loss: 0.0511(0.4996)Grad: 1.0954  \n",
      "Epoch: [9][2100/2634]Data 0.000 (0.000)Elapsed 30m 23s (remain 7m 42s)Loss: 2.2216(0.5049)Grad: 1.6017  \n",
      "Epoch: [9][2200/2634]Data 0.000 (0.000)Elapsed 31m 50s (remain 6m 15s)Loss: 0.3062(0.5036)Grad: 2.1961  \n",
      "Epoch: [9][2300/2634]Data 0.000 (0.000)Elapsed 33m 16s (remain 4m 49s)Loss: 0.0268(0.5069)Grad: 0.6876  \n",
      "Epoch: [9][2400/2634]Data 0.000 (0.000)Elapsed 34m 43s (remain 3m 22s)Loss: 2.3892(0.5131)Grad: 1.1117  \n",
      "Epoch: [9][2500/2634]Data 0.000 (0.000)Elapsed 36m 10s (remain 1m 55s)Loss: 0.0937(0.5131)Grad: 1.2667  \n",
      "Epoch: [9][2600/2634]Data 0.000 (0.000)Elapsed 37m 36s (remain 0m 28s)Loss: 0.0062(0.5164)Grad: 0.3354  \n",
      "Epoch: [9][2633/2634]Data 0.000 (0.000)Elapsed 38m 5s (remain 0m 0s)Loss: 0.3048(0.5164)Grad: 1.4515  \n",
      "EVAL: [0/659] Data 0.642 (0.642) Elapsed 0m 0s (remain 8m 21s) Loss: 0.4055(0.4055) \n",
      "EVAL: [100/659] Data 0.055 (0.011) Elapsed 0m 12s (remain 1m 11s) Loss: 0.6169(0.5164) \n",
      "EVAL: [200/659] Data 0.000 (0.008) Elapsed 0m 25s (remain 0m 58s) Loss: 0.0330(0.4979) \n",
      "EVAL: [300/659] Data 0.000 (0.006) Elapsed 0m 37s (remain 0m 45s) Loss: 0.4697(0.4680) \n",
      "EVAL: [400/659] Data 0.000 (0.005) Elapsed 0m 50s (remain 0m 32s) Loss: 0.7036(0.4698) \n",
      "EVAL: [500/659] Data 0.013 (0.005) Elapsed 1m 3s (remain 0m 19s) Loss: 0.6736(0.4576) \n",
      "EVAL: [600/659] Data 0.000 (0.004) Elapsed 1m 15s (remain 0m 7s) Loss: 0.1071(0.4837) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.5164 avg_val_loss: 0.5045 time: 2367s\n",
      "Epoch 9 - Accuracy: 0.8923485855325612\n",
      "Epoch 9 - Save Best Score: 0.8923 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [658/659] Data 0.000 (0.004) Elapsed 1m 21s (remain 0m 0s) Loss: 0.0165(0.5045) \n",
      "Epoch: [10][0/2634]Data 0.767 (0.767)Elapsed 0m 1s (remain 80m 59s)Loss: 0.4201(0.4201)Grad: 2.1624  \n",
      "Epoch: [10][100/2634]Data 0.000 (0.008)Elapsed 1m 28s (remain 37m 3s)Loss: 0.0975(0.5395)Grad: 1.1003  \n",
      "Epoch: [10][200/2634]Data 0.000 (0.004)Elapsed 2m 55s (remain 35m 26s)Loss: 0.0576(0.5000)Grad: 1.5630  \n",
      "Epoch: [10][300/2634]Data 0.000 (0.003)Elapsed 4m 22s (remain 33m 54s)Loss: 0.0069(0.5355)Grad: 0.2961  \n",
      "Epoch: [10][400/2634]Data 0.000 (0.002)Elapsed 5m 49s (remain 32m 24s)Loss: 1.2756(0.5280)Grad: 3.7298  \n",
      "Epoch: [10][500/2634]Data 0.000 (0.002)Elapsed 7m 15s (remain 30m 56s)Loss: 0.0887(0.5076)Grad: 1.5821  \n",
      "Epoch: [10][600/2634]Data 0.000 (0.001)Elapsed 8m 42s (remain 29m 28s)Loss: 0.0102(0.5002)Grad: 0.4507  \n",
      "Epoch: [10][700/2634]Data 0.000 (0.001)Elapsed 10m 9s (remain 28m 0s)Loss: 0.3816(0.5019)Grad: 1.5036  \n",
      "Epoch: [10][800/2634]Data 0.000 (0.001)Elapsed 11m 36s (remain 26m 32s)Loss: 0.1753(0.4982)Grad: 1.5128  \n",
      "Epoch: [10][900/2634]Data 0.000 (0.001)Elapsed 13m 2s (remain 25m 5s)Loss: 0.6660(0.5060)Grad: 2.4133  \n",
      "Epoch: [10][1000/2634]Data 0.000 (0.001)Elapsed 14m 29s (remain 23m 37s)Loss: 2.0472(0.5048)Grad: 1.7473  \n",
      "Epoch: [10][1100/2634]Data 0.000 (0.001)Elapsed 15m 55s (remain 22m 10s)Loss: 0.0058(0.4965)Grad: 0.4605  \n",
      "Epoch: [10][1200/2634]Data 0.000 (0.001)Elapsed 17m 22s (remain 20m 43s)Loss: 0.1943(0.5123)Grad: 2.1684  \n",
      "Epoch: [10][1300/2634]Data 0.000 (0.001)Elapsed 18m 48s (remain 19m 16s)Loss: 1.7353(0.5060)Grad: 1.6029  \n",
      "Epoch: [10][1400/2634]Data 0.000 (0.001)Elapsed 20m 15s (remain 17m 49s)Loss: 0.6735(0.5046)Grad: 1.4549  \n",
      "Epoch: [10][1500/2634]Data 0.000 (0.001)Elapsed 21m 42s (remain 16m 22s)Loss: 0.1903(0.4987)Grad: 1.8804  \n",
      "Epoch: [10][1600/2634]Data 0.000 (0.001)Elapsed 23m 8s (remain 14m 56s)Loss: 0.0128(0.4994)Grad: 0.4798  \n",
      "Epoch: [10][1700/2634]Data 0.000 (0.001)Elapsed 24m 35s (remain 13m 29s)Loss: 0.0242(0.5045)Grad: 1.1009  \n",
      "Epoch: [10][1800/2634]Data 0.000 (0.001)Elapsed 26m 2s (remain 12m 2s)Loss: 3.2282(0.5092)Grad: 1.7813  \n",
      "Epoch: [10][1900/2634]Data 0.000 (0.001)Elapsed 27m 28s (remain 10m 35s)Loss: 0.0028(0.5064)Grad: 0.2782  \n",
      "Epoch: [10][2000/2634]Data 0.000 (0.001)Elapsed 28m 55s (remain 9m 8s)Loss: 0.2263(0.5071)Grad: 2.6843  \n",
      "Epoch: [10][2100/2634]Data 0.000 (0.001)Elapsed 30m 22s (remain 7m 42s)Loss: 0.1245(0.5085)Grad: 1.1996  \n",
      "Epoch: [10][2200/2634]Data 0.000 (0.000)Elapsed 31m 48s (remain 6m 15s)Loss: 1.2533(0.5117)Grad: 2.2234  \n",
      "Epoch: [10][2300/2634]Data 0.000 (0.000)Elapsed 33m 15s (remain 4m 48s)Loss: 0.7496(0.5132)Grad: 3.2053  \n",
      "Epoch: [10][2400/2634]Data 0.000 (0.000)Elapsed 34m 41s (remain 3m 22s)Loss: 0.0030(0.5127)Grad: 0.3156  \n",
      "Epoch: [10][2500/2634]Data 0.000 (0.000)Elapsed 36m 8s (remain 1m 55s)Loss: 1.1795(0.5138)Grad: 1.3625  \n",
      "Epoch: [10][2600/2634]Data 0.000 (0.000)Elapsed 37m 35s (remain 0m 28s)Loss: 0.0629(0.5165)Grad: 1.2859  \n",
      "Epoch: [10][2633/2634]Data 0.000 (0.000)Elapsed 38m 3s (remain 0m 0s)Loss: 1.2615(0.5166)Grad: 1.6865  \n",
      "EVAL: [0/659] Data 0.493 (0.493) Elapsed 0m 0s (remain 6m 56s) Loss: 0.4732(0.4732) \n",
      "EVAL: [100/659] Data 0.000 (0.009) Elapsed 0m 12s (remain 1m 11s) Loss: 0.5987(0.4372) \n",
      "EVAL: [200/659] Data 0.000 (0.005) Elapsed 0m 25s (remain 0m 58s) Loss: 0.0348(0.4336) \n",
      "EVAL: [300/659] Data 0.010 (0.005) Elapsed 0m 37s (remain 0m 44s) Loss: 0.5248(0.4089) \n",
      "EVAL: [400/659] Data 0.000 (0.005) Elapsed 0m 49s (remain 0m 32s) Loss: 0.5827(0.4111) \n",
      "EVAL: [500/659] Data 0.000 (0.004) Elapsed 1m 2s (remain 0m 19s) Loss: 0.7287(0.4063) \n",
      "EVAL: [600/659] Data 0.000 (0.003) Elapsed 1m 14s (remain 0m 7s) Loss: 0.1033(0.4332) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.5166 avg_val_loss: 0.4546 time: 2365s\n",
      "Epoch 10 - Accuracy: 0.8902601101196127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [658/659] Data 0.000 (0.003) Elapsed 1m 20s (remain 0m 0s) Loss: 0.0133(0.4546) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=============== fold: 4 result ================\n",
      "Score: 0.89235\n",
      "============ CV ============\n",
      "Score: 0.89235\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 22031.227412,
   "end_time": "2021-01-30T20:43:17.982413",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-30T14:36:06.755001",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
