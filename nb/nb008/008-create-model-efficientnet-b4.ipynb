{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:04.210774Z",
     "iopub.status.busy": "2021-01-10T23:58:04.209848Z",
     "iopub.status.idle": "2021-01-10T23:58:04.212378Z",
     "shell.execute_reply": "2021-01-10T23:58:04.212956Z"
    },
    "papermill": {
     "duration": 0.040585,
     "end_time": "2021-01-10T23:58:04.213107",
     "exception": false,
     "start_time": "2021-01-10T23:58:04.172522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install pytorch_ranger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:04.277336Z",
     "iopub.status.busy": "2021-01-10T23:58:04.276593Z",
     "iopub.status.idle": "2021-01-10T23:58:05.250203Z",
     "shell.execute_reply": "2021-01-10T23:58:05.224948Z"
    },
    "papermill": {
     "duration": 1.00751,
     "end_time": "2021-01-10T23:58:05.250437",
     "exception": false,
     "start_time": "2021-01-10T23:58:04.242927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:05.427796Z",
     "iopub.status.busy": "2021-01-10T23:58:05.426823Z",
     "iopub.status.idle": "2021-01-10T23:58:05.447698Z",
     "shell.execute_reply": "2021-01-10T23:58:05.448758Z"
    },
    "papermill": {
     "duration": 0.104452,
     "end_time": "2021-01-10T23:58:05.448975",
     "exception": false,
     "start_time": "2021-01-10T23:58:05.344523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_tfrecords',\n",
       " 'sample_submission.csv',\n",
       " 'test_tfrecords',\n",
       " 'label_num_to_disease_map.json',\n",
       " 'train_images',\n",
       " 'train.csv',\n",
       " 'test_images']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/cassava-leaf-disease-classification/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:05.554314Z",
     "iopub.status.busy": "2021-01-10T23:58:05.552490Z",
     "iopub.status.idle": "2021-01-10T23:58:06.033548Z",
     "shell.execute_reply": "2021-01-10T23:58:06.032939Z"
    },
    "papermill": {
     "duration": 0.535497,
     "end_time": "2021-01-10T23:58:06.033686",
     "exception": false,
     "start_time": "2021-01-10T23:58:05.498189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label  source\n",
       "0  1000015157.jpg      0    2020\n",
       "1  1000201771.jpg      3    2020\n",
       "2   100042118.jpg      1    2020\n",
       "3  1000723321.jpg      1    2020\n",
       "4  1000812911.jpg      3    2020"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  2216849948.jpg      4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cassava Bacterial Blight (CBB)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cassava Brown Streak Disease (CBSD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cassava Green Mottle (CGM)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cassava Mosaic Disease (CMD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0\n",
       "0       Cassava Bacterial Blight (CBB)\n",
       "1  Cassava Brown Streak Disease (CBSD)\n",
       "2           Cassava Green Mottle (CGM)\n",
       "3         Cassava Mosaic Disease (CMD)\n",
       "4                              Healthy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv('../input/cassava-leaf-disease-merged/merged.csv')\n",
    "test = pd.read_csv('../input/cassava-leaf-disease-classification//sample_submission.csv')\n",
    "label_map = pd.read_json('../input/cassava-leaf-disease-classification/label_num_to_disease_map.json', orient='index')\n",
    "\n",
    "display(train.head())\n",
    "display(test.head())\n",
    "display(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029994,
     "end_time": "2021-01-10T23:58:06.096573",
     "exception": false,
     "start_time": "2021-01-10T23:58:06.066579",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Directory settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:06.162065Z",
     "iopub.status.busy": "2021-01-10T23:58:06.161309Z",
     "iopub.status.idle": "2021-01-10T23:58:06.164411Z",
     "shell.execute_reply": "2021-01-10T23:58:06.163815Z"
    },
    "papermill": {
     "duration": 0.038756,
     "end_time": "2021-01-10T23:58:06.164527",
     "exception": false,
     "start_time": "2021-01-10T23:58:06.125771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "    \n",
    "TRAIN_PATH = '../input/cassava-leaf-disease-merged/train'\n",
    "TEST_PATH = '../input/cassava-leaf-disease-classification/test_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030458,
     "end_time": "2021-01-10T23:58:06.227284",
     "exception": false,
     "start_time": "2021-01-10T23:58:06.196826",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:06.316045Z",
     "iopub.status.busy": "2021-01-10T23:58:06.315040Z",
     "iopub.status.idle": "2021-01-10T23:58:06.318512Z",
     "shell.execute_reply": "2021-01-10T23:58:06.319276Z"
    },
    "papermill": {
     "duration": 0.06211,
     "end_time": "2021-01-10T23:58:06.319455",
     "exception": false,
     "start_time": "2021-01-10T23:58:06.257345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    debug = False\n",
    "    apex = False\n",
    "    print_freq = 100\n",
    "    num_workers = 4\n",
    "    model_name = 'tf_efficientnet_b4'\n",
    "    size = 500\n",
    "    scheduler = 'CosineAnnealingWarmRestarts'\n",
    "    loss_train = 'BiTemperedLoss'\n",
    "    epochs = 10\n",
    "    T_0 = 10\n",
    "    lr_1 = 2.5e-4\n",
    "    lr_2 = 2.5e-5\n",
    "    t1 = 0.9\n",
    "    t2 = 1.5\n",
    "    smooth = 1e-2\n",
    "    min_lr = 1e-6\n",
    "    batch_size = 8\n",
    "    weight_decay = 1e-6\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1000\n",
    "    seed = 42\n",
    "    target_size = 5\n",
    "    target_col = 'label'\n",
    "    n_fold = 5\n",
    "    trn_fold = [0, 1, 2, 3, 4]\n",
    "    train = True\n",
    "    inference = False\n",
    "    \n",
    "if CFG.debug:\n",
    "    CFG.epochs = 3\n",
    "    train = train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029903,
     "end_time": "2021-01-10T23:58:06.385719",
     "exception": false,
     "start_time": "2021-01-10T23:58:06.355816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:06.474448Z",
     "iopub.status.busy": "2021-01-10T23:58:06.470973Z",
     "iopub.status.idle": "2021-01-10T23:58:11.267751Z",
     "shell.execute_reply": "2021-01-10T23:58:11.269371Z"
    },
    "papermill": {
     "duration": 4.845445,
     "end_time": "2021-01-10T23:58:11.269599",
     "exception": false,
     "start_time": "2021-01-10T23:58:06.424154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "sys.path.append('../input/bi-tempered-loss-pytorch')\n",
    "from bi_tempered_loss import *\n",
    "\n",
    "# sys.path.append('../input/pytorch-optimizer')\n",
    "# import torch_optimizer as optim\n",
    "\n",
    "sys.path.append('../input/pytorch-sam')\n",
    "from sam import SAM\n",
    "\n",
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n",
    ")\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "import timm\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if CFG.apex:\n",
    "    from apex import amp\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044705,
     "end_time": "2021-01-10T23:58:11.368519",
     "exception": false,
     "start_time": "2021-01-10T23:58:11.323814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:11.460674Z",
     "iopub.status.busy": "2021-01-10T23:58:11.459800Z",
     "iopub.status.idle": "2021-01-10T23:58:11.476439Z",
     "shell.execute_reply": "2021-01-10T23:58:11.475746Z"
    },
    "papermill": {
     "duration": 0.068586,
     "end_time": "2021-01-10T23:58:11.476606",
     "exception": false,
     "start_time": "2021-01-10T23:58:11.408020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f}')\n",
    "    \n",
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.063414,
     "end_time": "2021-01-10T23:58:11.583108",
     "exception": false,
     "start_time": "2021-01-10T23:58:11.519694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:11.656989Z",
     "iopub.status.busy": "2021-01-10T23:58:11.656225Z",
     "iopub.status.idle": "2021-01-10T23:58:11.685265Z",
     "shell.execute_reply": "2021-01-10T23:58:11.680653Z"
    },
    "papermill": {
     "duration": 0.071533,
     "end_time": "2021-01-10T23:58:11.685371",
     "exception": false,
     "start_time": "2021-01-10T23:58:11.613838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  label\n",
      "0     0         299\n",
      "      1         695\n",
      "      2         604\n",
      "      3        3092\n",
      "      4         578\n",
      "1     0         299\n",
      "      1         695\n",
      "      2         604\n",
      "      3        3092\n",
      "      4         578\n",
      "2     0         298\n",
      "      1         695\n",
      "      2         603\n",
      "      3        3093\n",
      "      4         578\n",
      "3     0         298\n",
      "      1         695\n",
      "      2         603\n",
      "      3        3093\n",
      "      4         578\n",
      "4     0         298\n",
      "      1         696\n",
      "      2         603\n",
      "      3        3092\n",
      "      4         578\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[CFG.target_col])):\n",
    "    folds.loc[val_index, 'fold'] = int(n)\n",
    "folds['fold'] = folds['fold'].astype(int)\n",
    "print(folds.groupby(['fold', CFG.target_col]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032211,
     "end_time": "2021-01-10T23:58:11.750432",
     "exception": false,
     "start_time": "2021-01-10T23:58:11.718221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:11.828637Z",
     "iopub.status.busy": "2021-01-10T23:58:11.819435Z",
     "iopub.status.idle": "2021-01-10T23:58:11.830779Z",
     "shell.execute_reply": "2021-01-10T23:58:11.831363Z"
    },
    "papermill": {
     "duration": 0.050857,
     "end_time": "2021-01-10T23:58:11.831496",
     "exception": false,
     "start_time": "2021-01-10T23:58:11.780639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_id'].values\n",
    "        self.labels = df['label'].values\n",
    "#         self.labels = pd.get_dummies(df['label']).values  # One Hot Encoding\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f'{TRAIN_PATH}/{file_name}'\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        label = torch.tensor(self.labels[idx]).long()\n",
    "        return image, label\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_id'].values\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f'{TEST_PATH}/{file_name}'\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:11.899221Z",
     "iopub.status.busy": "2021-01-10T23:58:11.898230Z",
     "iopub.status.idle": "2021-01-10T23:58:11.901170Z",
     "shell.execute_reply": "2021-01-10T23:58:11.900604Z"
    },
    "papermill": {
     "duration": 0.036401,
     "end_time": "2021-01-10T23:58:11.901285",
     "exception": false,
     "start_time": "2021-01-10T23:58:11.864884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataset = TrainDataset(train, transform=None)\n",
    "\n",
    "# for i in range(1):\n",
    "#     image, label = train_dataset[i]\n",
    "#     plt.imshow(image)\n",
    "#     plt.title(f'label: {label}')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029426,
     "end_time": "2021-01-10T23:58:11.961373",
     "exception": false,
     "start_time": "2021-01-10T23:58:11.931947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:12.031880Z",
     "iopub.status.busy": "2021-01-10T23:58:12.031089Z",
     "iopub.status.idle": "2021-01-10T23:58:12.034789Z",
     "shell.execute_reply": "2021-01-10T23:58:12.035284Z"
    },
    "papermill": {
     "duration": 0.044666,
     "end_time": "2021-01-10T23:58:12.035417",
     "exception": false,
     "start_time": "2021-01-10T23:58:11.990751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transforms(*, data):\n",
    "    \n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "            RandomResizedCrop(CFG.size, CFG.size), \n",
    "            Transpose(p=0.5), \n",
    "            HorizontalFlip(p=0.5), \n",
    "            VerticalFlip(p=0.5), \n",
    "            ShiftScaleRotate(p=0.5), \n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5), \n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5), \n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "            ), \n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    \n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "            Resize(CFG.size, CFG.size), \n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "            ), \n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:12.102866Z",
     "iopub.status.busy": "2021-01-10T23:58:12.101788Z",
     "iopub.status.idle": "2021-01-10T23:58:12.106159Z",
     "shell.execute_reply": "2021-01-10T23:58:12.105498Z"
    },
    "papermill": {
     "duration": 0.038967,
     "end_time": "2021-01-10T23:58:12.106271",
     "exception": false,
     "start_time": "2021-01-10T23:58:12.067304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataset = TrainDataset(train, transform=get_transforms(data='train'))\n",
    "\n",
    "# for i in range(1):\n",
    "#     image, label = train_dataset[i]\n",
    "#     plt.imshow(image[0])\n",
    "#     plt.title(f'label: {label}')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030386,
     "end_time": "2021-01-10T23:58:12.166780",
     "exception": false,
     "start_time": "2021-01-10T23:58:12.136394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:12.236830Z",
     "iopub.status.busy": "2021-01-10T23:58:12.236135Z",
     "iopub.status.idle": "2021-01-10T23:58:12.239866Z",
     "shell.execute_reply": "2021-01-10T23:58:12.240326Z"
    },
    "papermill": {
     "duration": 0.041461,
     "end_time": "2021-01-10T23:58:12.240447",
     "exception": false,
     "start_time": "2021-01-10T23:58:12.198986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomEfficientNetB4(nn.Module):\n",
    "    def __init__(self, model_name='tf_efficientnet_b4', pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, CFG.target_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:12.306716Z",
     "iopub.status.busy": "2021-01-10T23:58:12.305374Z",
     "iopub.status.idle": "2021-01-10T23:58:12.310538Z",
     "shell.execute_reply": "2021-01-10T23:58:12.309864Z"
    },
    "papermill": {
     "duration": 0.038915,
     "end_time": "2021-01-10T23:58:12.310638",
     "exception": false,
     "start_time": "2021-01-10T23:58:12.271723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = CustomEfficientNetB4(model_name=CFG.model_name, pretrained=False)\n",
    "# train_dataset = TrainDataset(train, transform=get_transforms(data='train'))\n",
    "# train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, \n",
    "#                           num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "# for image, label in train_loader:\n",
    "#     print(image.size())\n",
    "#     output = model(image)\n",
    "#     print(output)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034277,
     "end_time": "2021-01-10T23:58:12.396328",
     "exception": false,
     "start_time": "2021-01-10T23:58:12.362051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:12.467095Z",
     "iopub.status.busy": "2021-01-10T23:58:12.466447Z",
     "iopub.status.idle": "2021-01-10T23:58:12.470817Z",
     "shell.execute_reply": "2021-01-10T23:58:12.470315Z"
    },
    "papermill": {
     "duration": 0.044227,
     "end_time": "2021-01-10T23:58:12.470915",
     "exception": false,
     "start_time": "2021-01-10T23:58:12.426688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Label Smoothing\n",
    "# ====================================================\n",
    "class LabelSmoothingLoss(nn.Module): \n",
    "    def __init__(self, classes=5, smoothing=0.0, dim=-1): \n",
    "        super(LabelSmoothingLoss, self).__init__() \n",
    "        self.confidence = 1.0 - smoothing \n",
    "        self.smoothing = smoothing \n",
    "        self.cls = classes \n",
    "        self.dim = dim \n",
    "    def forward(self, pred, target): \n",
    "        pred = pred.log_softmax(dim=self.dim) \n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred) \n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1)) \n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence) \n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:12.539124Z",
     "iopub.status.busy": "2021-01-10T23:58:12.538349Z",
     "iopub.status.idle": "2021-01-10T23:58:12.542233Z",
     "shell.execute_reply": "2021-01-10T23:58:12.541708Z"
    },
    "papermill": {
     "duration": 0.041186,
     "end_time": "2021-01-10T23:58:12.542361",
     "exception": false,
     "start_time": "2021-01-10T23:58:12.501175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = nn.CrossEntropyLoss()(inputs, targets)\n",
    "\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:12.613077Z",
     "iopub.status.busy": "2021-01-10T23:58:12.611272Z",
     "iopub.status.idle": "2021-01-10T23:58:12.613855Z",
     "shell.execute_reply": "2021-01-10T23:58:12.614337Z"
    },
    "papermill": {
     "duration": 0.043077,
     "end_time": "2021-01-10T23:58:12.614444",
     "exception": false,
     "start_time": "2021-01-10T23:58:12.571367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FocalCosineLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, xent=.1):\n",
    "        super(FocalCosineLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.xent = xent\n",
    "\n",
    "        self.y = torch.Tensor([1]).cuda()\n",
    "\n",
    "    def forward(self, input, target, reduction=\"mean\"):\n",
    "        cosine_loss = F.cosine_embedding_loss(input, F.one_hot(target, num_classes=input.size(-1)), self.y, reduction=reduction)\n",
    "\n",
    "        cent_loss = F.cross_entropy(F.normalize(input), target, reduce=False)\n",
    "        pt = torch.exp(-cent_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * cent_loss\n",
    "\n",
    "        if reduction == \"mean\":\n",
    "            focal_loss = torch.mean(focal_loss)\n",
    "\n",
    "        return cosine_loss + self.xent * focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:12.685202Z",
     "iopub.status.busy": "2021-01-10T23:58:12.683413Z",
     "iopub.status.idle": "2021-01-10T23:58:12.686015Z",
     "shell.execute_reply": "2021-01-10T23:58:12.686492Z"
    },
    "papermill": {
     "duration": 0.042769,
     "end_time": "2021-01-10T23:58:12.686620",
     "exception": false,
     "start_time": "2021-01-10T23:58:12.643851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SymmetricCrossEntropy(nn.Module):\n",
    "\n",
    "    def __init__(self, alpha=0.1, beta=1.0, num_classes=5):\n",
    "        super(SymmetricCrossEntropy, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, logits, targets, reduction='mean'):\n",
    "        onehot_targets = torch.eye(self.num_classes)[targets].cuda()\n",
    "        ce_loss = F.cross_entropy(logits, targets, reduction=reduction)\n",
    "        rce_loss = (-onehot_targets*logits.softmax(1).clamp(1e-7, 1.0).log()).sum(1)\n",
    "        if reduction == 'mean':\n",
    "            rce_loss = rce_loss.mean()\n",
    "        elif reduction == 'sum':\n",
    "            rce_loss = rce_loss.sum()\n",
    "        return self.alpha * ce_loss + self.beta * rce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:12.781772Z",
     "iopub.status.busy": "2021-01-10T23:58:12.759825Z",
     "iopub.status.idle": "2021-01-10T23:58:12.794780Z",
     "shell.execute_reply": "2021-01-10T23:58:12.795294Z"
    },
    "papermill": {
     "duration": 0.078618,
     "end_time": "2021-01-10T23:58:12.795417",
     "exception": false,
     "start_time": "2021-01-10T23:58:12.716799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_t(u, t):\n",
    "    \"\"\"Compute log_t for `u'.\"\"\"\n",
    "    if t==1.0:\n",
    "        return u.log()\n",
    "    else:\n",
    "        return (u.pow(1.0 - t) - 1.0) / (1.0 - t)\n",
    "\n",
    "def exp_t(u, t):\n",
    "    \"\"\"Compute exp_t for `u'.\"\"\"\n",
    "    if t==1:\n",
    "        return u.exp()\n",
    "    else:\n",
    "        return (1.0 + (1.0-t)*u).relu().pow(1.0 / (1.0 - t))\n",
    "\n",
    "def compute_normalization_fixed_point(activations, t, num_iters):\n",
    "\n",
    "    \"\"\"Returns the normalization value for each example (t > 1.0).\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      t: Temperature 2 (> 1.0 for tail heaviness).\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Return: A tensor of same shape as activation with the last dimension being 1.\n",
    "    \"\"\"\n",
    "    mu, _ = torch.max(activations, -1, keepdim=True)\n",
    "    normalized_activations_step_0 = activations - mu\n",
    "\n",
    "    normalized_activations = normalized_activations_step_0\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        logt_partition = torch.sum(\n",
    "                exp_t(normalized_activations, t), -1, keepdim=True)\n",
    "        normalized_activations = normalized_activations_step_0 * \\\n",
    "                logt_partition.pow(1.0-t)\n",
    "\n",
    "    logt_partition = torch.sum(\n",
    "            exp_t(normalized_activations, t), -1, keepdim=True)\n",
    "    normalization_constants = - log_t(1.0 / logt_partition, t) + mu\n",
    "\n",
    "    return normalization_constants\n",
    "\n",
    "def compute_normalization_binary_search(activations, t, num_iters):\n",
    "\n",
    "    \"\"\"Returns the normalization value for each example (t < 1.0).\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      t: Temperature 2 (< 1.0 for finite support).\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Return: A tensor of same rank as activation with the last dimension being 1.\n",
    "    \"\"\"\n",
    "\n",
    "    mu, _ = torch.max(activations, -1, keepdim=True)\n",
    "    normalized_activations = activations - mu\n",
    "\n",
    "    effective_dim = \\\n",
    "        torch.sum(\n",
    "                (normalized_activations > -1.0 / (1.0-t)).to(torch.int32),\n",
    "            dim=-1, keepdim=True).to(activations.dtype)\n",
    "\n",
    "    shape_partition = activations.shape[:-1] + (1,)\n",
    "    lower = torch.zeros(shape_partition, dtype=activations.dtype, device=activations.device)\n",
    "    upper = -log_t(1.0/effective_dim, t) * torch.ones_like(lower)\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        logt_partition = (upper + lower)/2.0\n",
    "        sum_probs = torch.sum(\n",
    "                exp_t(normalized_activations - logt_partition, t),\n",
    "                dim=-1, keepdim=True)\n",
    "        update = (sum_probs < 1.0).to(activations.dtype)\n",
    "        lower = torch.reshape(\n",
    "                lower * update + (1.0-update) * logt_partition,\n",
    "                shape_partition)\n",
    "        upper = torch.reshape(\n",
    "                upper * (1.0 - update) + update * logt_partition,\n",
    "                shape_partition)\n",
    "\n",
    "    logt_partition = (upper + lower)/2.0\n",
    "    return logt_partition + mu\n",
    "\n",
    "class ComputeNormalization(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Class implementing custom backward pass for compute_normalization. See compute_normalization.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, activations, t, num_iters):\n",
    "        if t < 1.0:\n",
    "            normalization_constants = compute_normalization_binary_search(activations, t, num_iters)\n",
    "        else:\n",
    "            normalization_constants = compute_normalization_fixed_point(activations, t, num_iters)\n",
    "\n",
    "        ctx.save_for_backward(activations, normalization_constants)\n",
    "        ctx.t=t\n",
    "        return normalization_constants\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        activations, normalization_constants = ctx.saved_tensors\n",
    "        t = ctx.t\n",
    "        normalized_activations = activations - normalization_constants \n",
    "        probabilities = exp_t(normalized_activations, t)\n",
    "        escorts = probabilities.pow(t)\n",
    "        escorts = escorts / escorts.sum(dim=-1, keepdim=True)\n",
    "        grad_input = escorts * grad_output\n",
    "        \n",
    "        return grad_input, None, None\n",
    "\n",
    "def compute_normalization(activations, t, num_iters=5):\n",
    "    \"\"\"Returns the normalization value for each example. \n",
    "    Backward pass is implemented.\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      t: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Return: A tensor of same rank as activation with the last dimension being 1.\n",
    "    \"\"\"\n",
    "    return ComputeNormalization.apply(activations, t, num_iters)\n",
    "\n",
    "def tempered_sigmoid(activations, t, num_iters = 5):\n",
    "    \"\"\"Tempered sigmoid function.\n",
    "    Args:\n",
    "      activations: Activations for the positive class for binary classification.\n",
    "      t: Temperature tensor > 0.0.\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Returns:\n",
    "      A probabilities tensor.\n",
    "    \"\"\"\n",
    "    internal_activations = torch.stack([activations,\n",
    "        torch.zeros_like(activations)],\n",
    "        dim=-1)\n",
    "    internal_probabilities = tempered_softmax(internal_activations, t, num_iters)\n",
    "    return internal_probabilities[..., 0]\n",
    "\n",
    "\n",
    "def tempered_softmax(activations, t, num_iters=5):\n",
    "    \"\"\"Tempered softmax function.\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      t: Temperature > 1.0.\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Returns:\n",
    "      A probabilities tensor.\n",
    "    \"\"\"\n",
    "    if t == 1.0:\n",
    "        return activations.softmax(dim=-1)\n",
    "\n",
    "    normalization_constants = compute_normalization(activations, t, num_iters)\n",
    "    return exp_t(activations - normalization_constants, t)\n",
    "\n",
    "def bi_tempered_binary_logistic_loss(activations,\n",
    "        labels,\n",
    "        t1,\n",
    "        t2,\n",
    "        label_smoothing = 0.0,\n",
    "        num_iters=5,\n",
    "        reduction='mean'):\n",
    "\n",
    "    \"\"\"Bi-Tempered binary logistic loss.\n",
    "    Args:\n",
    "      activations: A tensor containing activations for class 1.\n",
    "      labels: A tensor with shape as activations, containing probabilities for class 1\n",
    "      t1: Temperature 1 (< 1.0 for boundedness).\n",
    "      t2: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n",
    "      label_smoothing: Label smoothing\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Returns:\n",
    "      A loss tensor.\n",
    "    \"\"\"\n",
    "    internal_activations = torch.stack([activations,\n",
    "        torch.zeros_like(activations)],\n",
    "        dim=-1)\n",
    "    internal_labels = torch.stack([labels.to(activations.dtype),\n",
    "        1.0 - labels.to(activations.dtype)],\n",
    "        dim=-1)\n",
    "    return bi_tempered_logistic_loss(internal_activations, \n",
    "            internal_labels,\n",
    "            t1,\n",
    "            t2,\n",
    "            label_smoothing = label_smoothing,\n",
    "            num_iters = num_iters,\n",
    "            reduction = reduction)\n",
    "\n",
    "def bi_tempered_logistic_loss(activations,\n",
    "        labels,\n",
    "        t1,\n",
    "        t2,\n",
    "        label_smoothing=0.0,\n",
    "        num_iters=5,\n",
    "        reduction = 'mean'):\n",
    "\n",
    "    \"\"\"Bi-Tempered Logistic Loss.\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      labels: A tensor with shape and dtype as activations (onehot), \n",
    "        or a long tensor of one dimension less than activations (pytorch standard)\n",
    "      t1: Temperature 1 (< 1.0 for boundedness).\n",
    "      t2: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n",
    "      label_smoothing: Label smoothing parameter between [0, 1). Default 0.0.\n",
    "      num_iters: Number of iterations to run the method. Default 5.\n",
    "      reduction: ``'none'`` | ``'mean'`` | ``'sum'``. Default ``'mean'``.\n",
    "        ``'none'``: No reduction is applied, return shape is shape of\n",
    "        activations without the last dimension.\n",
    "        ``'mean'``: Loss is averaged over minibatch. Return shape (1,)\n",
    "        ``'sum'``: Loss is summed over minibatch. Return shape (1,)\n",
    "    Returns:\n",
    "      A loss tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(labels.shape)<len(activations.shape): #not one-hot\n",
    "        labels_onehot = torch.zeros_like(activations)\n",
    "        labels_onehot.scatter_(1, labels[..., None], 1)\n",
    "    else:\n",
    "        labels_onehot = labels\n",
    "\n",
    "    if label_smoothing > 0:\n",
    "        num_classes = labels_onehot.shape[-1]\n",
    "        labels_onehot = ( 1 - label_smoothing * num_classes / (num_classes - 1) ) \\\n",
    "                * labels_onehot + \\\n",
    "                label_smoothing / (num_classes - 1)\n",
    "\n",
    "    probabilities = tempered_softmax(activations, t2, num_iters)\n",
    "\n",
    "    loss_values = labels_onehot * log_t(labels_onehot + 1e-10, t1) \\\n",
    "            - labels_onehot * log_t(probabilities, t1) \\\n",
    "            - labels_onehot.pow(2.0 - t1) / (2.0 - t1) \\\n",
    "            + probabilities.pow(2.0 - t1) / (2.0 - t1)\n",
    "    loss_values = loss_values.sum(dim = -1) #sum over classes\n",
    "\n",
    "    if reduction == 'none':\n",
    "        return loss_values\n",
    "    if reduction == 'sum':\n",
    "        return loss_values.sum()\n",
    "    if reduction == 'mean':\n",
    "        return loss_values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:12.862045Z",
     "iopub.status.busy": "2021-01-10T23:58:12.861282Z",
     "iopub.status.idle": "2021-01-10T23:58:12.863641Z",
     "shell.execute_reply": "2021-01-10T23:58:12.864194Z"
    },
    "papermill": {
     "duration": 0.039601,
     "end_time": "2021-01-10T23:58:12.864300",
     "exception": false,
     "start_time": "2021-01-10T23:58:12.824699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BiTemperedLogisticLoss(nn.Module): \n",
    "    def __init__(self, t1, t2, smoothing=0.0): \n",
    "        super(BiTemperedLogisticLoss, self).__init__() \n",
    "        self.t1 = t1\n",
    "        self.t2 = t2\n",
    "        self.smoothing = smoothing\n",
    "    def forward(self, logit_label, truth_label):\n",
    "        loss_label = bi_tempered_logistic_loss(\n",
    "            logit_label, truth_label,\n",
    "            t1=self.t1, t2=self.t2,\n",
    "            label_smoothing=self.smoothing,\n",
    "            reduction='none'\n",
    "        )\n",
    "        \n",
    "        loss_label = loss_label.mean()\n",
    "        return loss_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:12.926573Z",
     "iopub.status.busy": "2021-01-10T23:58:12.925567Z",
     "iopub.status.idle": "2021-01-10T23:58:12.965165Z",
     "shell.execute_reply": "2021-01-10T23:58:12.964712Z"
    },
    "papermill": {
     "duration": 0.071665,
     "end_time": "2021-01-10T23:58:12.965264",
     "exception": false,
     "start_time": "2021-01-10T23:58:12.893599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "def asMinutes(s):\n",
    "    \"\"\"秒を分に変換する関数\"\"\"\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    \"\"\"経過時間の測定と終了時間の予測を行う関数\n",
    "    Parameters\n",
    "    ----------\n",
    "    since : float\n",
    "        実験を始めた時刻\n",
    "    percent : float\n",
    "        実験が進んだ割合\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    s : 経過時間\n",
    "    re : 終了までの時間の予測\n",
    "    \"\"\"\n",
    "    now = time.time()\n",
    "    s = now - since  # 経過時間の測定\n",
    "    es = s / percent  # 終了時間の予測\n",
    "    re = es - s  # 残り時間の予想\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(re))\n",
    "\n",
    "def train_fn(train_loader, model, loss_train, loss_metric, optimizer, epoch, shechduler, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        y_preds = model(images)\n",
    "        metric = loss_metric(y_preds, labels)\n",
    "        loss = loss_train(y_preds, labels)\n",
    "        # record loss\n",
    "        losses.update(metric.item(), batch_size)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        if CFG.apex:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else: \n",
    "            loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            optimizer.first_step(zero_grad=True)\n",
    "#             optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "        # measure elapsed time\n",
    "        loss_train(model(images), labels).backward()\n",
    "#         loss = torch.mean(loss)\n",
    "#         loss.backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "        \n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}]'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})'\n",
    "                  'Elapsed {remain:s}' \n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f})' \n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  .format(epoch+1, step, len(train_loader), batch_time=batch_time, \n",
    "                          data_time=data_time, loss=losses, \n",
    "                          remain=timeSince(start, float(step+1)/len(train_loader)), \n",
    "                          grad_norm=grad_norm))\n",
    "    return losses.avg\n",
    "\n",
    "def valid_fn(valid_loader, model, loss_metric, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (images, labels) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images)\n",
    "        loss = loss_metric(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(\n",
    "                   step, len(valid_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses,\n",
    "                   remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                   ))\n",
    "            \n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions\n",
    "\n",
    "def inference(model, states, test_loader, device):\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    probs = []\n",
    "    for i, (images) in tk0:\n",
    "        images = images.to(device)\n",
    "        avgpreds = []\n",
    "        for state in states:\n",
    "            model.load_state_dict(state['model'])\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "        avg_preds = np.mean(avg_preds, axis=0)\n",
    "        probs.append(avg_preds)\n",
    "    probs = np.concatenate(probs)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029686,
     "end_time": "2021-01-10T23:58:13.024007",
     "exception": false,
     "start_time": "2021-01-10T23:58:12.994321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:13.118522Z",
     "iopub.status.busy": "2021-01-10T23:58:13.108091Z",
     "iopub.status.idle": "2021-01-10T23:58:13.127048Z",
     "shell.execute_reply": "2021-01-10T23:58:13.126483Z"
    },
    "papermill": {
     "duration": 0.073394,
     "end_time": "2021-01-10T23:58:13.127158",
     "exception": false,
     "start_time": "2021-01-10T23:58:13.053764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# Train loop\n",
    "# ======================================================\n",
    "\n",
    "def train_loop(folds, fold):\n",
    "    \n",
    "    seed_torch(seed=CFG.seed)    \n",
    "    \n",
    "    LOGGER.info(f'========== fold: {fold} training ============')\n",
    "    \n",
    "    # ======================================================\n",
    "    # loader\n",
    "    # ======================================================\n",
    "    trn_idx = folds[folds['fold'] != fold].index\n",
    "    val_idx = folds[folds['fold'] == fold].index\n",
    "    \n",
    "    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = TrainDataset(train_folds, \n",
    "                                 transform=get_transforms(data='train'))\n",
    "    valid_dataset = TrainDataset(valid_folds, \n",
    "                                 transform=get_transforms(data='valid'))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, \n",
    "                              batch_size=CFG.batch_size, \n",
    "                              shuffle=True, \n",
    "                              num_workers=CFG.num_workers, \n",
    "                              pin_memory=True, \n",
    "                              drop_last=False)\n",
    "    valid_loader = DataLoader(valid_dataset, \n",
    "                              batch_size=CFG.batch_size, \n",
    "                              shuffle=False, \n",
    "                              num_workers=CFG.num_workers, \n",
    "                              pin_memory=True, \n",
    "                              drop_last=False)\n",
    "    \n",
    "    # ===============================================\n",
    "    # scheduler\n",
    "    # ===============================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler=='ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n",
    "        elif CFG.scheduler=='CosineAnnealingLR':\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        return scheduler\n",
    "    \n",
    "    # ===============================================\n",
    "    # model & optimizer\n",
    "    # ===============================================\n",
    "    model = CustomEfficientNetB4(CFG.model_name, pretrained=True)\n",
    "    \n",
    "    # 最初の3epochはclassifier層以外全て凍結する。\n",
    "    for name, param in model.model.named_parameters():\n",
    "        if 'classifier' not in name:\n",
    "            param.requires_grad=False\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    base_optimizer = Adam\n",
    "    optimizer = SAM(model.parameters(), base_optimizer, lr=CFG.lr_1, weight_decay=CFG.weight_decay, amsgrad=False)\n",
    "    \n",
    "    scheduler = get_scheduler(optimizer)\n",
    "    \n",
    "    # ===============================================\n",
    "    # apex \n",
    "    # ===============================================\n",
    "    if CFG.apex:\n",
    "        model.optimizer = amp.initialize(model, optimizer, opt_level='O1', verbosity=0)\n",
    "        \n",
    "    # ===============================================\n",
    "    # loop\n",
    "    # ===============================================\n",
    "    def get_loss_train():\n",
    "        if CFG.loss_train == 'CrossEntropyLoss':\n",
    "            loss_train = nn.CrossEntropyLoss()\n",
    "        elif CFG.loss_train == 'LabelSmoothing':\n",
    "            loss_train = LabelSmoothingLoss(classes=CFG.target_size, smoothing=CFG.smooth)\n",
    "        elif CFG.loss_train == 'FocalLoss':\n",
    "            loss_train = FocalLoss().to(device)\n",
    "        elif CFG.loss_train == 'FocalCosineLoss':\n",
    "            loss_train = FocalCosineLoss()\n",
    "        elif CFG.loss_train == 'SymmetricCrossEntropyLoss':\n",
    "            loss_train = SymmetricCrossEntropy().to(device)\n",
    "        elif CFG.loss_train == 'BiTemperedLoss':\n",
    "            loss_train = BiTemperedLogisticLoss(t1=CFG.t1, t2=CFG.t2, smoothing=CFG.smooth)\n",
    "        return loss_train\n",
    "    \n",
    "    loss_train = get_loss_train()\n",
    "    LOGGER.info(f'loss_train: {loss_train}')\n",
    "    loss_metric = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_score = 0.\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(CFG.epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        if epoch == 1:\n",
    "            \n",
    "            # 2epoch目に重みを全て解凍する\n",
    "            for param in model.model.parameters():\n",
    "                param.requires_grad = True\n",
    "                \n",
    "            # 学習率を4e-3から4e-4に落とす\n",
    "            base_optimizer = Adam\n",
    "            optimizer = SAM(model.parameters(), base_optimizer, lr=CFG.lr_2, weight_decay=CFG.weight_decay, amsgrad=False)\n",
    "            scheduler = get_scheduler(optimizer)\n",
    "\n",
    "            LOGGER.info('requires_grad of all parameters are unlocked')\n",
    "            \n",
    "        \n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, loss_train, loss_metric, optimizer, epoch, scheduler, device)\n",
    "        \n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, loss_metric, device)\n",
    "        valid_labels = valid_folds[CFG.target_col].values\n",
    "        \n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "        \n",
    "        # scoring\n",
    "        score = get_score(valid_labels, preds.argmax(1))\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f} avg_val_loss: {avg_val_loss:.4f} time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Accuracy: {score}')\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(), \n",
    "                        'preds': preds}, \n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth')\n",
    "            \n",
    "        # inference用に全て保存しておく        \n",
    "        torch.save({'model': model.state_dict()}, OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_epoch{epoch+1}.pth')\n",
    "    \n",
    "    check_point = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth')\n",
    "    valid_folds[[str(c) for c in range(5)]] = check_point['preds']\n",
    "    valid_folds['preds'] = check_point['preds'].argmax(1)\n",
    "    \n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:13.202814Z",
     "iopub.status.busy": "2021-01-10T23:58:13.201901Z",
     "iopub.status.idle": "2021-01-10T23:58:13.205494Z",
     "shell.execute_reply": "2021-01-10T23:58:13.204883Z"
    },
    "papermill": {
     "duration": 0.047985,
     "end_time": "2021-01-10T23:58:13.205590",
     "exception": false,
     "start_time": "2021-01-10T23:58:13.157605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# main\n",
    "# ====================================================\n",
    "def main():\n",
    "    \n",
    "    \"\"\"\n",
    "    Prepare: 1.train 2.test 3.submission 4.folds\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_result(result_df):\n",
    "        preds = result_df['preds'].values\n",
    "        labels = result_df[CFG.target_col].values\n",
    "        score = get_score(labels, preds)\n",
    "        LOGGER.info(f'Score: {score:<.5f}')\n",
    "        \n",
    "    if CFG.train:\n",
    "        # train\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df = train_loop(folds, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                LOGGER.info(f'=============== fold: {fold} result ================')\n",
    "                get_result(_oof_df)\n",
    "                \n",
    "                # 1foldのみを用いる\n",
    "                break\n",
    "                \n",
    "        # CV result\n",
    "        LOGGER.info(f'============ CV ============')\n",
    "        get_result(oof_df)\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)\n",
    "        \n",
    "    if CFG.inference:\n",
    "        # inference\n",
    "        model = CustomEfficientNetB4(CFG.model_name, pretrained=False)\n",
    "        states = [torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth') for fold in CFG.trn_fold]\n",
    "        test_dataset = TestDataset(test, batch_size=CFG.batch_size, shuffle=False, pin_memory=True)\n",
    "        predictions = inference(model, states, test_loader, device)\n",
    "        # submission\n",
    "        test['label'] = predictions.argmax(1)\n",
    "        test[['image_id', 'label']].to_csv(OUTPUT_DIR+'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:13.270297Z",
     "iopub.status.busy": "2021-01-10T23:58:13.269432Z",
     "iopub.status.idle": "2021-01-10T23:58:13.273425Z",
     "shell.execute_reply": "2021-01-10T23:58:13.274056Z"
    },
    "papermill": {
     "duration": 0.038884,
     "end_time": "2021-01-10T23:58:13.274174",
     "exception": false,
     "start_time": "2021-01-10T23:58:13.235290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "used device: cuda\n"
     ]
    }
   ],
   "source": [
    "LOGGER.info(f'used device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:58:13.343717Z",
     "iopub.status.busy": "2021-01-10T23:58:13.342094Z",
     "iopub.status.idle": "2021-01-11T06:10:27.285500Z",
     "shell.execute_reply": "2021-01-11T06:10:27.284944Z"
    },
    "papermill": {
     "duration": 22333.981001,
     "end_time": "2021-01-11T06:10:27.285626",
     "exception": false,
     "start_time": "2021-01-10T23:58:13.304625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ============\n",
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b4_aa-818f208c.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_b4_aa-818f208c.pth\n",
      "loss_train: BiTemperedLogisticLoss()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2634]Data 1.064 (1.064)Elapsed 0m 2s (remain 99m 13s)Loss: 1.5837(1.5837)Grad: 0.9534  \n",
      "Epoch: [1][100/2634]Data 0.000 (0.011)Elapsed 0m 26s (remain 11m 16s)Loss: 0.9028(1.3223)Grad: 0.6628  \n",
      "Epoch: [1][200/2634]Data 0.000 (0.006)Elapsed 0m 52s (remain 10m 33s)Loss: 1.9268(1.3535)Grad: 0.6286  \n",
      "Epoch: [1][300/2634]Data 0.000 (0.004)Elapsed 1m 17s (remain 9m 58s)Loss: 2.7716(1.3519)Grad: 0.8505  \n",
      "Epoch: [1][400/2634]Data 0.000 (0.004)Elapsed 1m 42s (remain 9m 29s)Loss: 0.3533(1.3059)Grad: 0.4591  \n",
      "Epoch: [1][500/2634]Data 0.000 (0.003)Elapsed 2m 7s (remain 9m 4s)Loss: 1.9753(1.3117)Grad: 0.6514  \n",
      "Epoch: [1][600/2634]Data 0.000 (0.003)Elapsed 2m 33s (remain 8m 37s)Loss: 1.2813(1.2996)Grad: 0.6422  \n",
      "Epoch: [1][700/2634]Data 0.000 (0.002)Elapsed 2m 58s (remain 8m 11s)Loss: 0.4431(1.2720)Grad: 0.5714  \n",
      "Epoch: [1][800/2634]Data 0.003 (0.002)Elapsed 3m 23s (remain 7m 44s)Loss: 0.9482(1.2556)Grad: 0.5671  \n",
      "Epoch: [1][900/2634]Data 0.000 (0.002)Elapsed 3m 48s (remain 7m 19s)Loss: 1.1248(1.2407)Grad: 0.4976  \n",
      "Epoch: [1][1000/2634]Data 0.000 (0.002)Elapsed 4m 13s (remain 6m 54s)Loss: 1.5165(1.2322)Grad: 0.7109  \n",
      "Epoch: [1][1100/2634]Data 0.000 (0.002)Elapsed 4m 38s (remain 6m 27s)Loss: 0.6863(1.2173)Grad: 0.5455  \n",
      "Epoch: [1][1200/2634]Data 0.000 (0.002)Elapsed 5m 4s (remain 6m 2s)Loss: 1.6736(1.2060)Grad: 0.5280  \n",
      "Epoch: [1][1300/2634]Data 0.000 (0.002)Elapsed 5m 29s (remain 5m 37s)Loss: 2.5656(1.1970)Grad: 0.7959  \n",
      "Epoch: [1][1400/2634]Data 0.000 (0.002)Elapsed 5m 54s (remain 5m 12s)Loss: 0.9477(1.1821)Grad: 0.6243  \n",
      "Epoch: [1][1500/2634]Data 0.000 (0.002)Elapsed 6m 19s (remain 4m 46s)Loss: 1.1343(1.1718)Grad: 0.5885  \n",
      "Epoch: [1][1600/2634]Data 0.011 (0.001)Elapsed 6m 44s (remain 4m 20s)Loss: 1.2468(1.1647)Grad: 0.7667  \n",
      "Epoch: [1][1700/2634]Data 0.000 (0.001)Elapsed 7m 9s (remain 3m 55s)Loss: 0.1673(1.1556)Grad: 0.4289  \n",
      "Epoch: [1][1800/2634]Data 0.000 (0.001)Elapsed 7m 34s (remain 3m 30s)Loss: 0.8713(1.1455)Grad: 0.5490  \n",
      "Epoch: [1][1900/2634]Data 0.000 (0.001)Elapsed 8m 0s (remain 3m 5s)Loss: 2.4437(1.1365)Grad: 0.8045  \n",
      "Epoch: [1][2000/2634]Data 0.000 (0.001)Elapsed 8m 24s (remain 2m 39s)Loss: 0.8001(1.1339)Grad: 0.6011  \n",
      "Epoch: [1][2100/2634]Data 0.000 (0.001)Elapsed 8m 50s (remain 2m 14s)Loss: 0.7492(1.1239)Grad: 0.5069  \n",
      "Epoch: [1][2200/2634]Data 0.000 (0.001)Elapsed 9m 14s (remain 1m 49s)Loss: 0.8345(1.1213)Grad: 0.5717  \n",
      "Epoch: [1][2300/2634]Data 0.000 (0.001)Elapsed 9m 39s (remain 1m 23s)Loss: 0.7234(1.1173)Grad: 0.6480  \n",
      "Epoch: [1][2400/2634]Data 0.004 (0.001)Elapsed 10m 5s (remain 0m 58s)Loss: 1.4733(1.1108)Grad: 0.6716  \n",
      "Epoch: [1][2500/2634]Data 0.000 (0.001)Elapsed 10m 30s (remain 0m 33s)Loss: 0.9205(1.1106)Grad: 0.4967  \n",
      "Epoch: [1][2600/2634]Data 0.000 (0.001)Elapsed 10m 55s (remain 0m 8s)Loss: 0.2376(1.1053)Grad: 0.5899  \n",
      "Epoch: [1][2633/2634]Data 0.000 (0.001)Elapsed 11m 3s (remain 0m 0s)Loss: 1.0076(1.1068)Grad: 0.7253  \n",
      "EVAL: [0/659] Data 0.703 (0.703) Elapsed 0m 0s (remain 9m 0s) Loss: 0.4467(0.4467) \n",
      "EVAL: [100/659] Data 0.082 (0.032) Elapsed 0m 14s (remain 1m 22s) Loss: 0.5023(0.7769) \n",
      "EVAL: [200/659] Data 0.003 (0.027) Elapsed 0m 29s (remain 1m 6s) Loss: 0.8139(0.8041) \n",
      "EVAL: [300/659] Data 0.000 (0.026) Elapsed 0m 44s (remain 0m 52s) Loss: 0.3225(0.7912) \n",
      "EVAL: [400/659] Data 0.000 (0.026) Elapsed 0m 58s (remain 0m 37s) Loss: 1.7591(0.8160) \n",
      "EVAL: [500/659] Data 0.081 (0.025) Elapsed 1m 11s (remain 0m 22s) Loss: 0.9595(0.8220) \n",
      "EVAL: [600/659] Data 0.000 (0.024) Elapsed 1m 25s (remain 0m 8s) Loss: 0.6464(0.8341) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 1.1068 avg_val_loss: 0.8469 time: 757s\n",
      "Epoch 1 - Accuracy: 0.7004555808656037\n",
      "Epoch 1 - Save Best Score: 0.7005 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [658/659] Data 0.000 (0.023) Elapsed 1m 32s (remain 0m 0s) Loss: 0.4768(0.8469) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "requires_grad of all parameters are unlocked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2634]Data 0.850 (0.850)Elapsed 0m 2s (remain 95m 26s)Loss: 0.4384(0.4384)Grad: 3.3906  \n",
      "Epoch: [2][100/2634]Data 0.000 (0.009)Elapsed 1m 31s (remain 38m 10s)Loss: 0.3982(0.8872)Grad: 2.0703  \n",
      "Epoch: [2][200/2634]Data 0.000 (0.004)Elapsed 2m 59s (remain 36m 10s)Loss: 0.2906(0.8710)Grad: 2.8489  \n",
      "Epoch: [2][300/2634]Data 0.000 (0.003)Elapsed 4m 27s (remain 34m 33s)Loss: 0.8445(0.8336)Grad: 3.1267  \n",
      "Epoch: [2][400/2634]Data 0.000 (0.002)Elapsed 5m 55s (remain 32m 57s)Loss: 0.5463(0.8300)Grad: 3.3220  \n",
      "Epoch: [2][500/2634]Data 0.000 (0.002)Elapsed 7m 23s (remain 31m 28s)Loss: 0.6203(0.8126)Grad: 2.4220  \n",
      "Epoch: [2][600/2634]Data 0.000 (0.002)Elapsed 8m 51s (remain 29m 58s)Loss: 0.2821(0.8155)Grad: 2.7108  \n",
      "Epoch: [2][700/2634]Data 0.000 (0.001)Elapsed 10m 19s (remain 28m 28s)Loss: 0.1368(0.8111)Grad: 2.1627  \n",
      "Epoch: [2][800/2634]Data 0.000 (0.001)Elapsed 11m 47s (remain 26m 58s)Loss: 0.7535(0.8093)Grad: 3.4360  \n",
      "Epoch: [2][900/2634]Data 0.000 (0.001)Elapsed 13m 14s (remain 25m 29s)Loss: 0.2144(0.8022)Grad: 2.7314  \n",
      "Epoch: [2][1000/2634]Data 0.000 (0.001)Elapsed 14m 42s (remain 23m 59s)Loss: 0.2405(0.7904)Grad: 2.0062  \n",
      "Epoch: [2][1100/2634]Data 0.000 (0.001)Elapsed 16m 9s (remain 22m 30s)Loss: 0.1663(0.7785)Grad: 2.8023  \n",
      "Epoch: [2][1200/2634]Data 0.000 (0.001)Elapsed 17m 37s (remain 21m 1s)Loss: 0.4194(0.7736)Grad: 1.8810  \n",
      "Epoch: [2][1300/2634]Data 0.000 (0.001)Elapsed 19m 4s (remain 19m 32s)Loss: 0.7337(0.7595)Grad: 3.2542  \n",
      "Epoch: [2][1400/2634]Data 0.000 (0.001)Elapsed 20m 32s (remain 18m 4s)Loss: 0.8271(0.7588)Grad: 2.7020  \n",
      "Epoch: [2][1500/2634]Data 0.000 (0.001)Elapsed 21m 59s (remain 16m 36s)Loss: 0.4548(0.7501)Grad: 1.9470  \n",
      "Epoch: [2][1600/2634]Data 0.000 (0.001)Elapsed 23m 27s (remain 15m 8s)Loss: 1.5256(0.7462)Grad: 1.8223  \n",
      "Epoch: [2][1700/2634]Data 0.000 (0.001)Elapsed 24m 54s (remain 13m 39s)Loss: 0.3511(0.7463)Grad: 2.9375  \n",
      "Epoch: [2][1800/2634]Data 0.000 (0.001)Elapsed 26m 22s (remain 12m 11s)Loss: 0.4646(0.7477)Grad: 2.0813  \n",
      "Epoch: [2][1900/2634]Data 0.000 (0.001)Elapsed 27m 49s (remain 10m 43s)Loss: 2.9040(0.7452)Grad: 1.9820  \n",
      "Epoch: [2][2000/2634]Data 0.000 (0.001)Elapsed 29m 17s (remain 9m 15s)Loss: 0.0930(0.7461)Grad: 1.5318  \n",
      "Epoch: [2][2100/2634]Data 0.000 (0.001)Elapsed 30m 44s (remain 7m 47s)Loss: 1.6096(0.7427)Grad: 2.5128  \n",
      "Epoch: [2][2200/2634]Data 0.000 (0.001)Elapsed 32m 11s (remain 6m 20s)Loss: 0.7056(0.7386)Grad: 3.0161  \n",
      "Epoch: [2][2300/2634]Data 0.000 (0.001)Elapsed 33m 39s (remain 4m 52s)Loss: 0.1498(0.7378)Grad: 1.6044  \n",
      "Epoch: [2][2400/2634]Data 0.000 (0.001)Elapsed 35m 6s (remain 3m 24s)Loss: 0.6314(0.7356)Grad: 2.8319  \n",
      "Epoch: [2][2500/2634]Data 0.000 (0.000)Elapsed 36m 34s (remain 1m 56s)Loss: 1.5222(0.7302)Grad: 2.8369  \n",
      "Epoch: [2][2600/2634]Data 0.000 (0.000)Elapsed 38m 2s (remain 0m 28s)Loss: 2.3267(0.7257)Grad: 2.6760  \n",
      "Epoch: [2][2633/2634]Data 0.000 (0.000)Elapsed 38m 31s (remain 0m 0s)Loss: 0.0523(0.7233)Grad: 1.7002  \n",
      "EVAL: [0/659] Data 0.632 (0.632) Elapsed 0m 0s (remain 8m 22s) Loss: 0.5279(0.5279) \n",
      "EVAL: [100/659] Data 0.024 (0.017) Elapsed 0m 14s (remain 1m 18s) Loss: 0.1291(0.4884) \n",
      "EVAL: [200/659] Data 0.000 (0.013) Elapsed 0m 27s (remain 1m 2s) Loss: 0.2553(0.5096) \n",
      "EVAL: [300/659] Data 0.002 (0.014) Elapsed 0m 42s (remain 0m 49s) Loss: 0.3492(0.4991) \n",
      "EVAL: [400/659] Data 0.005 (0.012) Elapsed 0m 55s (remain 0m 35s) Loss: 0.2456(0.5236) \n",
      "EVAL: [500/659] Data 0.000 (0.012) Elapsed 1m 8s (remain 0m 21s) Loss: 0.3789(0.5241) \n",
      "EVAL: [600/659] Data 0.000 (0.011) Elapsed 1m 21s (remain 0m 7s) Loss: 0.0382(0.5264) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.7233 avg_val_loss: 0.5287 time: 2400s\n",
      "Epoch 2 - Accuracy: 0.8536446469248291\n",
      "Epoch 2 - Save Best Score: 0.8536 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [658/659] Data 0.000 (0.010) Elapsed 1m 28s (remain 0m 0s) Loss: 0.0927(0.5287) \n",
      "Epoch: [3][0/2634]Data 0.775 (0.775)Elapsed 0m 1s (remain 83m 42s)Loss: 0.2348(0.2348)Grad: 2.1966  \n",
      "Epoch: [3][100/2634]Data 0.000 (0.008)Elapsed 1m 30s (remain 37m 48s)Loss: 0.2093(0.6099)Grad: 2.0286  \n",
      "Epoch: [3][200/2634]Data 0.000 (0.004)Elapsed 2m 58s (remain 35m 55s)Loss: 0.1818(0.6354)Grad: 1.7682  \n",
      "Epoch: [3][300/2634]Data 0.000 (0.003)Elapsed 4m 25s (remain 34m 21s)Loss: 0.4734(0.6667)Grad: 1.3066  \n",
      "Epoch: [3][400/2634]Data 0.000 (0.002)Elapsed 5m 53s (remain 32m 49s)Loss: 0.2535(0.6614)Grad: 1.5637  \n",
      "Epoch: [3][500/2634]Data 0.000 (0.002)Elapsed 7m 21s (remain 31m 21s)Loss: 2.3913(0.6329)Grad: 1.9378  \n",
      "Epoch: [3][600/2634]Data 0.000 (0.001)Elapsed 8m 49s (remain 29m 52s)Loss: 0.1786(0.6238)Grad: 1.4386  \n",
      "Epoch: [3][700/2634]Data 0.000 (0.001)Elapsed 10m 18s (remain 28m 24s)Loss: 0.6997(0.6333)Grad: 0.9872  \n",
      "Epoch: [3][800/2634]Data 0.000 (0.001)Elapsed 11m 46s (remain 26m 56s)Loss: 0.1144(0.6280)Grad: 2.0384  \n",
      "Epoch: [3][900/2634]Data 0.000 (0.001)Elapsed 13m 14s (remain 25m 28s)Loss: 0.3449(0.6349)Grad: 3.0500  \n",
      "Epoch: [3][1000/2634]Data 0.000 (0.001)Elapsed 14m 42s (remain 24m 0s)Loss: 0.8245(0.6293)Grad: 3.0905  \n",
      "Epoch: [3][1100/2634]Data 0.000 (0.001)Elapsed 16m 11s (remain 22m 32s)Loss: 0.0309(0.6235)Grad: 0.7862  \n",
      "Epoch: [3][1200/2634]Data 0.000 (0.001)Elapsed 17m 39s (remain 21m 4s)Loss: 0.3410(0.6209)Grad: 4.0884  \n",
      "Epoch: [3][1300/2634]Data 0.000 (0.001)Elapsed 19m 7s (remain 19m 35s)Loss: 4.3058(0.6269)Grad: 4.3326  \n",
      "Epoch: [3][1400/2634]Data 0.000 (0.001)Elapsed 20m 35s (remain 18m 7s)Loss: 0.6196(0.6271)Grad: 2.7778  \n",
      "Epoch: [3][1500/2634]Data 0.000 (0.001)Elapsed 22m 3s (remain 16m 38s)Loss: 0.5124(0.6311)Grad: 1.6403  \n",
      "Epoch: [3][1600/2634]Data 0.000 (0.001)Elapsed 23m 30s (remain 15m 10s)Loss: 0.1014(0.6336)Grad: 1.2989  \n",
      "Epoch: [3][1700/2634]Data 0.000 (0.001)Elapsed 24m 58s (remain 13m 41s)Loss: 0.9745(0.6310)Grad: 2.3658  \n",
      "Epoch: [3][1800/2634]Data 0.000 (0.001)Elapsed 26m 26s (remain 12m 13s)Loss: 0.1771(0.6295)Grad: 2.0437  \n",
      "Epoch: [3][1900/2634]Data 0.000 (0.001)Elapsed 27m 53s (remain 10m 45s)Loss: 0.6964(0.6331)Grad: 1.6379  \n",
      "Epoch: [3][2000/2634]Data 0.000 (0.001)Elapsed 29m 22s (remain 9m 17s)Loss: 0.0214(0.6366)Grad: 0.6714  \n",
      "Epoch: [3][2100/2634]Data 0.000 (0.001)Elapsed 30m 50s (remain 7m 49s)Loss: 0.9301(0.6349)Grad: 1.5793  \n",
      "Epoch: [3][2200/2634]Data 0.000 (0.001)Elapsed 32m 19s (remain 6m 21s)Loss: 0.5698(0.6299)Grad: 2.1598  \n",
      "Epoch: [3][2300/2634]Data 0.000 (0.001)Elapsed 33m 47s (remain 4m 53s)Loss: 0.7847(0.6288)Grad: 2.0478  \n",
      "Epoch: [3][2400/2634]Data 0.000 (0.000)Elapsed 35m 15s (remain 3m 25s)Loss: 0.1071(0.6263)Grad: 1.2122  \n",
      "Epoch: [3][2500/2634]Data 0.000 (0.000)Elapsed 36m 42s (remain 1m 57s)Loss: 0.7564(0.6249)Grad: 1.9755  \n",
      "Epoch: [3][2600/2634]Data 0.000 (0.000)Elapsed 38m 10s (remain 0m 29s)Loss: 0.2902(0.6254)Grad: 1.4931  \n",
      "Epoch: [3][2633/2634]Data 0.000 (0.000)Elapsed 38m 39s (remain 0m 0s)Loss: 1.1921(0.6234)Grad: 2.7496  \n",
      "EVAL: [0/659] Data 0.519 (0.519) Elapsed 0m 0s (remain 7m 20s) Loss: 0.7941(0.7941) \n",
      "EVAL: [100/659] Data 0.000 (0.019) Elapsed 0m 13s (remain 1m 14s) Loss: 0.0892(0.5343) \n",
      "EVAL: [200/659] Data 0.000 (0.017) Elapsed 0m 27s (remain 1m 2s) Loss: 0.2998(0.5412) \n",
      "EVAL: [300/659] Data 0.003 (0.015) Elapsed 0m 40s (remain 0m 48s) Loss: 0.1452(0.5094) \n",
      "EVAL: [400/659] Data 0.000 (0.014) Elapsed 0m 54s (remain 0m 35s) Loss: 0.7329(0.5244) \n",
      "EVAL: [500/659] Data 0.000 (0.013) Elapsed 1m 7s (remain 0m 21s) Loss: 0.3513(0.5148) \n",
      "EVAL: [600/659] Data 0.000 (0.011) Elapsed 1m 19s (remain 0m 7s) Loss: 0.0045(0.5226) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6234 avg_val_loss: 0.5271 time: 2407s\n",
      "Epoch 3 - Accuracy: 0.8694001518602885\n",
      "Epoch 3 - Save Best Score: 0.8694 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [658/659] Data 0.000 (0.010) Elapsed 1m 27s (remain 0m 0s) Loss: 0.0191(0.5271) \n",
      "Epoch: [4][0/2634]Data 0.962 (0.962)Elapsed 0m 2s (remain 95m 17s)Loss: 1.7458(1.7458)Grad: 2.0456  \n",
      "Epoch: [4][100/2634]Data 0.000 (0.010)Elapsed 1m 29s (remain 37m 26s)Loss: 0.1062(0.5984)Grad: 1.8509  \n",
      "Epoch: [4][200/2634]Data 0.000 (0.005)Elapsed 2m 56s (remain 35m 39s)Loss: 0.4912(0.6204)Grad: 1.6418  \n",
      "Epoch: [4][300/2634]Data 0.000 (0.003)Elapsed 4m 24s (remain 34m 8s)Loss: 0.8792(0.5936)Grad: 2.9311  \n",
      "Epoch: [4][400/2634]Data 0.000 (0.003)Elapsed 5m 51s (remain 32m 37s)Loss: 0.5677(0.5743)Grad: 2.0813  \n",
      "Epoch: [4][500/2634]Data 0.000 (0.002)Elapsed 7m 18s (remain 31m 8s)Loss: 0.0746(0.5776)Grad: 1.7968  \n",
      "Epoch: [4][600/2634]Data 0.000 (0.002)Elapsed 8m 45s (remain 29m 38s)Loss: 0.3970(0.5776)Grad: 2.6312  \n",
      "Epoch: [4][700/2634]Data 0.000 (0.002)Elapsed 10m 13s (remain 28m 12s)Loss: 1.6309(0.5815)Grad: 2.3574  \n",
      "Epoch: [4][800/2634]Data 0.000 (0.001)Elapsed 11m 41s (remain 26m 45s)Loss: 5.1340(0.5805)Grad: 2.3103  \n",
      "Epoch: [4][900/2634]Data 0.000 (0.001)Elapsed 13m 9s (remain 25m 17s)Loss: 0.7156(0.5644)Grad: 2.0905  \n",
      "Epoch: [4][1000/2634]Data 0.000 (0.001)Elapsed 14m 36s (remain 23m 49s)Loss: 0.4509(0.5783)Grad: 1.5525  \n",
      "Epoch: [4][1100/2634]Data 0.000 (0.001)Elapsed 16m 3s (remain 22m 21s)Loss: 2.6236(0.5803)Grad: 1.7660  \n",
      "Epoch: [4][1200/2634]Data 0.000 (0.001)Elapsed 17m 30s (remain 20m 53s)Loss: 0.3688(0.5863)Grad: 2.3351  \n",
      "Epoch: [4][1300/2634]Data 0.000 (0.001)Elapsed 18m 57s (remain 19m 25s)Loss: 0.1835(0.5802)Grad: 1.8534  \n",
      "Epoch: [4][1400/2634]Data 0.000 (0.001)Elapsed 20m 25s (remain 17m 58s)Loss: 0.0104(0.5757)Grad: 0.4289  \n",
      "Epoch: [4][1500/2634]Data 0.000 (0.001)Elapsed 21m 52s (remain 16m 30s)Loss: 0.8218(0.5728)Grad: 2.5065  \n",
      "Epoch: [4][1600/2634]Data 0.000 (0.001)Elapsed 23m 20s (remain 15m 3s)Loss: 0.6015(0.5851)Grad: 2.3232  \n",
      "Epoch: [4][1700/2634]Data 0.000 (0.001)Elapsed 24m 48s (remain 13m 36s)Loss: 0.0531(0.5873)Grad: 1.2004  \n",
      "Epoch: [4][1800/2634]Data 0.000 (0.001)Elapsed 26m 15s (remain 12m 8s)Loss: 1.7119(0.5919)Grad: 2.1252  \n",
      "Epoch: [4][1900/2634]Data 0.000 (0.001)Elapsed 27m 42s (remain 10m 41s)Loss: 0.0121(0.5918)Grad: 0.4803  \n",
      "Epoch: [4][2000/2634]Data 0.000 (0.001)Elapsed 29m 10s (remain 9m 13s)Loss: 0.1759(0.5912)Grad: 2.1327  \n",
      "Epoch: [4][2100/2634]Data 0.000 (0.001)Elapsed 30m 37s (remain 7m 46s)Loss: 0.0015(0.5878)Grad: 0.2330  \n",
      "Epoch: [4][2200/2634]Data 0.001 (0.001)Elapsed 32m 5s (remain 6m 18s)Loss: 1.3164(0.5890)Grad: 1.8211  \n",
      "Epoch: [4][2300/2634]Data 0.000 (0.001)Elapsed 33m 32s (remain 4m 51s)Loss: 0.8146(0.5893)Grad: 0.7450  \n",
      "Epoch: [4][2400/2634]Data 0.000 (0.001)Elapsed 35m 0s (remain 3m 23s)Loss: 0.2024(0.5879)Grad: 1.6675  \n",
      "Epoch: [4][2500/2634]Data 0.000 (0.001)Elapsed 36m 28s (remain 1m 56s)Loss: 0.1018(0.5899)Grad: 1.6073  \n",
      "Epoch: [4][2600/2634]Data 0.000 (0.001)Elapsed 37m 55s (remain 0m 28s)Loss: 1.2793(0.5885)Grad: 1.3214  \n",
      "Epoch: [4][2633/2634]Data 0.000 (0.001)Elapsed 38m 24s (remain 0m 0s)Loss: 0.0985(0.5892)Grad: 1.6736  \n",
      "EVAL: [0/659] Data 0.724 (0.724) Elapsed 0m 0s (remain 9m 10s) Loss: 0.8274(0.8274) \n",
      "EVAL: [100/659] Data 0.144 (0.024) Elapsed 0m 14s (remain 1m 22s) Loss: 0.0971(0.5778) \n",
      "EVAL: [200/659] Data 0.068 (0.020) Elapsed 0m 28s (remain 1m 4s) Loss: 0.2806(0.5674) \n",
      "EVAL: [300/659] Data 0.105 (0.017) Elapsed 0m 43s (remain 0m 51s) Loss: 0.0816(0.5465) \n",
      "EVAL: [400/659] Data 0.003 (0.015) Elapsed 0m 56s (remain 0m 36s) Loss: 0.5021(0.5514) \n",
      "EVAL: [500/659] Data 0.001 (0.015) Elapsed 1m 10s (remain 0m 22s) Loss: 0.4645(0.5394) \n",
      "EVAL: [600/659] Data 0.000 (0.014) Elapsed 1m 23s (remain 0m 8s) Loss: 0.0097(0.5408) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.5892 avg_val_loss: 0.5509 time: 2395s\n",
      "Epoch 4 - Accuracy: 0.8794608959757023\n",
      "Epoch 4 - Save Best Score: 0.8795 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [658/659] Data 0.000 (0.012) Elapsed 1m 30s (remain 0m 0s) Loss: 0.0052(0.5509) \n",
      "Epoch: [5][0/2634]Data 1.051 (1.051)Elapsed 0m 2s (remain 109m 11s)Loss: 0.4165(0.4165)Grad: 2.0677  \n",
      "Epoch: [5][100/2634]Data 0.000 (0.011)Elapsed 1m 30s (remain 37m 48s)Loss: 1.1305(0.6024)Grad: 1.4010  \n",
      "Epoch: [5][200/2634]Data 0.000 (0.005)Elapsed 2m 57s (remain 35m 52s)Loss: 2.0641(0.5824)Grad: 2.0924  \n",
      "Epoch: [5][300/2634]Data 0.000 (0.004)Elapsed 4m 25s (remain 34m 17s)Loss: 0.5344(0.5597)Grad: 2.5781  \n",
      "Epoch: [5][400/2634]Data 0.000 (0.003)Elapsed 5m 53s (remain 32m 47s)Loss: 0.2003(0.5399)Grad: 1.7019  \n",
      "Epoch: [5][500/2634]Data 0.000 (0.002)Elapsed 7m 20s (remain 31m 16s)Loss: 0.0790(0.5429)Grad: 1.0205  \n",
      "Epoch: [5][600/2634]Data 0.000 (0.002)Elapsed 8m 47s (remain 29m 45s)Loss: 1.3706(0.5717)Grad: 1.0275  \n",
      "Epoch: [5][700/2634]Data 0.000 (0.002)Elapsed 10m 15s (remain 28m 17s)Loss: 0.3364(0.5613)Grad: 1.5569  \n",
      "Epoch: [5][800/2634]Data 0.000 (0.001)Elapsed 11m 43s (remain 26m 49s)Loss: 0.3377(0.5535)Grad: 1.5189  \n",
      "Epoch: [5][900/2634]Data 0.000 (0.001)Elapsed 13m 11s (remain 25m 21s)Loss: 0.0795(0.5492)Grad: 0.9204  \n",
      "Epoch: [5][1000/2634]Data 0.000 (0.001)Elapsed 14m 38s (remain 23m 53s)Loss: 0.0651(0.5435)Grad: 1.4212  \n",
      "Epoch: [5][1100/2634]Data 0.000 (0.001)Elapsed 16m 5s (remain 22m 25s)Loss: 1.0522(0.5566)Grad: 2.1941  \n",
      "Epoch: [5][1200/2634]Data 0.000 (0.001)Elapsed 17m 33s (remain 20m 57s)Loss: 0.7320(0.5617)Grad: 1.4122  \n",
      "Epoch: [5][1300/2634]Data 0.000 (0.001)Elapsed 19m 1s (remain 19m 29s)Loss: 1.1770(0.5569)Grad: 2.4975  \n",
      "Epoch: [5][1400/2634]Data 0.000 (0.001)Elapsed 20m 29s (remain 18m 2s)Loss: 0.2143(0.5576)Grad: 1.8191  \n",
      "Epoch: [5][1500/2634]Data 0.000 (0.001)Elapsed 21m 58s (remain 16m 35s)Loss: 0.1676(0.5584)Grad: 1.5701  \n",
      "Epoch: [5][1600/2634]Data 0.000 (0.001)Elapsed 23m 26s (remain 15m 7s)Loss: 0.5948(0.5526)Grad: 2.3990  \n",
      "Epoch: [5][1700/2634]Data 0.000 (0.001)Elapsed 24m 54s (remain 13m 39s)Loss: 0.9401(0.5507)Grad: 1.1339  \n",
      "Epoch: [5][1800/2634]Data 0.000 (0.001)Elapsed 26m 23s (remain 12m 12s)Loss: 0.1372(0.5632)Grad: 2.7689  \n",
      "Epoch: [5][1900/2634]Data 0.000 (0.001)Elapsed 27m 52s (remain 10m 44s)Loss: 0.0752(0.5708)Grad: 1.3310  \n",
      "Epoch: [5][2000/2634]Data 0.000 (0.001)Elapsed 29m 21s (remain 9m 17s)Loss: 1.5901(0.5651)Grad: 1.9473  \n",
      "Epoch: [5][2100/2634]Data 0.000 (0.001)Elapsed 30m 49s (remain 7m 49s)Loss: 3.0659(0.5684)Grad: 1.1897  \n",
      "Epoch: [5][2200/2634]Data 0.000 (0.001)Elapsed 32m 17s (remain 6m 21s)Loss: 0.0433(0.5705)Grad: 1.0079  \n",
      "Epoch: [5][2300/2634]Data 0.000 (0.001)Elapsed 33m 45s (remain 4m 53s)Loss: 0.0850(0.5676)Grad: 0.9636  \n",
      "Epoch: [5][2400/2634]Data 0.000 (0.001)Elapsed 35m 12s (remain 3m 25s)Loss: 0.1261(0.5698)Grad: 1.3116  \n",
      "Epoch: [5][2500/2634]Data 0.000 (0.001)Elapsed 36m 40s (remain 1m 56s)Loss: 0.1232(0.5655)Grad: 1.2225  \n",
      "Epoch: [5][2600/2634]Data 0.000 (0.001)Elapsed 38m 7s (remain 0m 29s)Loss: 0.4906(0.5658)Grad: 2.6578  \n",
      "Epoch: [5][2633/2634]Data 0.000 (0.001)Elapsed 38m 36s (remain 0m 0s)Loss: 0.6452(0.5634)Grad: 3.2234  \n",
      "EVAL: [0/659] Data 0.715 (0.715) Elapsed 0m 0s (remain 8m 56s) Loss: 0.8023(0.8023) \n",
      "EVAL: [100/659] Data 0.000 (0.014) Elapsed 0m 13s (remain 1m 14s) Loss: 0.2286(0.4902) \n",
      "EVAL: [200/659] Data 0.004 (0.015) Elapsed 0m 29s (remain 1m 6s) Loss: 0.1623(0.5059) \n",
      "EVAL: [300/659] Data 0.000 (0.015) Elapsed 0m 43s (remain 0m 51s) Loss: 0.5179(0.4877) \n",
      "EVAL: [400/659] Data 0.000 (0.013) Elapsed 0m 57s (remain 0m 36s) Loss: 0.4610(0.5012) \n",
      "EVAL: [500/659] Data 0.000 (0.013) Elapsed 1m 10s (remain 0m 22s) Loss: 0.1232(0.4972) \n",
      "EVAL: [600/659] Data 0.000 (0.012) Elapsed 1m 24s (remain 0m 8s) Loss: 0.0045(0.5065) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.5634 avg_val_loss: 0.5072 time: 2410s\n",
      "Epoch 5 - Accuracy: 0.8805998481397115\n",
      "Epoch 5 - Save Best Score: 0.8806 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [658/659] Data 0.000 (0.011) Elapsed 1m 33s (remain 0m 0s) Loss: 0.0288(0.5072) \n",
      "Epoch: [6][0/2634]Data 0.924 (0.924)Elapsed 0m 2s (remain 87m 56s)Loss: 0.5147(0.5147)Grad: 0.8988  \n",
      "Epoch: [6][100/2634]Data 0.000 (0.009)Elapsed 1m 29s (remain 37m 27s)Loss: 1.0759(0.6744)Grad: 1.9192  \n",
      "Epoch: [6][200/2634]Data 0.000 (0.005)Elapsed 2m 57s (remain 35m 45s)Loss: 0.0377(0.6449)Grad: 0.8962  \n",
      "Epoch: [6][300/2634]Data 0.000 (0.003)Elapsed 4m 25s (remain 34m 15s)Loss: 0.3456(0.5933)Grad: 1.2960  \n",
      "Epoch: [6][400/2634]Data 0.000 (0.002)Elapsed 5m 52s (remain 32m 44s)Loss: 0.5021(0.6307)Grad: 0.9264  \n",
      "Epoch: [6][500/2634]Data 0.000 (0.002)Elapsed 7m 20s (remain 31m 13s)Loss: 0.5322(0.5952)Grad: 1.6618  \n",
      "Epoch: [6][600/2634]Data 0.000 (0.002)Elapsed 8m 47s (remain 29m 44s)Loss: 0.1787(0.5778)Grad: 1.8849  \n",
      "Epoch: [6][700/2634]Data 0.000 (0.001)Elapsed 10m 15s (remain 28m 16s)Loss: 0.0330(0.5658)Grad: 0.8132  \n",
      "Epoch: [6][800/2634]Data 0.000 (0.001)Elapsed 11m 42s (remain 26m 47s)Loss: 1.5114(0.5754)Grad: 1.9757  \n",
      "Epoch: [6][900/2634]Data 0.000 (0.001)Elapsed 13m 10s (remain 25m 19s)Loss: 0.8623(0.5674)Grad: 2.3387  \n",
      "Epoch: [6][1000/2634]Data 0.000 (0.001)Elapsed 14m 37s (remain 23m 51s)Loss: 0.1235(0.5578)Grad: 1.8708  \n",
      "Epoch: [6][1100/2634]Data 0.000 (0.001)Elapsed 16m 5s (remain 22m 24s)Loss: 0.5398(0.5635)Grad: 1.7552  \n",
      "Epoch: [6][1200/2634]Data 0.000 (0.001)Elapsed 17m 32s (remain 20m 55s)Loss: 0.1743(0.5542)Grad: 0.8843  \n",
      "Epoch: [6][1300/2634]Data 0.000 (0.001)Elapsed 18m 59s (remain 19m 27s)Loss: 4.0490(0.5513)Grad: 1.6895  \n",
      "Epoch: [6][1400/2634]Data 0.000 (0.001)Elapsed 20m 27s (remain 18m 0s)Loss: 0.0204(0.5486)Grad: 0.6060  \n",
      "Epoch: [6][1500/2634]Data 0.000 (0.001)Elapsed 21m 54s (remain 16m 32s)Loss: 1.9668(0.5565)Grad: 3.5122  \n",
      "Epoch: [6][1600/2634]Data 0.000 (0.001)Elapsed 23m 21s (remain 15m 4s)Loss: 2.8887(0.5607)Grad: 2.4122  \n",
      "Epoch: [6][1700/2634]Data 0.000 (0.001)Elapsed 24m 49s (remain 13m 36s)Loss: 0.7263(0.5608)Grad: 2.0077  \n",
      "Epoch: [6][1800/2634]Data 0.000 (0.001)Elapsed 26m 16s (remain 12m 9s)Loss: 0.0338(0.5590)Grad: 0.9212  \n",
      "Epoch: [6][1900/2634]Data 0.000 (0.001)Elapsed 27m 44s (remain 10m 41s)Loss: 0.0051(0.5590)Grad: 0.3141  \n",
      "Epoch: [6][2000/2634]Data 0.000 (0.001)Elapsed 29m 11s (remain 9m 14s)Loss: 0.4067(0.5586)Grad: 1.9364  \n",
      "Epoch: [6][2100/2634]Data 0.000 (0.001)Elapsed 30m 38s (remain 7m 46s)Loss: 1.3268(0.5706)Grad: 2.0733  \n",
      "Epoch: [6][2200/2634]Data 0.000 (0.001)Elapsed 32m 6s (remain 6m 19s)Loss: 0.0028(0.5728)Grad: 0.2320  \n",
      "Epoch: [6][2300/2634]Data 0.000 (0.001)Elapsed 33m 33s (remain 4m 51s)Loss: 0.0362(0.5725)Grad: 0.6964  \n",
      "Epoch: [6][2400/2634]Data 0.000 (0.001)Elapsed 35m 0s (remain 3m 23s)Loss: 0.0092(0.5730)Grad: 0.3417  \n",
      "Epoch: [6][2500/2634]Data 0.000 (0.001)Elapsed 36m 28s (remain 1m 56s)Loss: 0.3622(0.5671)Grad: 1.6041  \n",
      "Epoch: [6][2600/2634]Data 0.000 (0.001)Elapsed 37m 55s (remain 0m 28s)Loss: 0.0142(0.5655)Grad: 0.7078  \n",
      "Epoch: [6][2633/2634]Data 0.000 (0.001)Elapsed 38m 24s (remain 0m 0s)Loss: 0.0734(0.5652)Grad: 1.0851  \n",
      "EVAL: [0/659] Data 0.570 (0.570) Elapsed 0m 0s (remain 7m 58s) Loss: 0.7811(0.7811) \n",
      "EVAL: [100/659] Data 0.000 (0.013) Elapsed 0m 13s (remain 1m 12s) Loss: 0.3249(0.5003) \n",
      "EVAL: [200/659] Data 0.000 (0.010) Elapsed 0m 25s (remain 0m 57s) Loss: 0.1510(0.4993) \n",
      "EVAL: [300/659] Data 0.000 (0.009) Elapsed 0m 39s (remain 0m 47s) Loss: 0.2319(0.4837) \n",
      "EVAL: [400/659] Data 0.000 (0.009) Elapsed 0m 52s (remain 0m 33s) Loss: 0.3319(0.4926) \n",
      "EVAL: [500/659] Data 0.000 (0.007) Elapsed 1m 4s (remain 0m 20s) Loss: 0.3132(0.4843) \n",
      "EVAL: [600/659] Data 0.000 (0.007) Elapsed 1m 16s (remain 0m 7s) Loss: 0.0075(0.4884) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.5652 avg_val_loss: 0.4899 time: 2388s\n",
      "Epoch 6 - Accuracy: 0.8824981017463933\n",
      "Epoch 6 - Save Best Score: 0.8825 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [658/659] Data 0.000 (0.006) Elapsed 1m 23s (remain 0m 0s) Loss: 0.0882(0.4899) \n",
      "Epoch: [7][0/2634]Data 0.833 (0.833)Elapsed 0m 1s (remain 80m 12s)Loss: 0.4573(0.4573)Grad: 2.3744  \n",
      "Epoch: [7][100/2634]Data 0.000 (0.008)Elapsed 1m 29s (remain 37m 22s)Loss: 0.6023(0.6833)Grad: 2.0063  \n",
      "Epoch: [7][200/2634]Data 0.000 (0.004)Elapsed 2m 56s (remain 35m 39s)Loss: 1.5217(0.5929)Grad: 2.4881  \n",
      "Epoch: [7][300/2634]Data 0.000 (0.003)Elapsed 4m 24s (remain 34m 7s)Loss: 0.0181(0.5704)Grad: 0.4523  \n",
      "Epoch: [7][400/2634]Data 0.000 (0.002)Elapsed 5m 51s (remain 32m 36s)Loss: 0.8899(0.5543)Grad: 1.7005  \n",
      "Epoch: [7][500/2634]Data 0.000 (0.002)Elapsed 7m 18s (remain 31m 8s)Loss: 0.0506(0.5288)Grad: 0.6883  \n",
      "Epoch: [7][600/2634]Data 0.000 (0.002)Elapsed 8m 45s (remain 29m 39s)Loss: 0.0688(0.5514)Grad: 1.2698  \n",
      "Epoch: [7][700/2634]Data 0.000 (0.001)Elapsed 10m 13s (remain 28m 11s)Loss: 0.0435(0.5560)Grad: 0.5733  \n",
      "Epoch: [7][800/2634]Data 0.000 (0.001)Elapsed 11m 41s (remain 26m 44s)Loss: 0.0994(0.5629)Grad: 1.2285  \n",
      "Epoch: [7][900/2634]Data 0.000 (0.001)Elapsed 13m 8s (remain 25m 16s)Loss: 0.5432(0.5532)Grad: 2.4958  \n",
      "Epoch: [7][1000/2634]Data 0.000 (0.001)Elapsed 14m 35s (remain 23m 48s)Loss: 1.4232(0.5457)Grad: 1.4557  \n",
      "Epoch: [7][1100/2634]Data 0.000 (0.001)Elapsed 16m 2s (remain 22m 20s)Loss: 0.0872(0.5441)Grad: 1.5796  \n",
      "Epoch: [7][1200/2634]Data 0.000 (0.001)Elapsed 17m 30s (remain 20m 53s)Loss: 0.0695(0.5519)Grad: 0.5816  \n",
      "Epoch: [7][1300/2634]Data 0.000 (0.001)Elapsed 18m 58s (remain 19m 26s)Loss: 0.0037(0.5548)Grad: 0.2864  \n",
      "Epoch: [7][1400/2634]Data 0.000 (0.001)Elapsed 20m 25s (remain 17m 58s)Loss: 0.3905(0.5529)Grad: 1.5342  \n",
      "Epoch: [7][1500/2634]Data 0.000 (0.001)Elapsed 21m 53s (remain 16m 31s)Loss: 0.3181(0.5521)Grad: 1.5563  \n",
      "Epoch: [7][1600/2634]Data 0.000 (0.001)Elapsed 23m 20s (remain 15m 3s)Loss: 0.0239(0.5476)Grad: 0.6662  \n",
      "Epoch: [7][1700/2634]Data 0.000 (0.001)Elapsed 24m 48s (remain 13m 36s)Loss: 0.9143(0.5415)Grad: 1.7872  \n",
      "Epoch: [7][1800/2634]Data 0.000 (0.001)Elapsed 26m 16s (remain 12m 9s)Loss: 0.3260(0.5385)Grad: 0.8837  \n",
      "Epoch: [7][1900/2634]Data 0.000 (0.001)Elapsed 27m 44s (remain 10m 41s)Loss: 0.0209(0.5465)Grad: 0.5533  \n",
      "Epoch: [7][2000/2634]Data 0.000 (0.001)Elapsed 29m 11s (remain 9m 14s)Loss: 0.0420(0.5424)Grad: 0.9670  \n",
      "Epoch: [7][2100/2634]Data 0.000 (0.001)Elapsed 30m 39s (remain 7m 46s)Loss: 1.0981(0.5398)Grad: 2.9614  \n",
      "Epoch: [7][2200/2634]Data 0.000 (0.001)Elapsed 32m 6s (remain 6m 19s)Loss: 0.2878(0.5423)Grad: 0.8689  \n",
      "Epoch: [7][2300/2634]Data 0.000 (0.001)Elapsed 33m 34s (remain 4m 51s)Loss: 1.3850(0.5418)Grad: 0.9214  \n",
      "Epoch: [7][2400/2634]Data 0.000 (0.000)Elapsed 35m 1s (remain 3m 23s)Loss: 0.9745(0.5414)Grad: 2.5828  \n",
      "Epoch: [7][2500/2634]Data 0.000 (0.000)Elapsed 36m 29s (remain 1m 56s)Loss: 0.0140(0.5420)Grad: 0.5263  \n",
      "Epoch: [7][2600/2634]Data 0.000 (0.000)Elapsed 37m 56s (remain 0m 28s)Loss: 0.1868(0.5419)Grad: 1.3884  \n",
      "Epoch: [7][2633/2634]Data 0.000 (0.000)Elapsed 38m 24s (remain 0m 0s)Loss: 0.7303(0.5418)Grad: 1.3428  \n",
      "EVAL: [0/659] Data 0.605 (0.605) Elapsed 0m 0s (remain 8m 21s) Loss: 0.9736(0.9736) \n",
      "EVAL: [100/659] Data 0.000 (0.014) Elapsed 0m 14s (remain 1m 17s) Loss: 0.0928(0.5119) \n",
      "EVAL: [200/659] Data 0.000 (0.011) Elapsed 0m 26s (remain 1m 0s) Loss: 0.1197(0.5123) \n",
      "EVAL: [300/659] Data 0.000 (0.010) Elapsed 0m 39s (remain 0m 47s) Loss: 0.1654(0.4906) \n",
      "EVAL: [400/659] Data 0.002 (0.010) Elapsed 0m 53s (remain 0m 34s) Loss: 0.5590(0.5011) \n",
      "EVAL: [500/659] Data 0.000 (0.010) Elapsed 1m 5s (remain 0m 20s) Loss: 0.3304(0.4898) \n",
      "EVAL: [600/659] Data 0.000 (0.009) Elapsed 1m 18s (remain 0m 7s) Loss: 0.0026(0.4907) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.5418 avg_val_loss: 0.4922 time: 2390s\n",
      "Epoch 7 - Accuracy: 0.8849658314350797\n",
      "Epoch 7 - Save Best Score: 0.8850 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [658/659] Data 0.000 (0.008) Elapsed 1m 25s (remain 0m 0s) Loss: 0.0661(0.4922) \n",
      "Epoch: [8][0/2634]Data 0.811 (0.811)Elapsed 0m 1s (remain 80m 11s)Loss: 0.4243(0.4243)Grad: 2.4159  \n",
      "Epoch: [8][100/2634]Data 0.000 (0.008)Elapsed 1m 29s (remain 37m 23s)Loss: 1.9783(0.5008)Grad: 1.3371  \n",
      "Epoch: [8][200/2634]Data 0.000 (0.004)Elapsed 2m 57s (remain 35m 42s)Loss: 0.8235(0.5980)Grad: 3.5878  \n",
      "Epoch: [8][300/2634]Data 0.000 (0.003)Elapsed 4m 24s (remain 34m 10s)Loss: 1.1888(0.6077)Grad: 2.6189  \n",
      "Epoch: [8][400/2634]Data 0.000 (0.002)Elapsed 5m 51s (remain 32m 39s)Loss: 0.0066(0.5929)Grad: 0.4335  \n",
      "Epoch: [8][500/2634]Data 0.000 (0.002)Elapsed 7m 19s (remain 31m 12s)Loss: 0.6339(0.5748)Grad: 3.2557  \n",
      "Epoch: [8][600/2634]Data 0.000 (0.001)Elapsed 8m 47s (remain 29m 42s)Loss: 0.8971(0.5894)Grad: 0.9404  \n",
      "Epoch: [8][700/2634]Data 0.000 (0.001)Elapsed 10m 14s (remain 28m 14s)Loss: 2.0266(0.5819)Grad: 1.2411  \n",
      "Epoch: [8][800/2634]Data 0.000 (0.001)Elapsed 11m 42s (remain 26m 46s)Loss: 0.3031(0.5790)Grad: 2.1315  \n",
      "Epoch: [8][900/2634]Data 0.000 (0.001)Elapsed 13m 9s (remain 25m 18s)Loss: 0.0130(0.5643)Grad: 0.4367  \n",
      "Epoch: [8][1000/2634]Data 0.000 (0.001)Elapsed 14m 37s (remain 23m 51s)Loss: 0.6828(0.5615)Grad: 2.9315  \n",
      "Epoch: [8][1100/2634]Data 0.000 (0.001)Elapsed 16m 4s (remain 22m 23s)Loss: 0.2691(0.5528)Grad: 1.7965  \n",
      "Epoch: [8][1200/2634]Data 0.000 (0.001)Elapsed 17m 32s (remain 20m 55s)Loss: 0.2079(0.5419)Grad: 2.8047  \n",
      "Epoch: [8][1300/2634]Data 0.000 (0.001)Elapsed 18m 59s (remain 19m 27s)Loss: 1.0370(0.5490)Grad: 1.6473  \n",
      "Epoch: [8][1400/2634]Data 0.000 (0.001)Elapsed 20m 27s (remain 18m 0s)Loss: 0.8205(0.5446)Grad: 2.0614  \n",
      "Epoch: [8][1500/2634]Data 0.000 (0.001)Elapsed 21m 54s (remain 16m 32s)Loss: 0.2162(0.5383)Grad: 1.0047  \n",
      "Epoch: [8][1600/2634]Data 0.000 (0.001)Elapsed 23m 22s (remain 15m 4s)Loss: 0.0080(0.5334)Grad: 0.5105  \n",
      "Epoch: [8][1700/2634]Data 0.000 (0.001)Elapsed 24m 49s (remain 13m 37s)Loss: 2.1170(0.5325)Grad: 1.9113  \n",
      "Epoch: [8][1800/2634]Data 0.000 (0.001)Elapsed 26m 16s (remain 12m 9s)Loss: 0.0097(0.5311)Grad: 0.3658  \n",
      "Epoch: [8][1900/2634]Data 0.000 (0.001)Elapsed 27m 44s (remain 10m 41s)Loss: 0.6064(0.5298)Grad: 1.9137  \n",
      "Epoch: [8][2000/2634]Data 0.000 (0.001)Elapsed 29m 11s (remain 9m 14s)Loss: 0.2317(0.5254)Grad: 1.7395  \n",
      "Epoch: [8][2100/2634]Data 0.000 (0.001)Elapsed 30m 38s (remain 7m 46s)Loss: 2.7977(0.5293)Grad: 4.5338  \n",
      "Epoch: [8][2200/2634]Data 0.000 (0.001)Elapsed 32m 6s (remain 6m 18s)Loss: 1.0441(0.5264)Grad: 1.8392  \n",
      "Epoch: [8][2300/2634]Data 0.000 (0.001)Elapsed 33m 33s (remain 4m 51s)Loss: 0.3331(0.5296)Grad: 0.9543  \n",
      "Epoch: [8][2400/2634]Data 0.000 (0.000)Elapsed 35m 0s (remain 3m 23s)Loss: 0.0123(0.5282)Grad: 0.7308  \n",
      "Epoch: [8][2500/2634]Data 0.000 (0.000)Elapsed 36m 28s (remain 1m 56s)Loss: 0.0073(0.5289)Grad: 0.3159  \n",
      "Epoch: [8][2600/2634]Data 0.000 (0.000)Elapsed 37m 55s (remain 0m 28s)Loss: 0.0136(0.5328)Grad: 0.4813  \n",
      "Epoch: [8][2633/2634]Data 0.000 (0.000)Elapsed 38m 24s (remain 0m 0s)Loss: 0.5671(0.5324)Grad: 3.7442  \n",
      "EVAL: [0/659] Data 0.693 (0.693) Elapsed 0m 0s (remain 8m 45s) Loss: 0.8892(0.8892) \n",
      "EVAL: [100/659] Data 0.000 (0.014) Elapsed 0m 13s (remain 1m 12s) Loss: 0.1385(0.5418) \n",
      "EVAL: [200/659] Data 0.000 (0.010) Elapsed 0m 25s (remain 0m 59s) Loss: 0.1239(0.5496) \n",
      "EVAL: [300/659] Data 0.000 (0.010) Elapsed 0m 38s (remain 0m 45s) Loss: 0.1797(0.5162) \n",
      "EVAL: [400/659] Data 0.000 (0.009) Elapsed 0m 51s (remain 0m 33s) Loss: 0.5330(0.5280) \n",
      "EVAL: [500/659] Data 0.000 (0.008) Elapsed 1m 4s (remain 0m 20s) Loss: 0.2418(0.5167) \n",
      "EVAL: [600/659] Data 0.000 (0.007) Elapsed 1m 17s (remain 0m 7s) Loss: 0.0015(0.5204) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.5324 avg_val_loss: 0.5270 time: 2388s\n",
      "Epoch 8 - Accuracy: 0.886294608959757\n",
      "Epoch 8 - Save Best Score: 0.8863 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [658/659] Data 0.000 (0.007) Elapsed 1m 23s (remain 0m 0s) Loss: 0.0292(0.5270) \n",
      "Epoch: [9][0/2634]Data 0.577 (0.577)Elapsed 0m 1s (remain 85m 54s)Loss: 0.7969(0.7969)Grad: 2.7362  \n",
      "Epoch: [9][100/2634]Data 0.000 (0.006)Elapsed 1m 29s (remain 37m 18s)Loss: 1.7703(0.4217)Grad: 1.6224  \n",
      "Epoch: [9][200/2634]Data 0.000 (0.003)Elapsed 2m 56s (remain 35m 34s)Loss: 0.5944(0.4683)Grad: 0.7087  \n",
      "Epoch: [9][300/2634]Data 0.000 (0.002)Elapsed 4m 23s (remain 34m 1s)Loss: 0.5431(0.4770)Grad: 2.4492  \n",
      "Epoch: [9][400/2634]Data 0.000 (0.002)Elapsed 5m 50s (remain 32m 33s)Loss: 0.0792(0.4986)Grad: 1.0529  \n",
      "Epoch: [9][500/2634]Data 0.000 (0.001)Elapsed 7m 17s (remain 31m 4s)Loss: 0.1722(0.5000)Grad: 1.2692  \n",
      "Epoch: [9][600/2634]Data 0.000 (0.001)Elapsed 8m 45s (remain 29m 37s)Loss: 0.5243(0.5107)Grad: 3.1423  \n",
      "Epoch: [9][700/2634]Data 0.000 (0.001)Elapsed 10m 12s (remain 28m 10s)Loss: 0.1214(0.5228)Grad: 1.8697  \n",
      "Epoch: [9][800/2634]Data 0.000 (0.001)Elapsed 11m 40s (remain 26m 43s)Loss: 0.0890(0.5263)Grad: 1.4006  \n",
      "Epoch: [9][900/2634]Data 0.000 (0.001)Elapsed 13m 7s (remain 25m 14s)Loss: 1.4821(0.5315)Grad: 2.2373  \n",
      "Epoch: [9][1000/2634]Data 0.000 (0.001)Elapsed 14m 35s (remain 23m 47s)Loss: 0.3943(0.5172)Grad: 2.4378  \n",
      "Epoch: [9][1100/2634]Data 0.000 (0.001)Elapsed 16m 2s (remain 22m 19s)Loss: 0.5960(0.5139)Grad: 0.8055  \n",
      "Epoch: [9][1200/2634]Data 0.000 (0.001)Elapsed 17m 29s (remain 20m 52s)Loss: 0.0483(0.5081)Grad: 0.7961  \n",
      "Epoch: [9][1300/2634]Data 0.000 (0.001)Elapsed 18m 57s (remain 19m 25s)Loss: 0.5221(0.5195)Grad: 1.9895  \n",
      "Epoch: [9][1400/2634]Data 0.000 (0.001)Elapsed 20m 24s (remain 17m 57s)Loss: 0.7220(0.5289)Grad: 2.5301  \n",
      "Epoch: [9][1500/2634]Data 0.000 (0.001)Elapsed 21m 53s (remain 16m 31s)Loss: 0.0202(0.5302)Grad: 0.6302  \n",
      "Epoch: [9][1600/2634]Data 0.000 (0.001)Elapsed 23m 20s (remain 15m 3s)Loss: 0.2819(0.5244)Grad: 1.9265  \n",
      "Epoch: [9][1700/2634]Data 0.000 (0.000)Elapsed 24m 48s (remain 13m 36s)Loss: 0.0319(0.5235)Grad: 0.7773  \n",
      "Epoch: [9][1800/2634]Data 0.000 (0.000)Elapsed 26m 16s (remain 12m 9s)Loss: 0.5623(0.5221)Grad: 2.5366  \n",
      "Epoch: [9][1900/2634]Data 0.000 (0.000)Elapsed 27m 44s (remain 10m 41s)Loss: 0.0564(0.5243)Grad: 1.0514  \n",
      "Epoch: [9][2000/2634]Data 0.000 (0.000)Elapsed 29m 13s (remain 9m 14s)Loss: 0.1722(0.5242)Grad: 2.5561  \n",
      "Epoch: [9][2100/2634]Data 0.000 (0.000)Elapsed 30m 41s (remain 7m 47s)Loss: 0.0229(0.5255)Grad: 0.6476  \n",
      "Epoch: [9][2200/2634]Data 0.000 (0.000)Elapsed 32m 9s (remain 6m 19s)Loss: 0.4888(0.5291)Grad: 1.4176  \n",
      "Epoch: [9][2300/2634]Data 0.000 (0.000)Elapsed 33m 36s (remain 4m 51s)Loss: 1.4591(0.5271)Grad: 1.2773  \n",
      "Epoch: [9][2400/2634]Data 0.000 (0.000)Elapsed 35m 4s (remain 3m 24s)Loss: 0.9920(0.5240)Grad: 1.7589  \n",
      "Epoch: [9][2500/2634]Data 0.000 (0.000)Elapsed 36m 32s (remain 1m 56s)Loss: 0.6079(0.5291)Grad: 1.7430  \n",
      "Epoch: [9][2600/2634]Data 0.000 (0.000)Elapsed 37m 59s (remain 0m 28s)Loss: 0.4084(0.5239)Grad: 1.6183  \n",
      "Epoch: [9][2633/2634]Data 0.000 (0.000)Elapsed 38m 28s (remain 0m 0s)Loss: 2.3959(0.5240)Grad: 1.5164  \n",
      "EVAL: [0/659] Data 0.933 (0.933) Elapsed 0m 1s (remain 11m 23s) Loss: 0.8989(0.8989) \n",
      "EVAL: [100/659] Data 0.038 (0.018) Elapsed 0m 14s (remain 1m 17s) Loss: 0.0718(0.5138) \n",
      "EVAL: [200/659] Data 0.000 (0.014) Elapsed 0m 26s (remain 1m 0s) Loss: 0.1831(0.5219) \n",
      "EVAL: [300/659] Data 0.000 (0.012) Elapsed 0m 39s (remain 0m 46s) Loss: 0.2264(0.4960) \n",
      "EVAL: [400/659] Data 0.000 (0.012) Elapsed 0m 52s (remain 0m 34s) Loss: 0.6520(0.5140) \n",
      "EVAL: [500/659] Data 0.000 (0.011) Elapsed 1m 6s (remain 0m 21s) Loss: 0.1867(0.5020) \n",
      "EVAL: [600/659] Data 0.001 (0.010) Elapsed 1m 19s (remain 0m 7s) Loss: 0.0003(0.5059) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.5240 avg_val_loss: 0.5138 time: 2395s\n",
      "Epoch 9 - Accuracy: 0.8872437357630979\n",
      "Epoch 9 - Save Best Score: 0.8872 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [658/659] Data 0.000 (0.009) Elapsed 1m 26s (remain 0m 0s) Loss: 0.0018(0.5138) \n",
      "Epoch: [10][0/2634]Data 0.642 (0.642)Elapsed 0m 1s (remain 80m 10s)Loss: 0.0165(0.0165)Grad: 0.7181  \n",
      "Epoch: [10][100/2634]Data 0.000 (0.007)Elapsed 1m 29s (remain 37m 14s)Loss: 0.2810(0.4538)Grad: 1.5257  \n",
      "Epoch: [10][200/2634]Data 0.000 (0.003)Elapsed 2m 56s (remain 35m 42s)Loss: 0.6647(0.4646)Grad: 1.4540  \n",
      "Epoch: [10][300/2634]Data 0.000 (0.002)Elapsed 4m 24s (remain 34m 8s)Loss: 1.6072(0.5048)Grad: 2.1275  \n",
      "Epoch: [10][400/2634]Data 0.000 (0.002)Elapsed 5m 51s (remain 32m 38s)Loss: 0.3862(0.5211)Grad: 0.9716  \n",
      "Epoch: [10][500/2634]Data 0.000 (0.001)Elapsed 7m 19s (remain 31m 12s)Loss: 0.0107(0.5140)Grad: 0.5731  \n",
      "Epoch: [10][600/2634]Data 0.000 (0.001)Elapsed 8m 47s (remain 29m 45s)Loss: 0.1641(0.5062)Grad: 1.2100  \n",
      "Epoch: [10][700/2634]Data 0.000 (0.001)Elapsed 10m 15s (remain 28m 16s)Loss: 2.1740(0.5149)Grad: 2.5960  \n",
      "Epoch: [10][800/2634]Data 0.000 (0.001)Elapsed 11m 43s (remain 26m 49s)Loss: 0.3381(0.5277)Grad: 2.7817  \n",
      "Epoch: [10][900/2634]Data 0.000 (0.001)Elapsed 13m 10s (remain 25m 20s)Loss: 0.2301(0.5217)Grad: 1.6868  \n",
      "Epoch: [10][1000/2634]Data 0.000 (0.001)Elapsed 14m 38s (remain 23m 52s)Loss: 0.3614(0.5149)Grad: 1.6671  \n",
      "Epoch: [10][1100/2634]Data 0.000 (0.001)Elapsed 16m 5s (remain 22m 24s)Loss: 1.1395(0.5201)Grad: 2.6177  \n",
      "Epoch: [10][1200/2634]Data 0.000 (0.001)Elapsed 17m 33s (remain 20m 56s)Loss: 0.1066(0.5217)Grad: 0.8284  \n",
      "Epoch: [10][1300/2634]Data 0.000 (0.001)Elapsed 19m 0s (remain 19m 28s)Loss: 0.5713(0.5170)Grad: 1.8595  \n",
      "Epoch: [10][1400/2634]Data 0.000 (0.001)Elapsed 20m 27s (remain 18m 0s)Loss: 0.3672(0.5208)Grad: 2.2190  \n",
      "Epoch: [10][1500/2634]Data 0.000 (0.001)Elapsed 21m 55s (remain 16m 32s)Loss: 1.6746(0.5214)Grad: 0.9996  \n",
      "Epoch: [10][1600/2634]Data 0.000 (0.001)Elapsed 23m 22s (remain 15m 4s)Loss: 1.1778(0.5160)Grad: 2.5010  \n",
      "Epoch: [10][1700/2634]Data 0.000 (0.001)Elapsed 24m 49s (remain 13m 37s)Loss: 0.1693(0.5109)Grad: 1.9302  \n",
      "Epoch: [10][1800/2634]Data 0.000 (0.001)Elapsed 26m 16s (remain 12m 9s)Loss: 1.3275(0.5118)Grad: 2.3208  \n",
      "Epoch: [10][1900/2634]Data 0.000 (0.000)Elapsed 27m 44s (remain 10m 41s)Loss: 0.0440(0.5089)Grad: 0.8450  \n",
      "Epoch: [10][2000/2634]Data 0.000 (0.000)Elapsed 29m 11s (remain 9m 14s)Loss: 0.0447(0.5106)Grad: 0.9723  \n",
      "Epoch: [10][2100/2634]Data 0.000 (0.000)Elapsed 30m 38s (remain 7m 46s)Loss: 0.0461(0.5097)Grad: 1.1513  \n",
      "Epoch: [10][2200/2634]Data 0.000 (0.000)Elapsed 32m 5s (remain 6m 18s)Loss: 0.0275(0.5143)Grad: 0.4746  \n",
      "Epoch: [10][2300/2634]Data 0.000 (0.000)Elapsed 33m 33s (remain 4m 51s)Loss: 0.0218(0.5132)Grad: 0.6328  \n",
      "Epoch: [10][2400/2634]Data 0.000 (0.000)Elapsed 35m 0s (remain 3m 23s)Loss: 0.0065(0.5108)Grad: 0.3188  \n",
      "Epoch: [10][2500/2634]Data 0.000 (0.000)Elapsed 36m 27s (remain 1m 56s)Loss: 0.3705(0.5092)Grad: 2.1941  \n",
      "Epoch: [10][2600/2634]Data 0.000 (0.000)Elapsed 37m 55s (remain 0m 28s)Loss: 2.3789(0.5081)Grad: 4.0853  \n",
      "Epoch: [10][2633/2634]Data 0.000 (0.000)Elapsed 38m 23s (remain 0m 0s)Loss: 0.2191(0.5055)Grad: 1.8876  \n",
      "EVAL: [0/659] Data 0.624 (0.624) Elapsed 0m 0s (remain 8m 25s) Loss: 0.9983(0.9983) \n",
      "EVAL: [100/659] Data 0.099 (0.019) Elapsed 0m 15s (remain 1m 24s) Loss: 0.1176(0.4580) \n",
      "EVAL: [200/659] Data 0.000 (0.013) Elapsed 0m 27s (remain 1m 3s) Loss: 0.1754(0.4700) \n",
      "EVAL: [300/659] Data 0.000 (0.011) Elapsed 0m 40s (remain 0m 47s) Loss: 0.2360(0.4513) \n",
      "EVAL: [400/659] Data 0.000 (0.010) Elapsed 0m 53s (remain 0m 34s) Loss: 0.5112(0.4619) \n",
      "EVAL: [500/659] Data 0.000 (0.010) Elapsed 1m 6s (remain 0m 20s) Loss: 0.2560(0.4524) \n",
      "EVAL: [600/659] Data 0.000 (0.008) Elapsed 1m 19s (remain 0m 7s) Loss: 0.0013(0.4526) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.5055 avg_val_loss: 0.4547 time: 2390s\n",
      "Epoch 10 - Accuracy: 0.8895216400911162\n",
      "Epoch 10 - Save Best Score: 0.8895 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [658/659] Data 0.000 (0.008) Elapsed 1m 26s (remain 0m 0s) Loss: 0.0204(0.4547) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=============== fold: 0 result ================\n",
      "Score: 0.88952\n",
      "============ CV ============\n",
      "Score: 0.88952\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 22348.653672,
   "end_time": "2021-01-11T06:10:28.258226",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-10T23:57:59.604554",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
